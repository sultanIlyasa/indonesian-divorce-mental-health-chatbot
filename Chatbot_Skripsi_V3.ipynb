{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing Dataset & Dependencies"
      ],
      "metadata": {
        "id": "cHxiZjEhdq4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "tf.random.set_seed(1234)\n",
        "import tensorflow_datasets as tfds\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import pydot\n",
        "import matplotlib.pyplot as plt\n",
        "import graphviz"
      ],
      "metadata": {
        "id": "cMqvgEsSdGEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sentence(sentence):\n",
        "  sentence = sentence.replace('_comma_', ',')\n",
        "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "  sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
        "  sentence = re.sub(r\"  \",\"\",sentence)\n",
        "  sentence = sentence.strip()\n",
        "  return sentence\n",
        "\n",
        "MAX_SENTENCE_LENGTH = 128"
      ],
      "metadata": {
        "id": "691j-aVveHNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"D:\\skripsi-sultin\\data\\datasets_skripsi_sultan_new - Copy.csv\")"
      ],
      "metadata": {
        "id": "ijmXg6KytWx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##load convo from df and concenatate\n",
        "\n",
        "def load_conversations_from_csv():\n",
        "    inputs, outputs = [], []\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        ip = preprocess_sentence(row['question'])\n",
        "        op = preprocess_sentence(row['response'].replace('\\n', ' '))\n",
        "\n",
        "        if len(ip.split())>MAX_SENTENCE_LENGTH:\n",
        "            continue\n",
        "\n",
        "        outputs.append(op)\n",
        "        inputs.append(ip)\n",
        "\n",
        "    return inputs, outputs\n",
        "\n",
        "questions, answers = load_conversations_from_csv()"
      ],
      "metadata": {
        "id": "CafRx02AvUp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(questions))\n",
        "print(len(answers))"
      ],
      "metadata": {
        "id": "RfYxkeoUvjg_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8307ef0a-53e5-4066-e001-bdea53a84a28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500\n",
            "500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Question: ' + questions[41])\n",
        "print('Answer: ' + answers[41])"
      ],
      "metadata": {
        "id": "33q1DBp-vsRv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3193058-877d-440f-e6dd-a6aaf3fbc1d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Bagaimana cara membangun kembali hubungan yang baik dengan kedua orang tua setelah mereka berpisah ?\n",
            "Answer: Setelah perceraian , hubungan dengan kedua orang tua mungkin terasa berbeda , tetapi bukan berarti keterikatan yang sehat tidak bisa terjalin . Cobalah untuk membangun kembali hubungan dengan langkah kecil , seperti menghabiskan waktu bersama dalam suasana yang nyaman atau mengungkapkan perasaan Anda secara terbuka . Ingatlah bahwa Anda tidak harus memilih salah satu orang tua kedua hubungan tersebut tetap penting dan bisa berkembang dengan cara yang unik . Dengan pendekatan yang penuh pengertian , Anda dapat menemukan cara untuk menjaga kedekatan tanpa merasa terjebak dalam konflik masa lalu .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(questions)\n",
        "len(answers)"
      ],
      "metadata": {
        "id": "zx0UUPhCv9cJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "196ff911-c942-425f-c416-31b1a9010443"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    questions + answers, target_vocab_size=2**13)\n",
        "\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
        "\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2"
      ],
      "metadata": {
        "id": "f8ffCNcKxn0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Tokenized sample question: {}'.format(tokenizer.encode(questions[27])))\n"
      ],
      "metadata": {
        "id": "QZZpRvIY0pe9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b047ef57-d00e-4ca3-e349-b96e2d876d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized sample question: [51, 134, 98, 257, 64, 5, 18, 1, 635, 583, 274, 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_filter(inputs, outputs):\n",
        "    tokenized_inputs, tokenized_outputs = [], []\n",
        "\n",
        "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
        "        # Tokenize sentences\n",
        "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
        "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
        "\n",
        "        # Check tokenized sentence max length\n",
        "        if len(sentence1) <= MAX_SENTENCE_LENGTH and len(sentence2) <= MAX_SENTENCE_LENGTH:\n",
        "            tokenized_inputs.append(sentence1)\n",
        "            tokenized_outputs.append(sentence2)\n",
        "\n",
        "    # Pad tokenized sentences\n",
        "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "        tokenized_inputs, maxlen=MAX_SENTENCE_LENGTH, padding='post'\n",
        "    )\n",
        "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "        tokenized_outputs, maxlen=MAX_SENTENCE_LENGTH, padding='post'\n",
        "    )\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    return np.array(tokenized_inputs, dtype=np.int32), np.array(tokenized_outputs, dtype=np.int32)\n",
        "\n",
        "\n",
        "# Ensure questions & answers contain raw text before passing them in\n",
        "questions_raw, answers_raw = questions, answers\n",
        "questions, answers = tokenize_and_filter(questions_raw, answers_raw)\n",
        "\n",
        "print(\"Tokenized questions shape:\", questions.shape)\n",
        "print(\"Tokenized answers shape:\", answers.shape)\n"
      ],
      "metadata": {
        "id": "bLbdAjlw0tV4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f061a32a-3bca-441c-aad5-869d3b6ffb02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized questions shape: (500, 128)\n",
            "Tokenized answers shape: (500, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Vocab size: {}'.format(VOCAB_SIZE))\n",
        "print('Number of samples: {}'.format(len(questions)))"
      ],
      "metadata": {
        "id": "zbDORvzy0wP2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4643c3e8-6787-4e93-9403-89fc7bec1d87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 2462\n",
            "Number of samples: 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: save tokenizer\n",
        "\n",
        "tokenizer.save_to_file('tokenizer_vocab')\n"
      ],
      "metadata": {
        "id": "F5XbSc09kGDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 8\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': tf.convert_to_tensor(questions, dtype=tf.int32),\n",
        "        'dec_inputs': tf.convert_to_tensor(answers[:, :-1], dtype=tf.int32)\n",
        "    },\n",
        "    tf.convert_to_tensor(answers[:, 1:], dtype=tf.int32)  # <-- Not a dict\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "print(\"Dataset element spec:\", dataset.element_spec)\n"
      ],
      "metadata": {
        "id": "MXFfnAmy0zCO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a1ba836-6182-4351-a1d0-5ad41650cc03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset element spec: ({'inputs': TensorSpec(shape=(None, 128), dtype=tf.int32, name=None), 'dec_inputs': TensorSpec(shape=(None, 127), dtype=tf.int32, name=None)}, TensorSpec(shape=(None, 127), dtype=tf.int32, name=None))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "id": "x6Z979JE009Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e1cea4d-3fb6-4334-c376-85f64d49c50f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_PrefetchDataset element_spec=({'inputs': TensorSpec(shape=(None, 128), dtype=tf.int32, name=None), 'dec_inputs': TensorSpec(shape=(None, 127), dtype=tf.int32, name=None)}, TensorSpec(shape=(None, 127), dtype=tf.int32, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attention"
      ],
      "metadata": {
        "id": "vJrBgesq07cb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function = To compute the attention output given query, key, and value matrices,\n",
        "# optionally applying a mask to ignore irrelevant tokens (e.g., padding or future tokens in decoding).\n",
        "\n",
        "def scaled_dot_product_attention(query, key, value, mask=None):\n",
        "\n",
        "  # Ensure all input tensors are in the same datatype (float32) for consistency and safe numerical operations.\n",
        "  # Step 1: Ensure tensors are float32\n",
        "  \"\"\"Calculate the attention weights.\"\"\"\n",
        "  query = tf.cast(query, tf.float32)\n",
        "  key = tf.cast(key, tf.float32)\n",
        "  value = tf.cast(value, tf.float32)\n",
        "  print(f\"Query shape: {query.shape}\")\n",
        "  print(f\"Key shape: {key.shape}\")\n",
        "  print(f\"Value shape: {value.shape}\")\n",
        "\n",
        "  # This computes the raw attention scores by taking the dot product between query\n",
        "  # and the transpose of key. The result tells you how much each word should attend to every other word.\n",
        "  # Step 2: Q @ K^T\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "  print(f\"\\nQ × Kᵀ shape: {matmul_qk.shape}\")\n",
        "\n",
        "\n",
        "  # This scales down the attention scores by the square root of the key dimension to avoid extremely large values, which can destabilize training.\n",
        "  # Step 3: Scale by sqrt(depth)\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "  print(\"Scaled logits shape:\", logits.shape)\n",
        "\n",
        "  # If a mask is provided (e.g., for padding or future tokens),\n",
        "  # it adds a large negative value (-1e9) to the masked positions so that their softmax becomes near-zero, effectively ignoring them.\n",
        "  # Step 4: Add mask (if provided)\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "    print(\"Applied mask.\")\n",
        "\n",
        "  # Converts the scaled scores into normalized attention weights.\n",
        "  # The axis=-1 means softmax is applied across the last dimension (i.e., over all keys for each query).\n",
        "  # Step 5: Softmax to get attention weights\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "  print(\"Attention weights shape:\", attention_weights.shape)\n",
        "\n",
        "  #Computes the final attention output by taking the weighted sum of value vectors,\n",
        "  #where the weights come from the attention scores. This produces a new representation that focuses on the most relevant parts of the input.\n",
        "  # Step 6: Attention weights @ V\n",
        "  output = tf.matmul(attention_weights, value)\n",
        "  print(\"Final output shape:\", output.shape)\n",
        "\n",
        "  return output"
      ],
      "metadata": {
        "id": "QMmVs6Tb0936"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulated input (batch_size=1, seq_len=6, d_model=512)\n",
        "batch_size = 1\n",
        "seq_len = 6\n",
        "d_model = 512\n",
        "\n",
        "q = tf.random.uniform((batch_size, seq_len, d_model))  # shape: (1, 6, 512)\n",
        "k = tf.random.uniform((batch_size, seq_len, d_model))  # shape: (1, 6, 512)\n",
        "v = tf.random.uniform((batch_size, seq_len, d_model))  # shape: (1, 6, 512)\n",
        "\n",
        "# Apply attention\n",
        "output = scaled_dot_product_attention(q, k, v)\n",
        "\n",
        "print(\"\\nFinal attention output (values only shown truncated):\")\n",
        "print(output.numpy()[0][:2])  # Print only first 2 output vectors for brevity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDUsQUHkdi7W",
        "outputId": "da510d4c-364a-4adc-e7dd-7fa27867ea1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query shape: (1, 6, 512)\n",
            "Key shape: (1, 6, 512)\n",
            "Value shape: (1, 6, 512)\n",
            "\n",
            "Q × Kᵀ shape: (1, 6, 6)\n",
            "Scaled logits shape: (1, 6, 6)\n",
            "Attention weights shape: (1, 6, 6)\n",
            "Final output shape: (1, 6, 512)\n",
            "\n",
            "Final attention output (values only shown truncated):\n",
            "[[0.45498696 0.4432221  0.39133194 ... 0.38996    0.54827297 0.72887117]\n",
            " [0.44566947 0.4468937  0.37181562 ... 0.38027588 0.520456   0.7100762 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # linear layers, Transforms the inputs into Q, K, and V vectors.\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # split heads\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    # Apply scaled dot-product attention\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    # concatenation of heads, Concatenate all heads back\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    # final linear layer\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "e-tUk8wJ1A4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer\n",
        "Masking"
      ],
      "metadata": {
        "id": "1X95jy_Z1DTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This function generates a padding mask used in Transformer models to prevent the model from attending to padding tokens (value 0) during training or inference.\n",
        "# Padding mask: Masks out padding tokens (0) so the model doesn't pay attention to them.\n",
        "def create_padding_mask(x):\n",
        "  #\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32) #This returns a boolean tensor where each True indicates a padding token (0).\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "metadata": {
        "id": "krGF7yZW1H2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This is a batch of 2 sequences (batch size = 2), each of length 5. 0 is used as the padding token.\n",
        "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0],\n",
        "                                       [0, 0, 0, 4, 5]])))\n",
        "# 2: batch size (2 sequences)\n",
        "# 1: broadcast over all attention heads\n",
        "# 1: broadcast over all query positions\n",
        "# 5: sequence length (so model knows which positions to mask)"
      ],
      "metadata": {
        "id": "94nn4OKt1KK7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8edce317-1bd5-4ae4-854e-e38df273c0e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 0. 1. 0. 1.]]]\n",
            "\n",
            "\n",
            " [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look-ahead mask: Prevents the decoder from \"cheating\" by looking at future tokens during training\n",
        "# Combines look-ahead and padding masking This ensures that:\n",
        "# The decoder doesn't peek into future tokens.\n",
        "# Padding tokens are also masked out.\n",
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]  #Get Sequence Length\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "#  [[0. 1. 1. 1. 1.]\n",
        "#  [0. 0. 1. 1. 1.]\n",
        "#  [0. 0. 0. 1. 1.]\n",
        "#  [0. 0. 0. 0. 1.]\n",
        "#  [0. 0. 0. 0. 0.]]\n",
        "\n",
        "#  Combine Both Masks\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "metadata": {
        "id": "G4DaQnr91OvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(create_look_ahead_mask(tf.constant([[1, 2, 0, 4, 5]])))\n",
        "# 1\tbatch size (only 1 input sequence)\n",
        "# 1\tnumber of attention heads\n",
        "# 5\tquery positions (i.e., where we are attending from)\n",
        "# 5\tkey positions (i.e., where we are attending to)"
      ],
      "metadata": {
        "id": "97i5zrUe1Pao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1a4f47c-2c78-46d9-ec10-a23c1242331a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 1. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1.]\n",
            "   [0. 0. 1. 0. 1.]\n",
            "   [0. 0. 1. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positional Encoding"
      ],
      "metadata": {
        "id": "SBXxQD5n1Sz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformers don't have recurrence or convolution, so they lack any built-in notion of token order.\n",
        "# To fix this, we inject position information into input embeddings using sinusoidal functions.\n",
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "    def __init__(self, position, d_model):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "    def get_angles(self, position, i, d_model):\n",
        "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "        return position * angles\n",
        "\n",
        "    def positional_encoding(self, position, d_model):\n",
        "        angle_rads = self.get_angles(\n",
        "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "            d_model=d_model\n",
        "        )\n",
        "\n",
        "        # Apply sin to even indices in the array\n",
        "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "\n",
        "        # Apply cos to odd indices in the array\n",
        "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "\n",
        "        return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Make sure inputs are dense tensors\n",
        "        if isinstance(inputs, tf.SparseTensor):\n",
        "            inputs = tf.sparse.to_dense(inputs)\n",
        "\n",
        "        # Add positional encoding\n",
        "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape"
      ],
      "metadata": {
        "id": "4GQVrGkq1VeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_pos_encoding = PositionalEncoding(50, 512)\n",
        "\n",
        "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
        "plt.xlabel('Depth')\n",
        "plt.xlim((0, 512))\n",
        "plt.ylabel('Position')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oZUqX9Az1Ygn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "04fe21fd-eb88-4fb1-c37e-a52503368bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder Layer\n",
        "Each encoder layer consists of sublayers:\n",
        "\n",
        "\n",
        "\n",
        "1.   Multi-head attention (with padding mask)\n",
        "2.   2 dense layers followed by dropout\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RebwUoHx1cIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "    # Multi-head attention\n",
        "    attention = tf.keras.layers.MultiHeadAttention(\n",
        "        num_heads=num_heads, key_dim=d_model // num_heads, dropout=dropout\n",
        "    )(\n",
        "        query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
        "    )\n",
        "\n",
        "    # Add & normalize\n",
        "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "    attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "    # Feed-forward network\n",
        "    outputs = tf.keras.layers.Dense(units, activation=\"relu\")(attention)\n",
        "    outputs = tf.keras.layers.Dense(d_model)(outputs)\n",
        "\n",
        "    # Add & normalize\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "    return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "metadata": {
        "id": "tKaKMuTF1e4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_encoder_layer = encoder_layer(\n",
        "    units=512,\n",
        "    d_model=256,\n",
        "    num_heads=8,\n",
        "    dropout=0.1,\n",
        "    name=\"our_encoder_layer\")\n",
        "\n",
        "tf.keras.utils.plot_model(\n",
        "    sample_encoder_layer,\n",
        "    to_file='encoder_layer.png',\n",
        "    show_shapes=True,\n",
        "    show_layer_names=True,\n",
        "    rankdir='TB'  # Top to Bottom layout\n",
        ")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mikW8AbF1qoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder\n",
        "The Encoder consist of\n",
        "\n",
        "\n",
        "1.   Input Embedding\n",
        "2.   Positional Encoding\n",
        "3.   num_layers encoder layers\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BtCGXqCg10mK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder(vocab_size, num_layers, units, d_model, num_heads, dropout, name=\"encoder\"):\n",
        "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "    # Make sure we're using dense embeddings\n",
        "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "\n",
        "    # Add positional encoding\n",
        "    positional_encoding = PositionalEncoding(vocab_size, d_model)\n",
        "    outputs = positional_encoding(embeddings)\n",
        "\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "\n",
        "    # Stack encoder layers\n",
        "    for i in range(num_layers):\n",
        "        enc_layer = encoder_layer(\n",
        "            units=units,\n",
        "            d_model=d_model,\n",
        "            num_heads=num_heads,\n",
        "            dropout=dropout,\n",
        "            name=f\"encoder_layer_{i}\"\n",
        "        )\n",
        "        outputs = enc_layer([outputs, padding_mask])\n",
        "\n",
        "    return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "metadata": {
        "id": "MMxDuKNT15d0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_encoder = encoder(\n",
        "    vocab_size=8515,\n",
        "    num_layers=2,\n",
        "    units=512,\n",
        "    d_model=256,\n",
        "    num_heads=8,\n",
        "    dropout=0.1,\n",
        "    name=\"our_encoder\")\n",
        "\n",
        "tf.keras.utils.plot_model(\n",
        "   sample_encoder, to_file='encoder.png', show_shapes=True)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "R41uQ8G22FU7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85ca8689-613f-4681-b320-a4e632d0f0de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decoder Layer\n",
        "\n",
        "\n",
        "1.  Masked multi-head attention (with look ahead mask and padding mask)\n",
        "\n",
        "2.  Multi-head attention (with padding mask). value and key receive the encoder output as inputs. query receives the output from the masked multi-head attention sublayer.\n",
        "3. 2 dense layers followed by dropout\n",
        "\n"
      ],
      "metadata": {
        "id": "S1-LYJg23l4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "      })\n",
        "  attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1,\n",
        "          'key': enc_outputs,\n",
        "          'value': enc_outputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "metadata": {
        "id": "g8PuSdSJ37j6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_decoder_layer = decoder_layer(\n",
        "    units=512,\n",
        "    d_model=256,\n",
        "    num_heads=8,\n",
        "    dropout=0.1,\n",
        "    name=\"our_decoder_layer\")\n",
        "\n",
        "tf.keras.utils.plot_model(\n",
        "    sample_decoder_layer, to_file='decoder_layer.png', show_shapes=True)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "iIGYarSx4L9O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34f4f7a1-1b97-44a6-cbcb-fea0e8f2e704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From D:\\skripsi-sultin\\source\\final\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:219: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "Query shape: (None, 8, None, 32)\n",
            "Key shape: (None, 8, None, 32)\n",
            "Value shape: (None, 8, None, 32)\n",
            "\n",
            "Q × Kᵀ shape: (None, 8, None, None)\n",
            "Scaled logits shape: (None, 8, None, None)\n",
            "Applied mask.\n",
            "Attention weights shape: (None, 8, None, None)\n",
            "Final output shape: (None, 8, None, 32)\n",
            "Query shape: (None, 8, None, 32)\n",
            "Key shape: (None, 8, None, 32)\n",
            "Value shape: (None, 8, None, 32)\n",
            "\n",
            "Q × Kᵀ shape: (None, 8, None, None)\n",
            "Scaled logits shape: (None, 8, None, None)\n",
            "Applied mask.\n",
            "Attention weights shape: (None, 8, None, None)\n",
            "Final output shape: (None, 8, None, 32)\n",
            "Query shape: (None, 8, None, 32)\n",
            "Key shape: (None, 8, None, 32)\n",
            "Value shape: (None, 8, None, 32)\n",
            "\n",
            "Q × Kᵀ shape: (None, 8, None, None)\n",
            "Scaled logits shape: (None, 8, None, None)\n",
            "Applied mask.\n",
            "Attention weights shape: (None, 8, None, None)\n",
            "Final output shape: (None, 8, None, 32)\n",
            "Query shape: (None, 8, None, 32)\n",
            "Key shape: (None, 8, None, 32)\n",
            "Value shape: (None, 8, None, 32)\n",
            "\n",
            "Q × Kᵀ shape: (None, 8, None, None)\n",
            "Scaled logits shape: (None, 8, None, None)\n",
            "Applied mask.\n",
            "Attention weights shape: (None, 8, None, None)\n",
            "Final output shape: (None, 8, None, 32)\n",
            "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decoder\n",
        "\n",
        "\n",
        "1.   Output Embedding\n",
        "2.   Positional Encoding\n",
        "3.   N decoder layers\n",
        "\n"
      ],
      "metadata": {
        "id": "btfLCTsZ4Pd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name='decoder'):\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name='decoder_layer_{}'.format(i),\n",
        "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "metadata": {
        "id": "fXOyYjpi4Y3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_decoder = decoder(\n",
        "    vocab_size=8515,\n",
        "    num_layers=2,\n",
        "    units=512,\n",
        "    d_model=256,\n",
        "    num_heads=8,\n",
        "    dropout=0.1,\n",
        "    name=\"our_decoder\")\n",
        "\n",
        "tf.keras.utils.plot_model(\n",
        "    sample_decoder, to_file='decoder.png', show_shapes=True)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "OrvBJNBK4Zx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformers\n",
        "Transformer consists of the encoder, decoder and a final linear layer. The output of the decoder is the input to the linear layer and its output is returned."
      ],
      "metadata": {
        "id": "4tUScI0_4eJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "  # mask the future tokens for decoder inputs at the 1st attention block\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "  # mask the encoder outputs for the 2nd attention block\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "\n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs={'inputs': inputs, 'dec_inputs': dec_inputs}, outputs=outputs, name=name)"
      ],
      "metadata": {
        "id": "WHsYoT_74kI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_transformer = transformer(\n",
        "    vocab_size=8515,\n",
        "    num_layers=2,\n",
        "    units=512,\n",
        "    d_model=256,\n",
        "    num_heads=8,\n",
        "    dropout=0.1,\n",
        "    name=\"our_transformer\")\n",
        "\n",
        "tf.keras.utils.plot_model(\n",
        "    sample_transformer, to_file='transformer.png', show_shapes=True)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "V3ioUDDb4nDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model\n",
        "Initialize model"
      ],
      "metadata": {
        "id": "cORQT0lh4-Wo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loss function**\n",
        "Since the target sequences are padded, it is important to apply a padding mask when calculating the loss.\n"
      ],
      "metadata": {
        "id": "yyK_cwhK5KhU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  # Reshapes y_true (true labels) to match the shape of y_pred.\n",
        "    y_true = tf.reshape(y_true, shape=(-1, MAX_SENTENCE_LENGTH - 1))\n",
        "\n",
        "  # Computes the cross-entropy loss for each token\n",
        "  # reduction='none' means we’ll compute individual losses for each token without averaging.\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "  # Creates a mask for non-padding tokens.\n",
        "  # Padding tokens (0) are ignored.\n",
        "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "    loss = tf.multiply(loss, mask)\n",
        "  # Averages all the non-zero losses into a single scalar value.\n",
        "    return tf.reduce_mean(loss)"
      ],
      "metadata": {
        "id": "zNrePok35OVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom learning rate\n",
        "Use the Adam optimizer with a custom learning rate scheduler"
      ],
      "metadata": {
        "id": "PEjx_DWC5dbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=2000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    # Cast 'step' to tf.float32 before applying tf.math.rsqrt\n",
        "    step = tf.cast(step, tf.float32)\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "metadata": {
        "id": "aC0Zkf3F5jRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_learning_rate = CustomSchedule(d_model=256)\n",
        "\n",
        "plt.plot(sample_learning_rate(tf.range(3768, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")\n"
      ],
      "metadata": {
        "id": "XC8Zy0Aw5lH8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "62b8f11d-7612-4a10-e8e9-14373035377c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Step')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlEAAAGwCAYAAACJjDBkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAYe9JREFUeJzt3QlYVFX/B/Cv7JuAiCwiCCqKC4IbLrmmpWWmlormv8x8s3p9XVLLJZXqtTSXcsky26zeCrVMyy0VLXfcwAUVN1REAQFZlf3+n3NsJiYRAcE7y/fzPOPM3Dkzcy4g8+Xcc363hqIoCoiIiIioQswq1pyIiIiIBIYoIiIiokpgiCIiIiKqBIYoIiIiokpgiCIiIiKqBIYoIiIiokpgiCIiIiKqBIvKPInKp7i4GNeuXUPNmjVRo0YNtbtDRERE5SBKaGZlZaFu3bowM7v3eBNDVDUSAcrb21vtbhAREVElxMfHo169evd8nCGqGokRKM03wdHRUe3uEBERUTlkZmbKQRDN5/i9MERVI80hPBGgGKKIiIgMy/2m4nBiOREREVElMEQRERERVQJDFBEREVElMEQRERERVQJDFBEREVElMEQRERERVQJDFBEREVElMEQRERERVQJDFBEREVElMEQRERERGWKIWrZsGXx9fWFjY4P27dvj4MGDZbZfs2YNAgICZPvAwEBs2rTprjMvz5o1C56enrC1tUWvXr1w7tw5nTbvvfceOnXqBDs7Ozg7O5f5fqmpqfLkg6L0e3p6+gPsKRERERkTVUPUqlWrMHHiRISFheHo0aMICgpC7969kZycXGr7ffv2YdiwYRg1ahSioqIwYMAAeTl58qS2zbx587BkyRIsX74ckZGRsLe3l6+Zm5urbZOfn4/Bgwfjtddeu28fxXu1bNmyivaYiIiIjEUNRQzdqESMPLVr1w4ff/yxvF9cXCzPmjx27FhMnTr1rvahoaHIycnBhg0btNs6dOiA4OBgGZrErtStWxeTJk3C5MmT5eMZGRlwd3fHypUrMXToUJ3XE9smTJhwzxGmTz/9VAY9MbLVs2dP3Lx5s8yRq7y8PHn551mgRR94AmIiEnILimBjaa52N4ioDOLz28nJ6b6f36qNRInRoCNHjsjDbdrOmJnJ+/v37y/1OWJ7yfaCGGXStI+Li0NiYqJOG/FFEGHtXq95L6dOncK7776Lb7/9VvarPObMmSPfT3MRAYqISOOTP86j6awtmBAehYxbBWp3h4gekGohKiUlBUVFRXKUqCRxXwSh0ojtZbXXXFfkNUsjRpPEYcP58+fDx8en3M+bNm2aTK2aS3x8fLmfS0TG7WBcGhb8Hgsx9r8u+hp6L9qFXWdvqN0tIjLkieX6SIShpk2b4v/+7/8q9Dxra2s57FfyQkSUcbsAr6+KRrEC9GhSB36u9kjMzMULXx3EjHUncCu/UO0uEpEhhShXV1eYm5sjKSlJZ7u47+HhUepzxPay2muuK/KapdmxY4dcBWhhYSEvYj6Ups9iEjwRUUXMWn8SCem34eNih6XPtcbGcZ0xomN9+dj/DlzBE4t348jlNLW7SUSGEqKsrKzQpk0bREREaLeJieXifseOHUt9jthesr2wbds2bXs/Pz8Zlkq2EZPDxCq9e71maX7++WccO3YM0dHR8vLFF1/I7bt378aYMWMqvK9EZLp+ibqK9dHXYG5WA4uGBsPB2gJ2VhZ4p38L/G9Ue3g62eBy6i0MXr4fczefQV5hkdpdJqJysoCKRHmDESNGoG3btggJCcGiRYvk6ruRI0fKx1944QV4eXnJCdvC+PHj0a1bNyxcuBB9+/ZFeHg4Dh8+jBUrVsjHRS0nsdpu9uzZ8Pf3l6Fq5syZcsWeKIWgceXKFaSlpclrMS9LBCWhUaNGcHBwQMOGDe+avyWIQ3z3qytFRKQRn3YLM9fFyNvje/qjtU8tncc7+7tiy4SuePe3U/j56FUs//MC/ohNxoLBQWjh5aRSr4nIIEKUKFlw48YNWUJATPwWpQq2bNminRguQk7JlXGiQOYPP/yAGTNmYPr06TIorVu3Di1atNC2efPNN2UQGz16tCxd0LlzZ/maojinhni/b775Rnu/VatW8nrnzp3o3r37Q9p7IjJmhUXFGB8ehey8QrTzrYUxPRqV2s7J1hILhwTh8ebumL72BM4kZqH/sr14pWsDjOvpz3IIRHpM1TpRxq68dSaIyPgs2n4Wi7afQ01rC2wa3wXeLnb3fU5Kdh7Cfo3BxuPX5f2Gdewxb1BLtKnv8hB6TEQGUyeKiMhYiUniSyLunG5q9sAW5QpQgquDNZY91xqfPd8GdWpa48KNHAxavh9v/xqDnDyu4CPSNwxRRERVKCu3ABP+KmcwsJUX+gd7Vfg1ejf3wPbXu2Fwm3qyrtTKfZdkXand51hXikifMEQREVWhsPUxiE+7jXq1bPFO/+aVfh0nO0vMHxyEb18KgZezLa7evI3nvzyIN386xmrnRHqCIYqIqIqsj07A2qgEmNUAFg8NhqON5QO/ZtfGdbD19a54sZMvatQAVh++ip4f/iHfi1NaidTFEEVEVEXlDGb8clLeHvuof5VOBre3tsDbTzfH6lc6ysnmKdn5GB8eLSueX0rJqbL3IaKKYYgiInpARcUKJq6ORlZeIVr7OGPso6WXM3hQ7Xxd5Eq/SY81hpWFGXafS8Hji3bJSews0kn08DFEERE9oE92nsehSzdlNfJFoa1gYV59v1qtLcwxtqc/tk7oii7+rsgvLMaH287iycW7sf9CarW9LxHdjSGKiOgBRF25iUV/lTN4t39z+NQuXzmDB+Xrai8nnYu5V6I0giiHMOzzA5i0+hjScvIfSh+ITB1DFBFRJYlq5GJukjic93RQXVnS4GESp7oSJRQiJnXD8PY+cuK5OH3Mowv/wP8OXJb9IqLqwxBFRFRJogjmlbRbsgTBfwe0kKFGDeLUMe8NDMTPr3VCgEdNpN8qwIx1J/H0x3tw+FKaKn0iMgUMUURElbDh+DX8dOSqLGfwUWiwDDJqEyc43jC2M97u1wyONhaIuZYpK55PXBWN5MxctbtHZHQYooiIKigh/bY8WbAgTiwc4qc/57YTk9pffMQPOyd3x9B23vIQn6hd9ejCP7Fi1wU5EZ2IqgZDFBFRRcsZrIpGZm4hgr2dMa6nP/RRbQdrzH22Jdb9+xEEeTvL+VvvbzqDJxbz9DFEVYUhioioApb/eQGRcWmwtzKXK+Msq7GcQVUQAeqX1zph3qCWcHWwkqv4xOljRn97mIU6iR6Qfv/vJyLSI8fi0/HRtrPytqggXr+2PQyBmVkNDGnrjYhJ3fHSI34wN6uBraeS8NhHf+K/G07xXHxElcQQRURUDjl5hZiwKhqFxQr6BnpiUJt6MDRi8vusfs2weXwXdG9SBwVFCr7cE4duC3bi671xKCjifCmiimCIIiIqh3d/O4W4lBx4Otng/YGBqpUzqAqN3Wti5cgQfPNSCBq7O8iSCO/8dgq9P9qFbaeSeGJjonJiiCIiuo/NJ65j1eF4udJNljOwU7+cQVXo1rgONo3rIkOhmC91MSUHL397GM99HomTCRlqd49I7zFEERGV4XrGbUz9q5zBa90aokOD2jAmoiTCc+19ZEmEf3dvKE9svP9iKvp9vAeT1xzDtfTbaneRSG8xRBER3UOxLGdwDBm3C9CynhMm9GoMY1XTxhJv9gnAjknd5ClsxBE9UUy0+4I/8P6m00i/xfPxEf0TQxQR0T18vvuiHJWxtTTHotBgOUpj7OrVssOSYa3wy787ob2fiyzOuWLXRXSZtxPLdp7H7fwitbtIpDeM/zcCEVEliDlBC7bGyttvP90MDeo4wJS08qmF8NEd8PXIdvJ8fFm5hZj/eyy6zd+J7yMvcyUfEUMUEdHdbuUXYlx4lCwB0Ke5h6yxZIrECsQeTdzk5POPQoNQr5YtkrPy8NYvJ+VKvk0nrnMlH5m0Ggr/B1SbzMxMODk5ISMjA46Ojmp3h4jKadraE/jx4BV4ONpgy4QucLazUrtLeiGvsAg/RF7BxzvOIzXnzhwpMVds8uNN0MXf1aDLPhBV5vObIaoaMUQRGZ7fYxLxyndHZDmD70e1R6dGrmp3Se+I8/B9vusivth9ETl/zZFq51sLrz/WGJ0a8utFho8hSg8wRBEZlqTMXPRZtAs3bxXgla4NMO3Jpmp3Sa+lZOfhk50X8L/Iy3ICutCxQW1MfLwx2vm6qN09okpjiNIDDFFEhlXO4IWvDmLP+RS08HLE2tceMYnVeFUVPsXKvfCD8cj/a8K5OLwnRqZa+9RSu3tEFcYQpQcYoogMhzg0NXvjadhYmmHD2C5o5GZaq/GqQkL6bTlfas3heHmOQaFHkzqY+FgTBNZzUrt7ROXGEKUHGKKIDEPMtQwMXLZPjqKIU6CICt5UefFpt7Ak4hzWRiWg6K8w9Vgzd4x71J9higwCQ5QeYIgi0n+ieKQ4xcn55Gz5Qb/i+TZcZVZFxAmbRZhaF50gK6AL3ZvUwdhHG6FNfc6ZIv3FEKUHGKKI9N/MdSfx3YHLcKtpjS0TusLFnuUMqtr55Cws23kB66MT8NfAlJyAPrZnI3nN0Er6hiFKDzBEEem37aeS8K9vD8vb340KQRf/Omp3yahdSsnBp39cwM9Hr2rnTLWpXwv/ebQRujeuwzBFeoMhSg8wRBHpr+QsUc5gN9Jy8vGvzn6Y8VQztbtkUhPQP/vzAsIPxWtLIwR6Ockw9VhTd5iZMUyRuhii9ABDFJH+ljN4ceUh7Dp7A009HbFuTCdYW5ir3S2Tk5yZK09u/H3kFdwuuFO0s4l7TbzavQGealkXluYsMUHqYIjSAwxRRPrpqz1xeHfDKVhbiHIGneHvXlPtLpm01Ow8fLU3Dt/suyyroQtezrYY1dkPoe28YW9toXYXycRkMkSpjyGKSP+cvp6J/h/vleUM/tu/OZ7v6Kt2l+gvGbcKZPXzr/fGISX7zrn5nGwt8ULH+hjRyReuDtZqd5FMBEOUHmCIItIvuQVFePrjPTiblI2eAW74YkRbTmbW0+/T2qMJ+Hz3RVkmQRCjhoPa1MPLXRrA19Ve7S6Skcss5+e36gecly1bBl9fX9jY2KB9+/Y4ePBgme3XrFmDgIAA2T4wMBCbNm3SeVxkwlmzZsHT0xO2trbo1asXzp07p9PmvffeQ6dOnWBnZwdnZ+e73uPYsWMYNmwYvL295Ws0bdoUixcvrqI9JiK1zN18RgYoMaLxwaCWDFB6ysbSXBY83T6xG5b/X2sEeTsjr7BYzp3qsfAP/Pv7IzgWn652N4nUDVGrVq3CxIkTERYWhqNHjyIoKAi9e/dGcnJyqe337dsnw82oUaMQFRWFAQMGyMvJkye1bebNm4clS5Zg+fLliIyMhL29vXzN3NxcbZv8/HwMHjwYr732Wqnvc+TIEbi5ueF///sfYmJi8NZbb2HatGn4+OOPq+GrQEQPw84zyVi575K8vWBwSx4aMgDmZjXQp4Un1v27E1aN7oBHA9xk0c5NJxLRf9lehH62H7/HJGqrohM9bKoezhMjT+3atdOGk+LiYjn6M3bsWEydOvWu9qGhocjJycGGDRu02zp06IDg4GAZmsSu1K1bF5MmTcLkyZPl42Iozt3dHStXrsTQoUN1Xk9smzBhAtLT7/8XzZgxY3D69Gns2LHjnm3y8vLkpeRwoNgfHs4jUteNrDw8sXiXnGcz8hFfhPVrrnaXqJJiE7Pw2a4L+DX6mrbWVP3adnixky8Gt/WGAyehkykczhOjQWLERxxu03bGzEze379/f6nPEdtLthfEKJOmfVxcHBITE3XaiC+CCGv3es3yEl9IF5eyT1MwZ84c+X6aiwhQRKQu8cfVmz8dkwEqwKMmpvQJULtL9ACaeNTEh0OCsXtKD7zWvaGceH459Rbe+e0UOr4fgf9uOCXP3Uf0MKgWolJSUlBUVCRHiUoS90UQKo3YXlZ7zXVFXrM8xGFEcehx9OjRZbYTh/xE2NJc4uPjK/2eRFQ1vt1/GTtjb8DKwgyLh7aS823I8Hk62cpAvH/ao5g9oAUa1LFHVl4hvtwTh27zd+LV747g0KU0GaKJqgvHPe9DzLfq37+/nLf1+OOPl9nW2tpaXohIP5xNysJ7m07L29OfCJCjGGRc7Kws8H8d6uO5EB/sOndDhqjd51KwJSZRXkQl9Jc6+6JvYF0ZpImqkmo/Ua6urjA3N0dSUpLOdnHfw8Oj1OeI7WW111xX5DXLcurUKfTs2VOOQM2YMaPCzycidZfJj/sxSp5WpEeTOrLOEBkvcaqY7k3c8N2o9tj6elcMC/GRZRFOJGTg9VXH8MgHO/Dh1lhcz7itdlfJiKgWoqysrNCmTRtERERot4mJ5eJ+x44dS32O2F6yvbBt2zZtez8/PxmWSrYRk8PEKr17vea9iFV5PXr0wIgRI2RJBCIyLPO2xOJMYhZq21th3qAgljMwIY3da2LOM4HYP60n3ujdBG41reXigiU7zqPzB3cO9e07n8JDfWTYh/NEeQMRUtq2bYuQkBAsWrRIrr4bOXKkfPyFF16Al5eXnLAtjB8/Ht26dcPChQvRt29fhIeH4/Dhw1ixYoV8XPySFKvtZs+eDX9/fxmqZs6cKVfsiVIIGleuXEFaWpq8FvOyoqOj5fZGjRrBwcFBHsJ79NFH5aR10UfNfCoxclanDs/yTqTv/jx7Q55GRJg/uCXq1ORhdlPkYm+FMT0aYXTXBrIUwnf7LyMyLk17qK+RmwOe71Afz7T2Qk0bS7W7S4ZIUdnSpUsVHx8fxcrKSgkJCVEOHDigfaxbt27KiBEjdNqvXr1aady4sWzfvHlzZePGjTqPFxcXKzNnzlTc3d0Va2trpWfPnkpsbKxOG/GaYtf/edm5c6d8PCwsrNTH69evX6F9y8jIkM8T10T0cKRk5SptZ29T6k/ZoMxad0Lt7pCeOXM9U3nrl+NK05mb5c+IuDSbuVlui03MVLt7pCfK+/nN075UI572hejhEr/OXv72MLafTkZjdwf8+p/OXI1HpcrKLZCnlvl2/yVcuHHn1DJCez8XPN+xPh5v5sGJ6CYsk+fOUx9DFNHD9b8DlzFj3UlYmZth/X8eQVNP/r+jsomPwP0XUvHdgcvYeipJW/3c1cEKz7aph6HtfODHc/WZnEyGKPUxRBE9POeTs/DU0j3ILSjGzKeaYVRnP7W7RAZGrNz7MfIKwg/FIznr77NPdGxQG8Pa+6B3c3dYW3Bk0xRkMkSpjyGK6OHIKyzCwGX7cOp6Jrr4u+KbkSFyyTtRZRQWFWPHmWT8ePAK/jh7Q56vT6hlZ4lnW9fD0BAfOSmdjBdDlB5giCJ6ON7beAqf746Tq7G2jO8CN0cbtbtERiIh/TZWH4rH6sPxuJ7x94nsQ3xdMKy9N55o4cl5d0aIIUoPMEQRVb8951Lwf19Gytufv9AWjzXTPe0TUVUQc6X+PJuMHyLjsTM2WTt3ytHGAs+0rofBbeuheV0ntbtJVYQhSg8wRBFVr5s5+ei9aJecv/J/HXwwe0Cg2l0iE5CYkYs1h+Pl3CkxUqXRzNMRg9rUQ//guqjtwNpkhowhSg8wRBFVH/Gr65XvjsgVVQ3r2GPD2C6wteJhFXp4iosV7D6fIg/1bYtJQn5RsdxuaV4Djwa4YVAbb3RvUgeW5iyVYKyf3zwBMREZJDEKIAKU+MBaPLQVAxQ9dGLxQrfGdeQl/VY+fjt2DWuOXMXxqxn4PSZJXkSphAHBXhjc1psnwDZCHImqRhyJIqoeF25k46kle3C7oAhvPdkUL3dtoHaXiLRiE7Pw05F4/BKVgJTsfO32QC8nOXfq6aC6cLazUrWPVDYeztMDDFFEVS+/sBjPfLoXJxMy0bmRK759ieUMSD8VFBXjz9gb+OnIVUScSUJB0Z2PW1EMVhzuG9DKCz0C6rD2lB5iiNIDDFFEVW/u5jNY/ucFONtZ4vcJXeHOcgZkANJy8rE+OgFrDl+V9cw0xOq+vi095SG/dr4u/INATzBE6QGGKKKqte9CCoZ/ESmLHy7/vzbo08JD7S4RVdipa5kyUK2PvobEzL9rT3k528qVfWKEqrE750+piSFKDzBEEVUdMXG3z6Ld8kNnWIg35jzTUu0uET0QUWsqMi4V66ISsPlEIrLyCnXKJQxs5YWng+tytFUFDFF6gCGKqGqIX1P//v4oNp9MRANXe2wY1xl2VlxcTMYjt6BInmpGTEb/IzZZO3+qRg2gU8Pa6B/shd7NPeBka6l2V01CJkOU+hiiiKqGOO3Gmz8fh4VZDfzy70cQWI+Vocm4R103nrguR6gOXbqp3S4mpHdt7Ip+QXXRs6k7HKz5h0R1YYjSAwxRRA8uLiUHfZfsxq38IkzpE4DXujdUu0tED0182i05f+rXY9dwNilbu93a4s4Kv6da1pXXrJNWtRii9ABDFNGDLxEf9Ok+HLuagY4NauP7f7Xn6iUyWWeTsrDh2DVsOH4dF1NytNvtrMzlyNRTLT1l4U+eEPnBMUTpAYYoogcz//czWLbzgpwHsmVCF3g62ardJSLViY/tmGuZMkxtOH4NV2/+ff6+mtYW8iTcTwV5onOjOrCy4ClnKoMhSg8wRBFV3oGLqRj2+QFZzuDT4a3xRKCn2l0i0jviI1yM1IoRKjGP6nrG3yUTxB8fIlA90cIDnf1dWdSzAhii9ABDFFHlZNwqwBOLd+FaRi6GtK2HeYOC1O4SkUGcEPnolZtyhEoEqhtZedrHxCT0HgFuMlCJkyJzdWvZGKL0AEMUUcWJX0n/+TEKG49fh29tO2wc1wX2XIVEVOEaVIcupWHLyUR5KVnUU0xKF3Onngj0wKMB7iybUAqGKD3AEEVUceI8Y5PXHJPlDH5+rROCvJ3V7hKRwY9QRV9Nl2Fq88nriE/7ew6VpXkNdGroKkeoxKG/2g7WqvZVXzBE6QGGKKKKuZyagycX70ZOfhHe6N0EY3o0UrtLREZFfOSLc/fdCVSJOJ/8d9kEsfC1vV9teTqlx5u7m/RCjkyGKPUxRBFVrJzB4OX7ER2fjhA/F/z4cgeYs5wBUbU6n5ylDVRixV9JgV5O6NXUXY5QNfWsiRqifLqJyGSIUh9DFFH5fbg1Fkt2nEdNGwtsmdBVnoyViB6eK6m38HtMIrbEJMoJ6iXTgfj/KMKUCFXijxxjL52QyRClPoYoovIRE2BDP9uPYgVYOqyVPK0FEalHrOzbeSYZW08lYc/5G8gtKNY+Jv7Q6d7EDb2auslrY5yYzhClBxiiiO4v43aBnAeVkH4bz7auh4VDWM6ASJ/czi/CnvMp2H4qCRFnkpCSna99zMKsBto3cMFjTd1l1XRvFzsYA4YoPcAQRXR/48OjsD76Gnxc7LBpfBeeVJVIz0sniHmL208nYdupJJ2J6UKAR015Lj9Rk6qVtzMszA3zsB9DlB5giCIq2y9RV/H6qmNyAvmaVzuitU8ttbtERBU8Qfj2U0nYdjoJhy+lyUPyGuIwn6hH1SOgDro1doOLvRUMBUOUHmCIIir77PRPLN6N7LxCTHysMcb19Fe7S0T0ANJy8rHr7A3sOJOMP8/ekIfqNcTCvmBvZzza5M4oVfO6jnq92o8hSg8wRBGVrrCoGKErDuDI5ZtoW78Wwkd3MNhhfyIq/f+4OOwnAtXO2Bs4fV23fIJbTWt5+hlx6O+RRq6oaaNfk9MZovQAQxRR6RZtP4tF28/JM86LeVDGMhmViEp3PeM2/oi9M0q193wKbuUX6VRNb+frgh5N3NC1cR00dndQfZSKIUoPMEQR3e3I5TRZVFPMnVg8NBj9g73U7hIRPUR5hUU4GJeGnWduYGdsspxXVZKHow26+LvKQNW5kStqqTCXiiFKDzBEEenKyi3Ak0t2y3N3DWzlhY9Cg9XuEhGpLC4lR9akEvOoDlxMRV7h3zWpxIBUy3rO6PZXqBLzqh7GoX+GKD3AEEWka+KqaKyNSkC9WrbyMJ6jns2DICJ15RYUyeK7YoL6rrMpiE3K0nlcFPp8pOGdQNW1sSvq1aqeqQAMUXqAIYrob+ujEzA+PFqe5HT1Kx3R1tdF7S4RkZ5LzMjFrnMiUN2QBT/Tb/294k9oUMce34wMqfJ5leX9/GZVOyKqdldv3sKMdSfl7bGP+jNAEVG5eDjZYEhbb3kRhT5PJGT8NUp1A1Hx6fL0NJ5ONlCL6muKly1bBl9fX9jY2KB9+/Y4ePBgme3XrFmDgIAA2T4wMBCbNm3SeVwMrM2aNQuenp6wtbVFr169cO7cOZ027733Hjp16gQ7Ozs4OzuX+j5XrlxB3759ZRs3Nze88cYbKCwsrII9JjIt4hff66uikZVbiNY+zhj7aCO1u0REBsjcrIacEyVqyv30WiccnfkYvnkpRNXyKKqGqFWrVmHixIkICwvD0aNHERQUhN69eyM5ObnU9vv27cOwYcMwatQoREVFYcCAAfJy8uSdv3CFefPmYcmSJVi+fDkiIyNhb28vXzM3N1fbJj8/H4MHD8Zrr71W6vsUFRXJACXaiff85ptvsHLlShnOiKhiPtl5Hocu3ZSnc1kU2or1oIioSoiK6Kqf5UBRUUhIiDJmzBjt/aKiIqVu3brKnDlzSm0/ZMgQpW/fvjrb2rdvr7zyyivydnFxseLh4aHMnz9f+3h6erpibW2t/Pjjj3e93tdff604OTndtX3Tpk2KmZmZkpiYqN326aefKo6OjkpeXl659y8jI0PMN5PXRKbo6OU0pcG0jUr9KRuUn4/Eq90dIqIq/fxW7U9CMcpz5MgRebhNw8zMTN7fv39/qc8R20u2F8Qok6Z9XFwcEhMTddqIiWHiMOG9XvNe7yMOFbq7u+u8j5hoFhMTc8/n5eXlyTYlL0SmSpzOZcKqaHk4r19QXVnSgIjImKgWolJSUuRhs5JBRRD3RRAqjdheVnvNdUVesyLvU/I9SjNnzhwZ2jQXb2/vcr8nkbF5+9cYXE69BS9nW8we0EL1CsRERFWNkxOq0LRp0+RySM0lPj5e7S4RqWLD8Wv46chVWc5AFNQUcxeIiIyNaiHK1dUV5ubmSEpK0tku7nt4eJT6HLG9rPaa64q8ZkXep+R7lMba2lrWkyh5ITI1Cem3MX3tCXl7TI9GCPFjOQMiMk6qhSgrKyu0adMGERER2m3FxcXyfseOHUt9jthesr2wbds2bXs/Pz8Zckq2EfOSxCq9e73mvd7nxIkTOqsExfuIUNSsWbMK7SeRKRHzn0RV8szcQgT9tRSZiMhYqVpsU5Q3GDFiBNq2bYuQkBAsWrQIOTk5GDlypHz8hRdegJeXl5xrJIwfPx7dunXDwoULZQmC8PBwHD58GCtWrJCPizkXEyZMwOzZs+Hv7y9D1cyZM1G3bl1ZCqFkDai0tDR5LeZlRUdHy+2NGjWCg4MDHn/8cRmWnn/+eVkyQcyDmjFjBsaMGSNHm4iodJ/tuoDIuDTYW5ljcWgwLFnOgIiMmaKypUuXKj4+PoqVlZUseXDgwAHtY926dVNGjBih03716tVK48aNZfvmzZsrGzdu1HlclDmYOXOm4u7uLksb9OzZU4mNjdVpI15T7Po/Lzt37tS2uXTpkvLEE08otra2iqurqzJp0iSloKCgQvvGEgdkSqKv3FQa/lXOYPWhK2p3h4io0sr7+c1z51UjnjuPTEVOXiGeWrpHno29b6AnPn6uFVfjEZHRf35zrJ2IHti7v52SAUqcw+r9gYEMUERkEhiiiOiBbD5xHasOx0Pkpg+HBMPJjuUMiMg0MEQRUaVdz7iNqX+VM3i1W0N0bFhb7S4RET00DFFEVCnFxQomrT6GjNsFaFnPCa/3aqx2l4iIHiqGKCKqlM93X8S+C6mwtTTHotBgWFnw1wkRmRb+1iOiCjuZkIEFW2Pl7befboYGdRzU7hIR0UPHEEVEFXIrvxDjwqNQUKSgT3MPDGnLE20TkWliiCKiCpm98TQu3siBh6MN5jzDcgZEZLoYooio3H6PScQPkVf+KmcQhFr2Vmp3iYhINQxRRFQuSZm5mPrzcXl7dJcG6NTIVe0uERGpiiGKiMpdzuDmrQK08HLEpMebqN0lIiLVMUQR0X19tTcOe86nwMbSDItCW7GcARERQxQR3U/MtQzM23KnnMHMp5qhkRvLGRARCQxRRHRPt/OLMD48GvlFxXismTueC/FRu0tERHqDIYqI7un9TadxPjkbbjWt8cGzLVnOgIioBIYoIirV9lNJ+O7AZXl74ZAguLCcARGRDoYoIrpLclYu3vyrnMG/Ovuhi38dtbtERKR3GKKI6K5yBpPXHEdaTj6aejrijT4sZ0BEVOUhKjc390GeTkR6aOW+S9h19gasLcywZGgwrC3M1e4SEZFxhKji4mL897//hZeXFxwcHHDx4kW5febMmfjyyy+ro49E9JCcvp6JuZvPyNsz+jaFv3tNtbtERGQ8IWr27NlYuXIl5s2bByurvyeatmjRAl988UVV94+IHpLcAlHOIEqWM+gZ4Ib/61Bf7S4RERlXiPr222+xYsUKDB8+HObmfw/zBwUF4cyZO3/BEpHhESNQZ5Oy4epgjQ8GsZwBEVGVh6iEhAQ0atSo1MN8BQUFFX05ItIDO88ky7lQwoLBLWWQIiKiKg5RzZo1w+7du+/a/tNPP6FVq1YVfTkiUtmNrDy88dMxeXvkI77o3sRN7S4RERkEi4o+YdasWRgxYoQckRKjT2vXrkVsbKw8zLdhw4bq6SURVQtFUfDmT8eQkp2PAI+amNInQO0uEREZ70hU//798dtvv2H79u2wt7eXoer06dNy22OPPVY9vSSiavHt/svYGXsDVhZmWDy0FWwsWc6AiKjaRqKELl26YNu2bZV5KhHpibNJWXhv02l5e/oTAWjiwXIGRETVOhLVoEEDpKam3rU9PT1dPkZEhlHOYNyPUcgvLEb3JnUwopOv2l0iIjL+EHXp0iUUFRXdtT0vL0/OkyIi/TdvSyzOJGahtr0V5g8KYjkDIqLqPJz366+/am///vvvcHJy0t4XoSoiIgK+vvxrlkjf/Xn2Br7aGydvzx/cEnVqspwBEVG1hqgBAwbIa/EXq1idV5KlpaUMUAsXLqxUJ4jo4UjNzsPkNXfKGYzoWB+PBrir3SUiIuMPUaKcgeDn54dDhw7B1dW1OvtFRNVQzmDKz8dlXSh/NwdMe7Kp2l0iIjKt1XlxcXcOAxCRYfk+8gq2n06GlbkZlgxjOQMiIlVKHOTk5ODPP//ElStXkJ+fr/PYuHHjHrhTRFS1zidnYfbGU/L2lCcC0NTTUe0uERGZXoiKiorCk08+iVu3bskw5eLigpSUFNjZ2cHNzY0hikjP5BWKcgbRyC0oRhd/V4xkOQMiInVKHLz++uvo168fbt68CVtbWxw4cACXL19GmzZtsGDBgqrpFRFVmYVbz+LU9Uy42Fth4eAgmJmxnAERkSohKjo6GpMmTYKZmRnMzc1lfShvb2/MmzcP06dPr5JOEVHV2HMuBSt2XZS3P3i2JdwcbdTuEhGR6YYoUc5ABChBHL4T86IEUTcqPj6+wh1YtmyZLI9gY2OD9u3b4+DBg2W2X7NmDQICAmT7wMBAbNq06a4VSOJ8fp6ennKkrFevXjh37pxOm7S0NAwfPhyOjo5wdnbGqFGjkJ2drdNG1MLq0KEDatasiTp16uDZZ5+VhUaJDMXNnHxMXB0tbw9v74PHmrGcARGRqiGqVatWssSB0K1bNxlYvv/+e0yYMAEtWrSo0GutWrUKEydORFhYGI4ePYqgoCD07t0bycnJpbbft28fhg0bJkOPmJslaleJy8mTJ7VtxIjYkiVLsHz5ckRGRsqTJIvXzM3N1bYRASomJkae/2/Dhg3YtWsXRo8erbMCUZxo+dFHH5UjbyJQiXlfzzzzTEW/XESqljNIzspDwzr2mNG3mdpdIiIyPkoFHTp0SNmxY4e8nZSUpPTu3VupWbOm0rp1ayUqKqpCrxUSEqKMGTNGe7+oqEipW7euMmfOnFLbDxkyROnbt6/Otvbt2yuvvPKKvF1cXKx4eHgo8+fP1z6enp6uWFtbKz/++KO8f+rUKUXsttgPjc2bNys1atRQEhIS5P01a9YoFhYWsj8av/76q2yTn59f7v3LyMiQ7yWuiR6mHyIvK/WnbFAaTd+onLiarnZ3iIgMSnk/vys8EtW2bVv06NFDezhvy5YtyMzMxJEjRxAcHFzu1xGlEcRzxOE2DXGYUNzfv39/qc8R20u2F8Qok6a9GEFKTEzUaSMOM4rDhJo24locwhP7oSHai/cWI1eCmCQv7n/99dfylDYZGRn47rvvZDtxOPNexPww8bUoeSF62C7cyMa7v90pZ/Bm7wC08Pr7FE1ERFR1Khyi7kUcjnvqqafK3V4cHhMBxd1dd56GuC+CUGnE9rLaa67v10aEv5IsLCxkqQZNG1GVfevWrXKivLW1tQxdV69exerVq8vcpzlz5sjQprmICfdED1N+YTEmhEfjdkERHmlUG6M6+6ndJSIio1WhECXmBk2ePFmGi4sX76z4OXPmjJyX1K5dO+2pYQydCFMvv/yyPEegmP8lCotaWVlh0KBBcq7JvUybNk2OWmkulZloT/QgPtx2FicSMuBsZ4mFg4NZzoCISB+KbX755ZcyWIgRG1Ej6osvvsCHH36IsWPHIjQ0VE7ubtq0/OfiEufeEyUSkpKSdLaL+x4eHqU+R2wvq73mWmwTq/NKttEcahRt/jlxvbCwUK7Y0zxfrBgUI0likrrG//73PzmyJA75iVV7pRGjVuJCpIZ9F1Lw2a4L8vbcZ1rCw4nlDIiI9GIkavHixfjggw/kYThxWEtcf/LJJzhx4oRcCVeRACWIkR0x9ygiIkK7TYxkifsdO3Ys9Tlie8n2glhhp2kvDsOJIFSyjZiXJIKPpo24Tk9Pl/OxNHbs2CHfW8ydEkQ1dk0ZBw0R+DR9JNI36bfyMXHVMYiB0mEh3ujTovQ/RIiIqAqVd6a6nZ2dEhcXp10FZ2lpqezZs+eBZr+Hh4fLlXMrV66Uq+ZGjx6tODs7K4mJifLx559/Xpk6daq2/d69e+WquQULFiinT59WwsLCZD9OnDihbTN37lz5GuvXr1eOHz+u9O/fX/Hz81Nu376tbdOnTx+lVatWSmRkpNwHf39/ZdiwYdrHIyIi5Eq8d955Rzl79qxy5MgRuQqxfv36yq1bt8q9f1ydRw+D+P/46neH5Wq8HvN3Kjl5BWp3iYjIoJX387vcIUqEClHSQMPBwUG5cOHCg/VSUZSlS5cqPj4+ipWVlSx5cODAAe1j3bp1U0aMGKHTfvXq1Urjxo1l++bNmysbN2686wNl5syZiru7uwxoPXv2VGJjY3XapKamytAk9sHR0VEZOXKkkpWVpdNGlEQQQcve3l6pU6eO8vTTT8vgVhEMUfQwrDp4RQaohtM2KsfjWc6AiOhBlffzu4b4pzwjVuLw1uzZs+Hg4CDvT5kyBW+88Yac21QST0AMnUOJYm6VmGQuqqMTVbW4lBz0XbIbt/KLMKVPAF7r3lDtLhERmcznd7lDlDg1S40aZa/0EY9rVu0RQxRVr4KiYgz6dB+OXc1Axwa18f2/2nM1HhHRQ/z8LvfqPJ43jki/LNp+VgYoJ1tLfBgaxABFRGSoxTaJ6OGJvJiKT/7QlDMIhKeTrdpdIiIyOQxRRAYm41YBXl8VLcsZDGlbD08E/l0TjYiIHh6GKCIDIqYwTl93AtcycuFb2w5h/Zqr3SUiIpPFEEVkQH4+moCNx6/DwqwGFg9tBXvrck9rJCKiKsYQRWQgLqfmIGz9SXn79ccaI8jbWe0uERGZNIvKLPu7V3kDcd44cToXIqr6cgbjw6ORk1+EED8XvNqN9aCIiAwuRDk7O5dZL6pevXp48cUXERYWdtf554iocpZGnEN0fDpq2ljgo9BgmLOcARGR4YWolStX4q233pJBKSQkRG47ePAgvvnmG8yYMQM3btzAggUL5KjU9OnTq6PPRCbl0KU0fLzzvLz9/sBAeDmznAERkUGGKBGWFi5ciCFDhmi39evXD4GBgfjss88QEREBHx8fvPfeewxRRA8o43YBJoRHo1gBnm1dD/2C6qrdJSIi+kuFj7ft27cPrVq1umu72LZ//355u3Pnzrhy5UpFX5qI/mHW+pNISL8NHxc7vNOf5QyIiAw6RHl7e+PLL7+8a7vYJh4TUlNTUatWrarpIZGJWheVgPXR1+T8p0VDg+HAcgZERHqlwr+VxXynwYMHY/PmzWjXrp3cdvjwYZw5cwY//fSTvH/o0CGEhoZWfW+JTER82i3MWHennMH4nv5o7cM/SoiI9E0NRZRArqC4uDg5/+ns2bPyfpMmTfDKK6/A19e3Ovpo9GeBJiqpsKgYoSsO4Mjlm2hbvxbCR3eAhTlXuhIR6dvnd6WOD/j5+WHu3LkP0j8iugexEk8EqJrWd8oZMEAREemnSoWo9PR0WdYgOTkZxcXFOo+98MILVdU3IpNz5HIalkSck7dnD2wBbxc7tbtERERVFaJ+++03DB8+HNnZ2XKIq2ThTXGbIYqocrJyCzBh1Z1yBgNbeaF/sJfaXSIiojJU+DjBpEmT8NJLL8kQJUakbt68qb2kpaVV9OWI6C9h62MQn3Yb9WrZspwBEZExhqiEhASMGzcOdnY8zEBUVdZHJ2BtVALE2VwWhQbD0cZS7S4REVFVh6jevXvLkgZEVDWu3vy7nMHYR/3R1tdF7S4REVF1zInq27cv3njjDZw6dUqe6sXSUvcv5qeffrqiL0lksoqKFby+KhpZuYVo7eOMsY82UrtLRERUXXWizMzuPXglJpYXFRVV5OWMGutE0f18vOMcFmw9K6uRbxrXBT61eZiciMho60T9s6QBEVVO1JWb+Gj7nXIG7/ZvzgBFRGRgWMWPSAXZeYWynIE4nNcvqK4saUBERIalXCNRS5YswejRo2FjYyNvl0Ws3COisr39awwup96Cl7MtZg9ooVNvjYiIjGhOlDjNi1iRV7t2bXn7ni9WowYuXrxY1X00WJwTRaXZcPwa/vNDlCxnED66I0L8uBqPiMho50SJEw6XdpuIKuZa+m1MX3tC3h7ToxEDFBGRAeOcKKKHXM4gM7cQQd7OGNfTX+0uERHRA6jw6jxRwmDlypWIiIgo9QTEO3bseJD+EBmtz3ZdQGRcGuytzLE4NBiW5vwbhojIpELU+PHjZYgSRTdbtOCEWKLyOBafjg+3npW33366OXxd7dXuEhERPewQFR4ejtWrV+PJJ5980PcmMgk5f5UzKCxW0DfQE4Pa1FO7S0REVAUqfDzBysoKjRrx1BRE5fXfDacQl5IDTycbvD8wkKO3RESmGqImTZqExYsXo4JniyEySZtPXEf4oXiI3PThkGA42emea5KIiEzocN6ePXuwc+dObN68Gc2bN7/rBMRr166tyv4RGazrGbcx9a9yBq92a4iODWur3SUiIlIzRDk7O2PgwIFV2Qcio1NcrGDS6mPIuF2AlvWc8Hqvxmp3iYiI1AxRhYWF6NGjBx5//HF4eHhUdV+IjMbnuy9i34VU2FqaY1FoMKwsWM6AiMjYVOg3u4WFBV599VXk5eVVWQeWLVsGX19feV6+9u3b4+DBg2W2X7NmDQICAmT7wMBAbNq0SedxMVdr1qxZ8PT0hK2tLXr16oVz587ptElLS8Pw4cNlKXcxsjZq1ChkZ2ff9ToLFixA48aNYW1tDS8vL7z33ntVtt9kvE4mZGDB1lh5++2nm6FBHQe1u0RERNWgwn8eh4SEICoqqkrefNWqVZg4cSLCwsJw9OhRBAUFoXfv3rKIZ2n27duHYcOGydAj+jBgwAB5OXnypLbNvHnz5EmSly9fjsjISNjb28vXzM3N1bYRASomJgbbtm3Dhg0bsGvXLnmC5X/Ww/riiy9kkDpz5gx+/fVXue9EZbmVX4hx4VEoKFLQp7kHhrT1VrtLRESk5gmISxI1oqZNm4bXX38dbdq0kSGlpJYtW5b7tcTIU7t27fDxxx/L+6L6ube3N8aOHYupU6fe1T40NBQ5OTky+Gh06NABwcHBMjSJXalbt65cQTh58mT5uDh5oLu7uywQOnToUJw+fRrNmjXDoUOH0LZtW9lmy5Ytsu7V1atX5fNFG7EfIpw1adIElcUTEJue6b+cwA+RV+DhaIPN47uglr2V2l0iIqJq+vyu8EiUCCLiJMTjxo3DI488IgNMq1attNfllZ+fjyNHjsjDbdrOmJnJ+/v37y/1OWJ7yfaCGGXStBf9SkxM1GkjvggirGnaiGtxCE8ToATRXry3GLkSfvvtNzRo0ECGNT8/P3m48V//+pc8DFgWcZhTfOFLXsh0/B6TKAPUnXIGQQxQRERGrsKr80RQqQopKSnyPHxilKgkcV8cPiuNCEiltRfbNY9rtpXVxs3N7a65Xi4uLto2Fy9exOXLl+X8q2+//Vb2U4y8DRo0qMxzA86ZMwfvvPNOBb4KZCySMnMx9efj8vboLg3QqZGr2l0iIiJ9C1H169eHsROHFcWokghQYmK58OWXX8rDl7Gxsfc8xCcOc4o5XhpiJEocniTjL2cwec0x3LxVgBZejpj0eOUPARMRkRGHKI1Tp07hypUr8rBcSU8//XS5nu/q6gpzc3MkJSXpbBf371U+QWwvq73mWmwTq/NKthGHGzVt/jlxXZRuEIfqNM8XzxWjU5oAJTRt2lRei32+V4gSq/jEhUzLV3vjsPtcCmwszbAotBXLGRARmYgK/7YXh7rEKroWLVqgb9++2hVyogBnRYpwinPwiZGdiIgInREgcb9jx46lPkdsL9leECvsNO3F/CURhEq2EaNBYq6Tpo24Tk9Pl/OxNMQhOvHeYu6UIOZ6iWB14cIFbZuzZ8+azEgclV/MtQzM23KnnMHMp5qhkRvLGRARmQylgp566imlf//+yo0bNxQHBwfl1KlTyu7du5WQkBBl165dFXqt8PBwxdraWlm5cqV8ndGjRyvOzs5KYmKifPz5559Xpk6dqm2/d+9excLCQlmwYIFy+vRpJSwsTLG0tFROnDihbTN37lz5GuvXr1eOHz8u++rn56fcvn1b26ZPnz5Kq1atlMjISGXPnj2Kv7+/MmzYMO3jRUVFSuvWrZWuXbsqR48eVQ4fPqy0b99eeeyxxyq0fxkZGWLlo7wm43Mrr1DpufAPpf6UDcq/vjmkFBcXq90lIiKqAuX9/K5wiKpdu7Zy7NgxedvR0VE5c+aMvB0REaEEBwdXuKNLly5VfHx8FCsrKxnEDhw4oH2sW7duyogRI3Tar169WmncuLFs37x5c2Xjxo06j4sPspkzZyru7u4yoPXs2VOJjY3VaZOamipDkwiBYh9GjhypZGVl6bRJSEhQnnnmGdlGvNaLL74on1cRDFHGbcYvJ2SAajd7m5Kanad2d4iIqIqU9/O7wnWiatWqJQtjikNnDRs2lAUpxalgxKEvUUH81q1b1TdsZmBYJ8p4RZxOwqhvDsvb340KQRf/Omp3iYiIHvLnd4Unlou5UMeOHZMhSswhEhXCxfymFStWyNpKRMYuOSsXb/x0p5zBvzr7MUAREZmoCoeoGTNmyKrhwrvvvounnnoKXbp0Qe3ateVpXIiMv5zBcaTl5KOppyPe6MNyBkREpqrCIUpUCNdo1KiRLIwpygOIw3w1RKlmIiO2ct8l7Dp7A9YWZlgyNBjWFuZqd4mIiFRS6YI258+fx++//47bt2/Lat9Exu709UzM3Xynmv6Mvk3h715T7S4REZEhhajU1FT07NlTFqIUJ+29fv263D5q1Ch54l8iY5RbUIQJ4dHILypGzwA3/F8H1gsjIjJ1FQ5R4hxylpaWsnK3nZ2ddntoaCi2bNlS1f0j0gtiBCo2KQuuDtb4YFBLHromIqKKz4naunWrPIxXr149ne3+/v7ypL1ExmbnmWQ5F0pYMLilDFJEREQVHokSK/NKjkBpiMnlPG8cGZsbWXl446dj8vbIR3zRvYmb2l0iIiJDDVGinMG3336rvS8Oa4jzzol6UaLoJpGxEHVo3/zpGFKy8xHgURNT+gSo3SUiIjLkw3kiLImJ5YcPH0Z+fj7efPNNxMTEyJGovXv3Vk8viVTw3YHL2Bl7A1YWZlg8tBVsLFnOgIiIHmAkSlQsP3v2LDp37oz+/fvLw3vPPPMMoqKi5GlgiIzB2aQsvLfxtLw9/YkANPFgOQMiInrAkShBnE/mrbfe0tl29epVjB49Wp7+hcjQyxmM+zEKeYXF6N6kDkZ08lW7S0REZEzFNkurH/Xll19W1csRqWbellicScxCbXsrzB8UxHIGRERUvSGKyBj8efYGvtobJ2/PH9wSdWpyxSkREZWOIYroL6nZeZi85k45gxEd6+PRAHe1u0RERHqMIYror3IGU34+LutC+bs5YNqTTdXuEhERGcvEcrECryzp6elV0R8iVXwfeQXbTyfDytwMS4axnAEREVVhiBIr8u73+AsvvFDelyPSG+eTszB74yl5e8oTAWjq6ah2l4iIyJhC1Ndff129PSFSQV6hKGcQjdyCYnTxd8VIljMgIqJy4pwoMmkLt57FqeuZcLG3wsLBQTAzYzkDIiIqH4YoMll7zqVgxa6L8vYHz7aEm6ON2l0iIiIDwhBFJulmTj4mro6Wt4e398FjzVjOgIiIKoYhiky2nEFyVh4a1rHHjL7N1O4SEREZIIYoMjnhh+Kx9VQSLM1rYPHQVrC1YjkDIiKqOIYoMikXbmTj3d/ulDN4s3cAWniVXbqDiIjoXhiiyGTkFxZjQng0bhcU4ZFGtTGqs5/aXSIiIgPGEEUm48NtZ3EiIQPOdpZYODiY5QyIiOiBMESRSdh3IQWf7bogb899piU8nFjOgIiIHgxDFBm99Fv5mLjqGBQFGBbijT4tPNTuEhERGQGGKDL6cgbT1p5AYmYuGrjaY+ZTLGdARERVgyGKjNqaw1ex+WQiLMzulDOwsyr36SKJiIjKxBBFRisuJQdv/xYjb096vAkC67GcARERVR2GKDJKBUWinEEUbuUXoWOD2nilawO1u0REREaGIYqM0qLtZ3HsagacbC3xYWgQyxkQEVGVY4gioxN5MRWf/KEpZxAITydbtbtERERGiCGKjErGrQK8vipaljMY0rYengj0VLtLRERkpBiiyKjKGUxfdwLXMnLhW9sOYf2aq90lIiIyYnoRopYtWwZfX1/Y2Nigffv2OHjwYJnt16xZg4CAANk+MDAQmzZtuuvDdNasWfD09IStrS169eqFc+fO6bRJS0vD8OHD4ejoCGdnZ4waNQrZ2dmlvt/58+dRs2ZN2Y7019qjCdh4/Lq2nIG9NcsZEBGREYeoVatWYeLEiQgLC8PRo0cRFBSE3r17Izk5udT2+/btw7Bhw2ToiYqKwoABA+Tl5MmT2jbz5s3DkiVLsHz5ckRGRsLe3l6+Zm5urraNCFAxMTHYtm0bNmzYgF27dmH06NF3vV9BQYF8vy5dulTTV4CqwuXUHMxaf+dn4PXHGiPIm4GXiIiqVw1FDNuoSIw8tWvXDh9//LG8X1xcDG9vb4wdOxZTp069q31oaChycnJk8NHo0KEDgoODZWgSu1O3bl1MmjQJkydPlo9nZGTA3d0dK1euxNChQ3H69Gk0a9YMhw4dQtu2bWWbLVu24Mknn8TVq1fl8zWmTJmCa9euoWfPnpgwYQLS09PLvW+ZmZlwcnKS7y9GvKj6yhkMXr4f0fHpCPFzwY8vd4A5V+MREVEllffzW9WRqPz8fBw5ckQebtN2yMxM3t+/f3+pzxHbS7YXxCiTpn1cXBwSExN12ogvhAhrmjbiWhya0wQoQbQX7y1GrjR27NghDx2Kw43lkZeXJ7/wJS9U/ZZGnJMBqqaNBT4KDWaAIiKih0LVEJWSkoKioiI5SlSSuC+CUGnE9rLaa67v18bNzU3ncQsLC7i4uGjbpKam4sUXX5SjV+UdRZozZ44MbJqLGFGj6nXoUho+3nle3n5/YCC8nFnOgIiITGROlL56+eWX8dxzz6Fr167lfs60adPk0J/mEh8fX619NHWZuQWYEB6NYgV4tnU99Av6+zAsERGRUYcoV1dXmJubIykpSWe7uO/h4VHqc8T2stprru/X5p8T1wsLC+WKPU0bcShvwYIFcoRKXMREdhGMxO2vvvqq1L5ZW1vLUauSF6o+M9edREL6bfi42OGd/ixnQEREJhSirKys0KZNG0RERGi3iYnl4n7Hjh1LfY7YXrK9IFbYadr7+fnJIFSyjZibJOY6adqIazFBXMzH0hChSby3mDulmTcVHR2tvbz77ruyzIG4PXDgwCr+SlBFrYtKwProa3L+06KhwXBgOQMiInrIVP/kEeUNRowYISd5h4SEYNGiRXL13ciRI+XjL7zwAry8vOR8I2H8+PHo1q0bFi5ciL59+yI8PByHDx/GihUr5OM1atSQq+hmz54Nf39/GapmzpwpV9yJUghC06ZN0adPH3nITqzoE2UM/vOf/8iVe5qVeaJNSeI9xMTzFi1aPOSvEP1TfNotzFh3p5zB+J7+aO1TS+0uERGRCVI9RImSBTdu3JDFMcWkblGqQJQb0EwMv3LligwvGp06dcIPP/yAGTNmYPr06TIorVu3TifcvPnmmzKIibpPYsSpc+fO8jVFcU6N77//XgYnUbpAvP6zzz4ra0uRfissKsaEVdHIzitE2/q18O/uDdXuEhERmSjV60QZM9aJqnqLt5/DR9vPoqa1BTaN7wJvFzu1u0REREbGIOpEEVXEkcs3sWTHndP3zB7YggGKiIhUxRBFBiFLlDNYFYWiYgUDW3mhf7CX2l0iIiITxxBFBiFsfQzi026jXi1bljMgIiK9wBBFem99dALWRiVAnM1lUWgwHG0s1e4SERERQxTpt6s3/y5nMPZRf7T1dVG7S0RERBJDFOktMf9p4qpjyMotRGsfZ4x9tJHaXSIiItJiiCK99ekf53HwUpqsRr4otBUszPnjSkRE+oOfSqSXoq7cxEfb75QzeLd/c/jUZjkDIiLSLwxRpHdENXJRlVwczusXVFeWNCAiItI3DFGkd975NQaXU2/By9kWswe0kOdDJCIi0jcMUaRXNh6/jjVHrspyBh+FBsPJluUMiIhIPzFEkd64ln4b09Yel7fH9GiEED+WMyAiIv3FEEV6Qcx/en1VNDJzCxHk7YxxPf3V7hIREVGZGKJIL3y26wIi49Jgb2WOxaHBsGQ5AyIi0nP8pCLVHb+ajg+3npW33366OXxd7dXuEhER0X0xRJGqcvIKMT48GoXFCvoGemJQm3pqd4mIiKhcGKJIVf/dcApxKTnwdLLB+wMDWc6AiIgMBkMUqWbziesIPxQPkZs+HBIMJzuWMyAiIsPBEEWquJ5xG1PXnpC3X+3WEB0b1la7S0RERBXCEEUPXXGxgkmrjyHjdgFa1nPC670aq90lIiKiCmOIoofu890Xse9CKmwtzbEoNBhWFvwxJCIiw8NPL3qoTiZkYMHWWHn77aeboUEdB7W7REREVCkMUfTQ3MovxLjwKBQUKejT3AND2nqr3SUiIqJKY4iih2b2xtO4eCMHHo42mPMMyxkQEZFhY4iih2JrTCJ+iLzyVzmDINSyt1K7S0RERA+EIYqqXVJmLqb8fFzeHt2lATo1clW7S0RERA+MIYqqvZzB5DXHcPNWAVp4OWLS403U7hIREVGVYIiiavXV3jjsPpcCG0szLAptxXIGRERkNPiJRtUm5loG5m25U85g5lPN0MiN5QyIiMh4MERRtbidX4Tx4dHILyrGY83c8VyIj9pdIiIiqlIMUVQt3t90GueTs+FW0xofPNuS5QyIiMjoMERRlYs4nYTvDlyWtxcOCYILyxkQEZERYoiiKpWclYs3frpTzuBfnf3Qxb+O2l0iIiKqFgxRVMXlDI4jLScfTT0d8UYfljMgIiLjxRBFVeab/Zew6+wNWFuYYcnQYFhbmKvdJSIiomrDEEVV4kxiJuZsPiNvz+jbFP7uNdXuEhERUbViiKIHlltQhPE/RiO/sBg9A9zwfx3qq90lIiIi0whRy5Ytg6+vL2xsbNC+fXscPHiwzPZr1qxBQECAbB8YGIhNmzbpPK4oCmbNmgVPT0/Y2tqiV69eOHfunE6btLQ0DB8+HI6OjnB2dsaoUaOQnZ2tffyPP/5A//795WvY29sjODgY33//fRXvuXGYu/kMYpOy4OpgjQ8GsZwBERGZBtVD1KpVqzBx4kSEhYXh6NGjCAoKQu/evZGcnFxq+3379mHYsGEy9ERFRWHAgAHycvLkSW2befPmYcmSJVi+fDkiIyNlCBKvmZubq20jAlRMTAy2bduGDRs2YNeuXRg9erTO+7Rs2RI///wzjh8/jpEjR+KFF16QbelvO88kY+W+S/L2gsEtZZAiIiIyBTUUMWyjIjHy1K5dO3z88cfyfnFxMby9vTF27FhMnTr1rvahoaHIycnRCTMdOnSQI0UiNIndqVu3LiZNmoTJkyfLxzMyMuDu7o6VK1di6NChOH36NJo1a4ZDhw6hbdu2ss2WLVvw5JNP4urVq/L5penbt698na+++qpc+5aZmQknJyf5/mLEy9ikZOehz6JdSMnOx8hHfBHWr7naXSIiInpg5f38VnUkKj8/H0eOHJGH27QdMjOT9/fv31/qc8T2ku0FMcqkaR8XF4fExESdNuILIcKapo24FofwNAFKEO3Fe4uRq3sRX0wXF5d7Pp6Xlye/8CUvxkqE1TfWHJMBKsCjJqb0CVC7S0RERA+VqiEqJSUFRUVFcnSnJHFfBKHSiO1ltddc36+Nm5ubzuMWFhYyIN3rfVevXi1HrsRhvXuZM2eODGyaixhRM1aiIvnO2BuwsjDD4qGtYGPJcgZERGRaVJ8TZQh27twpw9Pnn3+O5s3vfchq2rRpcrRKc4mPj4cxOpuUhfc2npa3pz8RgCYeLGdARESmR9UQ5erqCnNzcyQlJelsF/c9PDxKfY7YXlZ7zfX92vxz4nphYaFcsffP9/3zzz/Rr18/fPTRR3JieVmsra3lsdOSF2MsZzDuxyjkFRaje5M6GNHJV+0uERERmV6IsrKyQps2bRAREaHdJiaWi/sdO3Ys9Tlie8n2glhhp2nv5+cng1DJNmJukpjrpGkjrtPT0+V8LI0dO3bI9xZzp0qWORCTyT/44AOdlXumbP7vsTiTmIXa9laYPyiI5QyIiMhkWajdAVHeYMSIEXKSd0hICBYtWiRX32nmHonRHy8vLznfSBg/fjy6deuGhQsXyoATHh6Ow4cPY8WKFfJx8aE+YcIEzJ49G/7+/jJUzZw5U664E6UQhKZNm6JPnz54+eWX5Yq+goIC/Oc//5Er9zQr88QhvKeeekq+37PPPqudKyWCX1mTy42ZOKXLl3vi5O35g1uiTk2WMyAiIhOm6IGlS5cqPj4+ipWVlRISEqIcOHBA+1i3bt2UESNG6LRfvXq10rhxY9m+efPmysaNG3UeLy4uVmbOnKm4u7sr1tbWSs+ePZXY2FidNqmpqcqwYcMUBwcHxdHRURk5cqSSlZWlfVy8p/jy/PMi+lNeGRkZ8jni2tClZOUqbWdvU+pP2aDMWndC7e4QERFVm/J+fqteJ8qYGUudKPEj8vK3h7H9dDL83Rzw29jOXI1HRERGyyDqRJFh+D7yigxQVuZmWDKM5QyIiIgEhigq0/nkLMzeeErenvJEAJp6Gu6IGhERUVViiKJ7yisU5QyikVtQjC7+rhjJcgZERERaDFF0Twu3nsWp65lwsbfCwsFBMDNjOQMiIiINhigq1Z5zKVix66K8/cGzLeHmaKN2l4iIiPQKQxTd5WZOPiaujpa3h7f3wWPNdM9DSERERAxRVEo5g6lrjyM5Kw8N69hjRt9maneJiIhILzFEkY7wQ/H4PSYJluY1sHhoK9hasZwBERFRaRiiSOvCjWy8+9udcgZv9g5ACy8ntbtERESktxiiSMovLMaE8GjcLijCI41qY1RnP7W7REREpNcYokj6cNtZnEjIgLOdJRYODmY5AyIiovtgiCLsu5CCz3ZdkLfnPtMSHk4sZ0BERHQ/DFEmLv1WPiauOgZxGuphId7o08JD7S4REREZBIYoEy9nMG3tCSRm5qKBqz1mPsVyBkREROXFEGXC1hy+is0nE2FhdqecgZ2VhdpdIiIiMhgMUSYqLiUHb/8WI29PerwJAuuxnAEREVFFMESZoIIiUc4gCrfyi9CxQW280rWB2l0iIiIyOAxRJmjR9rM4djUDTraW+DA0iOUMiIiIKoEhysREXkzFJ39oyhkEwtPJVu0uERERGSSGKBOScasAr6+KluUMhrSthycCPdXuEhERkcFiiDKhcgbT153AtYxc+Na2Q1i/5mp3iYiIyKAxRJmItUcTsPH4dW05A3trljMgIiJ6EAxRJuByag5mrT8pb7/+WGMEeTur3SUiIiKDxxBlAuUMxodHIye/CCF+Lni1W0O1u0RERGQUGKKM3NId5xEdn46aNhb4KDQY5ixnQEREVCUYoozYoUtp+HjHOXn7/YGB8HJmOQMiIqKqwhBlpDJzCzAhPBrFCvBs63roF1RX7S4REREZFYYoIzVz3UkkpN+Gj4sd3unPcgZERERVjSHKCK2LSsD66Gty/tOiocFwYDkDIiKiKscQZWTi027JUShhfE9/tPappXaXiIiIjBJDlBEpLCrGhFXRyMorRNv6tfDv7ixnQEREVF0YoozIsp0XcOTyTdS0vlPOwMKc314iIqLqwk9ZIyHC05K/yhnMHtgC3i52aneJiIjIqDFEGYEsUc5gVRSKihUMbOWF/sFeaneJiIjI6DFEGYGwX2MQn3Yb9WrZspwBERHRQ8IQZeB+PXYNa48mQJzNZVFoMBxtLNXuEhERkUlgiDJgV2/ewlu/nJC3xz7qj7a+Lmp3iYiIyGToRYhatmwZfH19YWNjg/bt2+PgwYNltl+zZg0CAgJk+8DAQGzatEnncUVRMGvWLHh6esLW1ha9evXCuXN3Jl1rpKWlYfjw4XB0dISzszNGjRqF7OxsnTbHjx9Hly5d5Pt4e3tj3rx50Bdi/tPEVceQlVuI1j7OGPtoI7W7REREZFJUD1GrVq3CxIkTERYWhqNHjyIoKAi9e/dGcnJyqe337duHYcOGydATFRWFAQMGyMvJk3cKTAoi7CxZsgTLly9HZGQk7O3t5Wvm5uZq24gAFRMTg23btmHDhg3YtWsXRo8erX08MzMTjz/+OOrXr48jR45g/vz5ePvtt7FixQrog0//OI+Dl9JkNfJFoa1YzoCIiOhhU1QWEhKijBkzRnu/qKhIqVu3rjJnzpxS2w8ZMkTp27evzrb27dsrr7zyirxdXFyseHh4KPPnz9c+np6erlhbWys//vijvH/q1ClF7PqhQ4e0bTZv3qzUqFFDSUhIkPc/+eQTpVatWkpeXp62zZQpU5QmTZqUe98yMjLk+4jrqhR15abSYNpGpf6UDcrPR+Kr9LWJiIhMXUY5P79VHb7Iz8+XozzicJuGmZmZvL9///5SnyO2l2wviFEmTfu4uDgkJibqtHFycpKHCTVtxLU4hNe2bVttG9FevLcYudK06dq1K6ysrHTeJzY2Fjdv3iy1b3l5eXIEq+SlqmXnFWJ8+J1yBv2C6sqSBkRERPTwqRqiUlJSUFRUBHd3d53t4r4IQqUR28tqr7m+Xxs3Nzedxy0sLODi4qLTprTXKPke/zRnzhwZ2DQXMY+qqmXnFqKWnRW8nG0xe0AL1KhRo8rfg4iIiO6PE2mq0LRp05CRkaG9xMfHV/l7eDjZYM2rHfHjyx3gZMtyBkRERCYZolxdXWFubo6kpCSd7eK+h4dHqc8R28tqr7m+X5t/TlwvLCyUK/ZKtintNUq+xz9ZW1vL1X4lL9XB0twMPrV5WhciIiKTDVFivlGbNm0QERGh3VZcXCzvd+zYsdTniO0l2wtihZ2mvZ+fnww5JduIuUlirpOmjbhOT0+X87E0duzYId9bzJ3StBEr9goKCnTep0mTJqhVq1aVfQ2IiIjIQCkqCw8PlyvnVq5cKVfNjR49WnF2dlYSExPl488//7wydepUbfu9e/cqFhYWyoIFC5TTp08rYWFhiqWlpXLixAltm7lz58rXWL9+vXL8+HGlf//+ip+fn3L79m1tmz59+iitWrVSIiMjlT179ij+/v7KsGHDdFb0ubu7y/c/efKk7KednZ3y2Wefqb46j4iIiKpPeT+/VQ9RwtKlSxUfHx/FyspKljw4cOCA9rFu3bopI0aM0Gm/evVqpXHjxrJ98+bNlY0bN+o8LsoczJw5U4YgEdB69uypxMbG6rRJTU2VocnBwUFxdHRURo4cqWRlZem0OXbsmNK5c2f5Gl5eXjKcVQRDFBERkeEp7+d3DfGP2qNhxkocRhSr9MQk8+qaH0VERETqfH5zdR4RERFRJTBEEREREVUCQxQRERFRJTBEEREREVUCQxQRERFRJTBEEREREVUCQxQRERFRJTBEEREREVUCQxQRERFRJVhU5klUPppi8KLyKRERERkGzef2/U7qwhBVjbKysuS1t7e32l0hIiKiSnyOi9O/3AvPnVeNiouLce3aNdSsWRM1atSo0oQsgll8fLxJnJOP+2vcTGl/TWlfBe6vccs04v0V0UgEqLp168LM7N4znzgSVY3EF75evXrV9vrih9bYfnDLwv01bqa0v6a0rwL317g5Gun+ljUCpcGJ5URERESVwBBFREREVAkMUQbI2toaYWFh8toUcH+Nmyntryntq8D9NW7WJra/peHEciIiIqJK4EgUERERUSUwRBERERFVAkMUERERUSUwRBERERFVAkOUAVq2bBl8fX1hY2OD9u3b4+DBgzA0b7/9tqziXvISEBCgfTw3NxdjxoxB7dq14eDggGeffRZJSUk6r3HlyhX07dsXdnZ2cHNzwxtvvIHCwkLog127dqFfv36y2q3Yt3Xr1uk8LtZzzJo1C56enrC1tUWvXr1w7tw5nTZpaWkYPny4LGLn7OyMUaNGITs7W6fN8ePH0aVLF/mzICoHz5s3D/q4vy+++OJd3+8+ffoY5P7OmTMH7dq1k2ciED93AwYMQGxsrE6bqvr5/eOPP9C6dWu5+qlRo0ZYuXIl9HF/u3fvftf399VXXzXI/f3000/RsmVLbQHJjh07YvPmzUb5vS3P/hrT97ZaiNV5ZDjCw8MVKysr5auvvlJiYmKUl19+WXF2dlaSkpIUQxIWFqY0b95cuX79uvZy48YN7eOvvvqq4u3trURERCiHDx9WOnTooHTq1En7eGFhodKiRQulV69eSlRUlLJp0ybF1dVVmTZtmqIPRH/eeustZe3atWL1q/LLL7/oPD537lzFyclJWbdunXLs2DHl6aefVvz8/JTbt29r2/Tp00cJCgpSDhw4oOzevVtp1KiRMmzYMO3jGRkZiru7uzJ8+HDl5MmTyo8//qjY2toqn332maJv+ztixAi5PyW/32lpaTptDGV/e/furXz99deyD9HR0cqTTz6p+Pj4KNnZ2VX683vx4kXFzs5OmThxonLq1Cll6dKlirm5ubJlyxa9299u3brJ30Ulv7/i+2WI+/vrr78qGzduVM6ePavExsYq06dPVywtLeX+G9v3tjz7a0zf2+rAEGVgQkJClDFjxmjvFxUVKXXr1lXmzJmjGFqIEh+YpUlPT5f/idesWaPddvr0afnhvH//fnlf/Ec1MzNTEhMTtW0+/fRTxdHRUcnLy1P0yT9DRXFxseLh4aHMnz9fZ5+tra1lMBDELxrxvEOHDmnbbN68WalRo4aSkJAg73/yySdKrVq1dPZ3ypQpSpMmTRQ13StE9e/f/57PMeT9TU5Oln3/888/q/Tn980335R/aJQUGhoqQ40+7a/mg3b8+PH3fI4h768gfu6++OILo//e/nN/TeF7+6B4OM+A5Ofn48iRI/LQT8nz84n7+/fvh6ERh6/E4Z8GDRrIwzhiSFgQ+1hQUKCzn+JQn4+Pj3Y/xXVgYCDc3d21bXr37i1PiBkTEwN9FhcXh8TERJ39E+doEodmS+6fOKTVtm1bbRvRXny/IyMjtW26du0KKysrna+BONRy8+ZN6BsxnC+G+ps0aYLXXnsNqamp2scMeX8zMjLktYuLS5X+/Io2JV9D00bt/+v/3F+N77//Hq6urmjRogWmTZuGW7duaR8z1P0tKipCeHg4cnJy5GEuY//e/nN/jfl7W1V4AmIDkpKSIn/IS/6wCuL+mTNnYEhEYBDHxMUH6vXr1/HOO+/IuS4nT56UAUN8UIoP1X/up3hMENelfR00j+kzTf9K63/J/ROBoyQLCwv5wVWyjZ+f312voXmsVq1a0Bdi/tMzzzwj+3vhwgVMnz4dTzzxhPwlam5ubrD7W1xcjAkTJuCRRx6RHzCavlTFz++92ogPp9u3b8u5dPqwv8Jzzz2H+vXryz+KxLy1KVOmyHC7du3aMvdF85i+7e+JEydkiBDzn8S8p19++QXNmjVDdHS0UX5v77W/xvi9rWoMUaQK8QGqISY1ilAl/qOuXr3aoP9DUemGDh2qvS3+ahXf84YNG8rRqZ49e8JQiQnGIvjv2bMHpuBe+zt69Gid769YMCG+ryIwi++zoRF/3InAJEbdfvrpJ4wYMQJ//vknjNW99lcEKWP73lY1Hs4zIGI4VfzV/s+VIOK+h4cHDJn4y65x48Y4f/683Bdx6DI9Pf2e+ymuS/s6aB7TZ5r+lfV9FNfJyck6j4vVLmIFmzF8DcQhXPHzLL7fhrq///nPf7Bhwwbs3LkT9erV026vqp/fe7URK6jU+EPjXvtbGvFHkVDy+2tI+ytGm8QKsjZt2sjViUFBQVi8eLHRfm/vtb/G+L2tagxRBkT8oIsf8oiICJ3hdXG/5PFrQySWsou/bMRfOWIfLS0tdfZTDB+LOVOa/RTXYgi65Afvtm3b5H9KzTC0vhKHpMQvlZL7J4a1xdyfkvsnflGLORgaO3bskN9vzS8x0UaUFhBzNEp+DcRflfp0KK80V69elXOixPfb0PZXzJ0XgUIc8hB9/Ochxqr6+RVtSr6Gps3D/r9+v/0tjRjVEEp+fw1lf0sjfg7z8vKM7nt7v/01he/tA3vgqen00EsciFVcK1eulCuaRo8eLUsclFwZYQgmTZqk/PHHH0pcXJyyd+9euTxWLIsVK380y4jFMuodO3bIZcQdO3aUl38uq3388cflsmuxVLZOnTp6U+IgKytLLvcVF/Hf7MMPP5S3L1++rC1xIL5v69evV44fPy5XrpVW4qBVq1ZKZGSksmfPHsXf319nyb9YKSSW/D///PNyObL42RDLiNUocVDW/orHJk+eLFcvie/39u3bldatW8v9yc3NNbj9fe2112R5CvHzW3LZ961bt7RtquLnV7Ms/I033pArwJYtW6bKsvD77e/58+eVd999V+6n+P6Kn+kGDRooXbt2Ncj9nTp1qlx5KPZF/N8U98Uq0a1btxrd9/Z++2ts39vqwBBlgESNDfGfWNSLEiUPRF0dQyOWt3p6esp98PLykvfFf1gNESb+/e9/y6W24j/fwIED5S/uki5duqQ88cQTslaQCGAimBUUFCj6YOfOnTJM/PMilvpryhzMnDlThgIRinv27ClrtJSUmpoqQ4SDg4NcLjxy5EgZSEoSNaY6d+4sX0N8HUU407f9FR+24hes+MUqlofXr19f1p35Z/A3lP0tbT/FRdRSquqfX/F1DQ4Olv9PxIdXyffQl/29cuWK/FB1cXGR3xdR30t8WJasJWRI+/vSSy/Jn1HRB/EzK/5vagKUsX1v77e/xva9rQ41xD8PPp5FREREZFo4J4qIiIioEhiiiIiIiCqBIYqIiIioEhiiiIiIiCqBIYqIiIioEhiiiIiIiCqBIYqIiIioEhiiiIiIiCqBIYqICICvry8WLVqkdjeIyIAwRBGRQalRo0aZl7fffrtSr3vo0CGMHj36gfoWFxeH5557DnXr1oWNjQ3q1auH/v3748yZM/LxS5cuyT5qTuJKRIbNQu0OEBFVxPXr17W3V61ahVmzZiE2Nla7zcHBQXtbnNWqqKgIFhb3/1VXp06dB+pXQUEBHnvsMTRp0gRr166VZ7m/evUqNm/ejPT09Ad6bSLSTxyJIiKD4uHhob04OTnJkR3NfTHiU7NmTRlc2rRpA2tra+zZswcXLlyQI0Lu7u4yZLVr1w7bt28v83CeeN0vvvgCAwcOhJ2dHfz9/fHrr7/es18xMTHyfT755BN06NAB9evXxyOPPILZs2fL+4Kfn5+8btWqlXz97t27a58v3qtp06ZyBCsgIEC+joZmBCs8PBydOnWSbVq0aIE///yzSr+2RFQxDFFEZHSmTp2KuXPn4vTp02jZsiWys7Px5JNPIiIiAlFRUejTpw/69euHK1eulPk677zzDoYMGYLjx4/L5w8fPhxpaWn3HMkyMzPDTz/9JEe/SnPw4EF5LQKcGFETI1bC999/L0fU3nvvPdnn999/HzNnzsQ333yj8/w33ngDkyZNkvvQsWNHuQ+pqamV/CoR0QNTiIgM1Ndff604OTlp7+/cuVMRv9bWrVt33+c2b95cWbp0qfZ+/fr1lY8++kh7X7zOjBkztPezs7Plts2bN9/zNT/++GPFzs5OqVmzptKjRw/l3XffVS5cuKB9PC4uTr5GVFSUzvMaNmyo/PDDDzrb/vvf/yodO3bUed7cuXO1jxcUFCj16tVTPvjgg/vuKxFVD45EEZHRadu2rc59MRI1efJkebjM2dlZHtITIz73G4kSo1ga9vb2cHR0RHJy8j3bjxkzBomJiXJkSYwUrVmzBs2bN8e2bdvu+ZycnBx5GHDUqFGyX5qLOAwotpckXlNDzPMS+yn2g4jUwYnlRGR0ROApSQQoEWQWLFiARo0awdbWFoMGDUJ+fn6Zr2NpaalzX8xLKi4uLvM5Yk6WOMwmLiII9e7dW16LSeelEQFP+Pzzz9G+fXudx8zNzct8LyJSF0eiiMjo7d27Fy+++KKcJB4YGCgnoYvJ2tVNhC4xSVyMNglWVlbyuuScKTHZXZREuHjxogx4JS+aiegaBw4c0N4uLCzEkSNH5OgaEamDI1FEZPTEyjoxiVuMDolgIyZt329EqaJE7aewsDA8//zzaNasmQxMYvXcV199hSlTpsg2bm5uchRsy5YtsoaUWGUnVhiKCezjxo2Tt8Wk97y8PBw+fBg3b97ExIkTte+xbNkyuS8iOH300Ufy8ZdeeqlK94OIyo8hioiM3ocffijDhigP4OrqKkNNZmZmlb6HCEWiTIIIRJqSBJr7r7/+unYe05IlS/Duu+/K1XhdunTBH3/8gX/961+yjML8+fPlCjxxOFKMmE2YMEHnPcSKQ3ERgU2MVImSC2J/iEgdNcTscpXem4iIykGEMnFoT5Q2CA4OVrs7RPQXzokiIiIiqgSGKCIiIqJK4OE8IiIiokrgSBQRERFRJTBEEREREVUCQxQRERFRJTBEEREREVUCQxQRERFRJTBEEREREVUCQxQRERFRJTBEEREREaHi/h/58qzoMIZoqQAAAABJRU5ErkJggg=="
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compile Model"
      ],
      "metadata": {
        "id": "8SKsgwgG5pSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import math\n",
        "\n",
        "def perplexity(real, pred):\n",
        "  # Reshape to match the shape of predictions.\n",
        "    real = tf.reshape(real, shape=(-1, MAX_SENTENCE_LENGTH - 1))\n",
        "  # Uses the previously defined loss function.\n",
        "    loss = loss_function(real, pred)\n",
        "    loss = tf.cast(loss, dtype=tf.float32)  # Convert to float32 explicitly\n",
        "    return tf.exp(loss)  # No need to cast twice"
      ],
      "metadata": {
        "id": "6H0cPfV35rJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "  # ensure labels have shape (batch_size, MAX_SENTENCE_LENGTH - 1)\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_SENTENCE_LENGTH - 1))\n",
        "  # Computes token-wise accuracy: For each token, is the highest-probability prediction equal to the true label?\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)"
      ],
      "metadata": {
        "id": "Uxxygox45tSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eksperimen NUM_LAYERS"
      ],
      "metadata": {
        "id": "jlVVBa6oxflE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NL2"
      ],
      "metadata": {
        "id": "-ajMSNAreofh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "#NUM_Layers Tuning Hypereparameters\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 256\n",
        "NUM_HEADS = 8\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1\n",
        "\n",
        "model_NL2 = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "metadata": {
        "id": "XuLQp_Q4eqPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "\n",
        "model_NL2.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss_function,\n",
        "    metrics=[accuracy, perplexity],\n",
        "    run_eagerly=True  # Set to True for debugging if needed\n",
        ")"
      ],
      "metadata": {
        "id": "e5on8lLFevtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 30\n",
        "\n",
        "history = model_NL2.fit(dataset, epochs=EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klbFihKve0Eg",
        "outputId": "7ecf7468-e7a4-4b7b-b1ad-1487f6b460a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 863ms/step - accuracy: 0.0051 - loss: 3.4969 - perplexity: 35.1302\n",
            "Epoch 2/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 770ms/step - accuracy: 0.0223 - loss: 3.2042 - perplexity: 25.7370\n",
            "Epoch 3/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 795ms/step - accuracy: 0.0279 - loss: 2.7742 - perplexity: 16.7307\n",
            "Epoch 4/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 815ms/step - accuracy: 0.0631 - loss: 2.5895 - perplexity: 13.6308\n",
            "Epoch 5/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 786ms/step - accuracy: 0.0993 - loss: 2.3187 - perplexity: 10.3427\n",
            "Epoch 6/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 827ms/step - accuracy: 0.1229 - loss: 2.0633 - perplexity: 7.9930\n",
            "Epoch 7/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 859ms/step - accuracy: 0.1399 - loss: 1.8242 - perplexity: 6.2789\n",
            "Epoch 8/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 840ms/step - accuracy: 0.1584 - loss: 1.6722 - perplexity: 5.4037\n",
            "Epoch 9/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 832ms/step - accuracy: 0.1655 - loss: 1.5374 - perplexity: 4.6920\n",
            "Epoch 10/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 839ms/step - accuracy: 0.1809 - loss: 1.4236 - perplexity: 4.1927\n",
            "Epoch 11/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 811ms/step - accuracy: 0.1945 - loss: 1.3180 - perplexity: 3.7663\n",
            "Epoch 12/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 794ms/step - accuracy: 0.2094 - loss: 1.1810 - perplexity: 3.2853\n",
            "Epoch 13/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 788ms/step - accuracy: 0.2319 - loss: 1.1173 - perplexity: 3.0823\n",
            "Epoch 14/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 797ms/step - accuracy: 0.2401 - loss: 0.9574 - perplexity: 2.6235\n",
            "Epoch 15/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 792ms/step - accuracy: 0.2617 - loss: 0.8658 - perplexity: 2.3864\n",
            "Epoch 16/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 806ms/step - accuracy: 0.2823 - loss: 0.7766 - perplexity: 2.1806\n",
            "Epoch 17/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 811ms/step - accuracy: 0.3019 - loss: 0.6525 - perplexity: 1.9253\n",
            "Epoch 18/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 792ms/step - accuracy: 0.3296 - loss: 0.5456 - perplexity: 1.7281\n",
            "Epoch 19/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 798ms/step - accuracy: 0.3554 - loss: 0.4570 - perplexity: 1.5814\n",
            "Epoch 20/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 796ms/step - accuracy: 0.3747 - loss: 0.3765 - perplexity: 1.4588\n",
            "Epoch 21/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 791ms/step - accuracy: 0.3858 - loss: 0.3154 - perplexity: 1.3721\n",
            "Epoch 22/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 816ms/step - accuracy: 0.4005 - loss: 0.2650 - perplexity: 1.3042\n",
            "Epoch 23/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 787ms/step - accuracy: 0.4106 - loss: 0.2409 - perplexity: 1.2732\n",
            "Epoch 24/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 823ms/step - accuracy: 0.4110 - loss: 0.2161 - perplexity: 1.2419\n",
            "Epoch 25/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 815ms/step - accuracy: 0.4114 - loss: 0.1972 - perplexity: 1.2186\n",
            "Epoch 26/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 910ms/step - accuracy: 0.4047 - loss: 0.1798 - perplexity: 1.1977\n",
            "Epoch 27/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 808ms/step - accuracy: 0.4081 - loss: 0.1733 - perplexity: 1.1901\n",
            "Epoch 28/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 791ms/step - accuracy: 0.4085 - loss: 0.1764 - perplexity: 1.1936\n",
            "Epoch 29/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 795ms/step - accuracy: 0.4187 - loss: 0.1688 - perplexity: 1.1845\n",
            "Epoch 30/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 807ms/step - accuracy: 0.4228 - loss: 0.1739 - perplexity: 1.1904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_NL2.save_weights('D:/skripsi-sultin/data/bot_v4_Final_NL2_E50.weights.h5')"
      ],
      "metadata": {
        "id": "a6WtCD3Me3NE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NL3"
      ],
      "metadata": {
        "id": "S03HjDIY7Gi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "#NUM_Layers Tuning Hypereparameters\n",
        "NUM_LAYERS = 3\n",
        "D_MODEL = 256\n",
        "NUM_HEADS = 8\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1\n",
        "\n",
        "model_NL3 = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "metadata": {
        "id": "ZlJPkq3zxlQl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48ec4cc1-7aee-47e8-9fba-a1bd259bd201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From D:\\skripsi-sultin\\source\\final\\venv\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From D:\\skripsi-sultin\\source\\final\\venv\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "\n",
        "model_NL3.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss_function,\n",
        "    metrics=[accuracy, perplexity],\n",
        "    run_eagerly=True  # Set to True for debugging if needed\n",
        ")"
      ],
      "metadata": {
        "id": "huKmaJe-yXgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 30\n",
        "\n",
        "history = model_NL3.fit(dataset, epochs=EPOCHS)"
      ],
      "metadata": {
        "id": "fLhpalc7ybrg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21c603f5-c233-48ac-fd65-9b87cfaec8c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - accuracy: 0.0063 - loss: 3.5037 - perplexity: 35.3499\n",
            "Epoch 2/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 0.0208 - loss: 3.2166 - perplexity: 26.0309\n",
            "Epoch 3/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 1s/step - accuracy: 0.0255 - loss: 2.7855 - perplexity: 16.9325\n",
            "Epoch 4/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 0.0619 - loss: 2.5984 - perplexity: 13.7507\n",
            "Epoch 5/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 0.0979 - loss: 2.3335 - perplexity: 10.4976\n",
            "Epoch 6/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 0.1208 - loss: 2.0821 - perplexity: 8.1469\n",
            "Epoch 7/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 0.1379 - loss: 1.8465 - perplexity: 6.4190\n",
            "Epoch 8/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 0.1579 - loss: 1.6883 - perplexity: 5.4902\n",
            "Epoch 9/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 0.1642 - loss: 1.5592 - perplexity: 4.7968\n",
            "Epoch 10/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 0.1792 - loss: 1.4501 - perplexity: 4.3086\n",
            "Epoch 11/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 0.1917 - loss: 1.3498 - perplexity: 3.8874\n",
            "Epoch 12/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 0.2029 - loss: 1.2209 - perplexity: 3.4222\n",
            "Epoch 13/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 0.2264 - loss: 1.1611 - perplexity: 3.2223\n",
            "Epoch 14/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 0.2330 - loss: 0.9987 - perplexity: 2.7356\n",
            "Epoch 15/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 0.2481 - loss: 0.9234 - perplexity: 2.5290\n",
            "Epoch 16/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 0.2692 - loss: 0.8344 - perplexity: 2.3111\n",
            "Epoch 17/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 0.2921 - loss: 0.7099 - perplexity: 2.0400\n",
            "Epoch 18/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.3106 - loss: 0.6148 - perplexity: 1.8527\n",
            "Epoch 19/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.3350 - loss: 0.5285 - perplexity: 1.6995\n",
            "Epoch 20/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.3568 - loss: 0.4435 - perplexity: 1.5603\n",
            "Epoch 21/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.3663 - loss: 0.3797 - perplexity: 1.4632\n",
            "Epoch 22/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.3847 - loss: 0.3279 - perplexity: 1.3894\n",
            "Epoch 23/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.3974 - loss: 0.2860 - perplexity: 1.3324\n",
            "Epoch 24/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.3991 - loss: 0.2573 - perplexity: 1.2944\n",
            "Epoch 25/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.4029 - loss: 0.2330 - perplexity: 1.2632\n",
            "Epoch 26/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.3922 - loss: 0.2242 - perplexity: 1.2524\n",
            "Epoch 27/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.3980 - loss: 0.2099 - perplexity: 1.2345\n",
            "Epoch 28/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.3947 - loss: 0.2178 - perplexity: 1.2444\n",
            "Epoch 29/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.4076 - loss: 0.2103 - perplexity: 1.2349\n",
            "Epoch 30/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.4141 - loss: 0.2035 - perplexity: 1.2262\n",
            "Epoch 31/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.4061 - loss: 0.1999 - perplexity: 1.2219\n",
            "Epoch 32/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.4164 - loss: 0.1955 - perplexity: 1.2164\n",
            "Epoch 33/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.4081 - loss: 0.1697 - perplexity: 1.1856\n",
            "Epoch 34/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.4182 - loss: 0.1620 - perplexity: 1.1764\n",
            "Epoch 35/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.4287 - loss: 0.1566 - perplexity: 1.1699\n",
            "Epoch 36/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 0.4265 - loss: 0.1441 - perplexity: 1.1555\n",
            "Epoch 37/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 0.4230 - loss: 0.1328 - perplexity: 1.1423\n",
            "Epoch 38/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.4268 - loss: 0.1208 - perplexity: 1.1288\n",
            "Epoch 39/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 0.4240 - loss: 0.1253 - perplexity: 1.1337\n",
            "Epoch 40/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 0.4347 - loss: 0.1209 - perplexity: 1.1287\n",
            "Epoch 41/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 0.4370 - loss: 0.1059 - perplexity: 1.1120\n",
            "Epoch 42/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 0.4221 - loss: 0.1097 - perplexity: 1.1163\n",
            "Epoch 43/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 1s/step - accuracy: 0.4386 - loss: 0.1013 - perplexity: 1.1068\n",
            "Epoch 44/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 1s/step - accuracy: 0.4298 - loss: 0.0990 - perplexity: 1.1042\n",
            "Epoch 45/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 1s/step - accuracy: 0.4401 - loss: 0.0970 - perplexity: 1.1020\n",
            "Epoch 46/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - accuracy: 0.4392 - loss: 0.0914 - perplexity: 1.0958\n",
            "Epoch 47/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 1s/step - accuracy: 0.4287 - loss: 0.0882 - perplexity: 1.0924\n",
            "Epoch 48/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 1s/step - accuracy: 0.4376 - loss: 0.0838 - perplexity: 1.0876\n",
            "Epoch 49/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - accuracy: 0.4325 - loss: 0.0847 - perplexity: 1.0886\n",
            "Epoch 50/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 1s/step - accuracy: 0.4364 - loss: 0.0774 - perplexity: 1.0806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_NL3.save_weights('D:/skripsi-sultin/data/bot_v4_Final_NL3_E50.weights.h5')"
      ],
      "metadata": {
        "id": "u6dQphZ_6hwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NL4"
      ],
      "metadata": {
        "id": "Jb0NFW8f7Isr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#NUM_Layers Tuning Hypereparameters\n",
        "NUM_LAYERS = 4\n",
        "D_MODEL = 256\n",
        "NUM_HEADS = 8\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1\n",
        "\n",
        "model_NL4 = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "metadata": {
        "id": "onq1Hjiq7J9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "\n",
        "model_NL4.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss_function,\n",
        "    metrics=[accuracy, perplexity],\n",
        "    run_eagerly=True  # Set to True for debugging if needed\n",
        ")"
      ],
      "metadata": {
        "id": "iM08l_eP7PZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 30\n",
        "\n",
        "history = model_NL4.fit(dataset, epochs=EPOCHS)"
      ],
      "metadata": {
        "id": "Rg_fYP3c7Q1Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddf10d8b-92a8-43f3-ad90-3eba23df63e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - accuracy: 0.0061 - loss: 3.4766 - perplexity: 34.3750\n",
            "Epoch 2/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - accuracy: 0.0214 - loss: 3.1976 - perplexity: 25.5271\n",
            "Epoch 3/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - accuracy: 0.0227 - loss: 2.7872 - perplexity: 16.9468\n",
            "Epoch 4/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - accuracy: 0.0516 - loss: 2.6404 - perplexity: 14.3496\n",
            "Epoch 5/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - accuracy: 0.0908 - loss: 2.3867 - perplexity: 11.0786\n",
            "Epoch 6/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - accuracy: 0.1187 - loss: 2.1285 - perplexity: 8.5398\n",
            "Epoch 7/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 2s/step - accuracy: 0.1326 - loss: 1.8999 - perplexity: 6.7816\n",
            "Epoch 8/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - accuracy: 0.1488 - loss: 1.7567 - perplexity: 5.8872\n",
            "Epoch 9/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - accuracy: 0.1581 - loss: 1.6189 - perplexity: 5.0932\n",
            "Epoch 10/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - accuracy: 0.1710 - loss: 1.5186 - perplexity: 4.6201\n",
            "Epoch 11/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - accuracy: 0.1837 - loss: 1.4159 - perplexity: 4.1577\n",
            "Epoch 12/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - accuracy: 0.1941 - loss: 1.2857 - perplexity: 3.6537\n",
            "Epoch 13/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - accuracy: 0.2162 - loss: 1.2374 - perplexity: 3.4814\n",
            "Epoch 14/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - accuracy: 0.2184 - loss: 1.0818 - perplexity: 2.9776\n",
            "Epoch 15/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - accuracy: 0.2344 - loss: 1.0084 - perplexity: 2.7569\n",
            "Epoch 16/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - accuracy: 0.2493 - loss: 0.9410 - perplexity: 2.5725\n",
            "Epoch 17/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - accuracy: 0.2670 - loss: 0.8132 - perplexity: 2.2634\n",
            "Epoch 18/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - accuracy: 0.2868 - loss: 0.7164 - perplexity: 2.0511\n",
            "Epoch 19/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 1s/step - accuracy: 0.3105 - loss: 0.6353 - perplexity: 1.8916\n",
            "Epoch 20/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 1s/step - accuracy: 0.3329 - loss: 0.5389 - perplexity: 1.7175\n",
            "Epoch 21/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 1s/step - accuracy: 0.3415 - loss: 0.4781 - perplexity: 1.6150\n",
            "Epoch 22/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - accuracy: 0.3630 - loss: 0.4114 - perplexity: 1.5106\n",
            "Epoch 23/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - accuracy: 0.3783 - loss: 0.3581 - perplexity: 1.4325\n",
            "Epoch 24/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 1s/step - accuracy: 0.3811 - loss: 0.3217 - perplexity: 1.3807\n",
            "Epoch 25/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - accuracy: 0.3823 - loss: 0.2993 - perplexity: 1.3500\n",
            "Epoch 26/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 1s/step - accuracy: 0.3802 - loss: 0.2756 - perplexity: 1.3191\n",
            "Epoch 27/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 1s/step - accuracy: 0.3839 - loss: 0.2553 - perplexity: 1.2925\n",
            "Epoch 28/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 2s/step - accuracy: 0.3903 - loss: 0.2402 - perplexity: 1.2726\n",
            "Epoch 29/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 2s/step - accuracy: 0.3966 - loss: 0.2431 - perplexity: 1.2766\n",
            "Epoch 30/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 2s/step - accuracy: 0.4043 - loss: 0.2345 - perplexity: 1.2654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_NL4.save_weights('D:/skripsi-sultin/data/bot_v4_Final_NL4_E50.weights.h5')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "YOUuqJbGy322"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NL5"
      ],
      "metadata": {
        "id": "gjbjwOJD8jE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#NUM_Layers Tuning Hypereparameters\n",
        "NUM_LAYERS = 5\n",
        "D_MODEL = 256\n",
        "NUM_HEADS = 8\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1\n",
        "\n",
        "model_NL5 = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "metadata": {
        "id": "h8ky_YZa8ls8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "\n",
        "model_NL5.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss_function,\n",
        "    metrics=[accuracy, perplexity],\n",
        "    run_eagerly=True  # Set to True for debugging if needed\n",
        ")"
      ],
      "metadata": {
        "id": "51Wo2F5-8q-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 30\n",
        "\n",
        "history = model_NL5.fit(dataset, epochs=EPOCHS)"
      ],
      "metadata": {
        "id": "f3ZS68F38sSh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc7a9b1c-6dc8-4628-d074-23f848870978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 2s/step - accuracy: 0.0075 - loss: 3.5815 - perplexity: 37.8291\n",
            "Epoch 2/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 2s/step - accuracy: 0.0221 - loss: 3.2343 - perplexity: 26.7047\n",
            "Epoch 3/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 2s/step - accuracy: 0.0219 - loss: 2.7927 - perplexity: 16.8355\n",
            "Epoch 4/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 2s/step - accuracy: 0.0296 - loss: 2.6748 - perplexity: 14.8979\n",
            "Epoch 5/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 2s/step - accuracy: 0.0743 - loss: 2.5170 - perplexity: 12.7841\n",
            "Epoch 6/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 2s/step - accuracy: 0.1093 - loss: 2.2143 - perplexity: 9.3541\n",
            "Epoch 7/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 2s/step - accuracy: 0.1253 - loss: 1.9793 - perplexity: 7.3684\n",
            "Epoch 8/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 2s/step - accuracy: 0.1423 - loss: 1.8107 - perplexity: 6.1951\n",
            "Epoch 9/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 2s/step - accuracy: 0.1546 - loss: 1.6812 - perplexity: 5.4696\n",
            "Epoch 10/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 2s/step - accuracy: 0.1663 - loss: 1.6151 - perplexity: 5.0825\n",
            "Epoch 11/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 2s/step - accuracy: 0.1782 - loss: 1.4985 - perplexity: 4.5237\n",
            "Epoch 12/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 2s/step - accuracy: 0.1806 - loss: 1.3674 - perplexity: 3.9811\n",
            "Epoch 13/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 2s/step - accuracy: 0.1984 - loss: 1.3098 - perplexity: 3.7373\n",
            "Epoch 14/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 2s/step - accuracy: 0.2071 - loss: 1.1852 - perplexity: 3.2978\n",
            "Epoch 15/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 2s/step - accuracy: 0.2188 - loss: 1.1311 - perplexity: 3.1192\n",
            "Epoch 16/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 2s/step - accuracy: 0.2319 - loss: 1.0360 - perplexity: 2.8335\n",
            "Epoch 17/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 2s/step - accuracy: 0.2421 - loss: 0.9119 - perplexity: 2.5017\n",
            "Epoch 18/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 2s/step - accuracy: 0.2619 - loss: 0.8334 - perplexity: 2.3141\n",
            "Epoch 19/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 2s/step - accuracy: 0.2735 - loss: 0.7461 - perplexity: 2.1154\n",
            "Epoch 20/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 2s/step - accuracy: 0.2888 - loss: 0.6804 - perplexity: 1.9822\n",
            "Epoch 21/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 2s/step - accuracy: 0.3071 - loss: 0.6138 - perplexity: 1.8518\n",
            "Epoch 22/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 2s/step - accuracy: 0.3274 - loss: 0.5462 - perplexity: 1.7306\n",
            "Epoch 23/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 2s/step - accuracy: 0.3401 - loss: 0.4694 - perplexity: 1.6028\n",
            "Epoch 24/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 2s/step - accuracy: 0.3434 - loss: 0.4383 - perplexity: 1.5524\n",
            "Epoch 25/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 2s/step - accuracy: 0.3574 - loss: 0.3961 - perplexity: 1.4884\n",
            "Epoch 26/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 2s/step - accuracy: 0.3678 - loss: 0.3653 - perplexity: 1.4432\n",
            "Epoch 27/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 2s/step - accuracy: 0.3668 - loss: 0.3505 - perplexity: 1.4222\n",
            "Epoch 28/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 2s/step - accuracy: 0.3748 - loss: 0.3341 - perplexity: 1.3985\n",
            "Epoch 29/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 2s/step - accuracy: 0.3717 - loss: 0.3088 - perplexity: 1.3648\n",
            "Epoch 30/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 2s/step - accuracy: 0.3725 - loss: 0.3003 - perplexity: 1.3521\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_NL5.save_weights('D:/skripsi-sultin/data/bot_v4_Final_NL5_E50.weights.h5')"
      ],
      "metadata": {
        "id": "c5ouBQTqhI7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eksperimen D_MODEL\n"
      ],
      "metadata": {
        "id": "cCdVtcVAxyIF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "D_MODEL128"
      ],
      "metadata": {
        "id": "oIn1iiZj88_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "#D_MODEL Tuning Hypereparameters\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 128\n",
        "NUM_HEADS = 8\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1\n",
        "\n",
        "model_DM128 = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "metadata": {
        "id": "KhOsOmJzxZMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "\n",
        "model_DM128.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss_function,\n",
        "    metrics=[accuracy, perplexity],\n",
        "    run_eagerly=True  # Set to True for debugging if needed\n",
        ")"
      ],
      "metadata": {
        "id": "hkNIXUHa9BIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 30\n",
        "\n",
        "history = model_DM128.fit(dataset, epochs=EPOCHS)"
      ],
      "metadata": {
        "id": "OPj8Jm3G9FjO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "754ebc1e-b846-47df-bb75-fe5da5f46ec6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 658ms/step - accuracy: 0.0017 - loss: 3.6107 - perplexity: 39.7680\n",
            "Epoch 2/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 649ms/step - accuracy: 0.0232 - loss: 3.3376 - perplexity: 29.4851\n",
            "Epoch 3/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 651ms/step - accuracy: 0.0242 - loss: 3.0484 - perplexity: 22.5553\n",
            "Epoch 4/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 652ms/step - accuracy: 0.0438 - loss: 2.7129 - perplexity: 15.3966\n",
            "Epoch 5/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 653ms/step - accuracy: 0.0756 - loss: 2.4938 - perplexity: 12.3342\n",
            "Epoch 6/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 655ms/step - accuracy: 0.1029 - loss: 2.2401 - perplexity: 9.7911\n",
            "Epoch 7/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 653ms/step - accuracy: 0.1255 - loss: 2.0077 - perplexity: 7.5498\n",
            "Epoch 8/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 651ms/step - accuracy: 0.1435 - loss: 1.8874 - perplexity: 6.6927\n",
            "Epoch 9/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 653ms/step - accuracy: 0.1578 - loss: 1.6925 - perplexity: 5.5062\n",
            "Epoch 10/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 655ms/step - accuracy: 0.1682 - loss: 1.6200 - perplexity: 5.1011\n",
            "Epoch 11/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 665ms/step - accuracy: 0.1747 - loss: 1.4684 - perplexity: 4.3988\n",
            "Epoch 12/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 659ms/step - accuracy: 0.1863 - loss: 1.4079 - perplexity: 4.1216\n",
            "Epoch 13/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 663ms/step - accuracy: 0.1931 - loss: 1.3071 - perplexity: 3.7323\n",
            "Epoch 14/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 708ms/step - accuracy: 0.2037 - loss: 1.2342 - perplexity: 3.4624\n",
            "Epoch 15/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 655ms/step - accuracy: 0.2156 - loss: 1.1488 - perplexity: 3.1760\n",
            "Epoch 16/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 654ms/step - accuracy: 0.2196 - loss: 1.0516 - perplexity: 2.8741\n",
            "Epoch 17/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 650ms/step - accuracy: 0.2390 - loss: 0.9589 - perplexity: 2.6258\n",
            "Epoch 18/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 656ms/step - accuracy: 0.2517 - loss: 0.8785 - perplexity: 2.4196\n",
            "Epoch 19/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 655ms/step - accuracy: 0.2697 - loss: 0.8095 - perplexity: 2.2535\n",
            "Epoch 20/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 656ms/step - accuracy: 0.2890 - loss: 0.7276 - perplexity: 2.0759\n",
            "Epoch 21/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 658ms/step - accuracy: 0.3003 - loss: 0.6435 - perplexity: 1.9085\n",
            "Epoch 22/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 662ms/step - accuracy: 0.3119 - loss: 0.5436 - perplexity: 1.7295\n",
            "Epoch 23/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 656ms/step - accuracy: 0.3361 - loss: 0.5004 - perplexity: 1.6533\n",
            "Epoch 24/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 654ms/step - accuracy: 0.3372 - loss: 0.4444 - perplexity: 1.5624\n",
            "Epoch 25/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 653ms/step - accuracy: 0.3564 - loss: 0.3913 - perplexity: 1.4809\n",
            "Epoch 26/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 654ms/step - accuracy: 0.3668 - loss: 0.3579 - perplexity: 1.4332\n",
            "Epoch 27/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 661ms/step - accuracy: 0.3751 - loss: 0.3273 - perplexity: 1.3890\n",
            "Epoch 28/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 683ms/step - accuracy: 0.3736 - loss: 0.3006 - perplexity: 1.3524\n",
            "Epoch 29/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 683ms/step - accuracy: 0.3911 - loss: 0.2868 - perplexity: 1.3334\n",
            "Epoch 30/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 686ms/step - accuracy: 0.3911 - loss: 0.2659 - perplexity: 1.3056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_DM128.save_weights('D:/skripsi-sultin/data/bot_v4_Final_DM128_E50.weights.h5')"
      ],
      "metadata": {
        "id": "R5ewZcp6weaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "D_MODEL 384"
      ],
      "metadata": {
        "id": "Ge32L6BZ9Je5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 384\n",
        "NUM_HEADS = 8\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1\n",
        "\n",
        "model_DM328 = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "metadata": {
        "id": "Mc_Au9w29mJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "\n",
        "model_DM328.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss_function,\n",
        "    metrics=[accuracy, perplexity],\n",
        "    run_eagerly=True  # Set to True for debugging if needed\n",
        ")"
      ],
      "metadata": {
        "id": "FtY1ihvi9nRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 30\n",
        "\n",
        "history = model_DM328.fit(dataset, epochs=EPOCHS)"
      ],
      "metadata": {
        "id": "f98mmpr99Ypz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8ebe809-8dce-47c3-8b65-edf92872908c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 824ms/step - accuracy: 0.0106 - loss: 3.6192 - perplexity: 40.2197\n",
            "Epoch 2/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 831ms/step - accuracy: 0.0202 - loss: 3.0781 - perplexity: 22.4896\n",
            "Epoch 3/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 842ms/step - accuracy: 0.0320 - loss: 2.7057 - perplexity: 15.4223\n",
            "Epoch 4/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 831ms/step - accuracy: 0.0772 - loss: 2.4826 - perplexity: 12.2602\n",
            "Epoch 5/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 839ms/step - accuracy: 0.1130 - loss: 2.1128 - perplexity: 8.4401\n",
            "Epoch 6/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 838ms/step - accuracy: 0.1368 - loss: 1.9111 - perplexity: 6.8458\n",
            "Epoch 7/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 831ms/step - accuracy: 0.1554 - loss: 1.7537 - perplexity: 5.8453\n",
            "Epoch 8/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 833ms/step - accuracy: 0.1723 - loss: 1.5794 - perplexity: 4.9304\n",
            "Epoch 9/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 831ms/step - accuracy: 0.1836 - loss: 1.4303 - perplexity: 4.2154\n",
            "Epoch 10/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 836ms/step - accuracy: 0.1973 - loss: 1.2959 - perplexity: 3.6792\n",
            "Epoch 11/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 854ms/step - accuracy: 0.2182 - loss: 1.1639 - perplexity: 3.2228\n",
            "Epoch 12/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 839ms/step - accuracy: 0.2373 - loss: 1.0579 - perplexity: 2.8925\n",
            "Epoch 13/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 827ms/step - accuracy: 0.2565 - loss: 0.9140 - perplexity: 2.5068\n",
            "Epoch 14/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 852ms/step - accuracy: 0.2757 - loss: 0.7749 - perplexity: 2.1805\n",
            "Epoch 15/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 838ms/step - accuracy: 0.3025 - loss: 0.6646 - perplexity: 1.9499\n",
            "Epoch 16/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 839ms/step - accuracy: 0.3335 - loss: 0.5638 - perplexity: 1.7625\n",
            "Epoch 17/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 830ms/step - accuracy: 0.3522 - loss: 0.4443 - perplexity: 1.5621\n",
            "Epoch 18/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 831ms/step - accuracy: 0.3781 - loss: 0.3474 - perplexity: 1.4175\n",
            "Epoch 19/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 842ms/step - accuracy: 0.4022 - loss: 0.2967 - perplexity: 1.3465\n",
            "Epoch 20/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 826ms/step - accuracy: 0.4103 - loss: 0.2372 - perplexity: 1.2685\n",
            "Epoch 21/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 827ms/step - accuracy: 0.4126 - loss: 0.2065 - perplexity: 1.2303\n",
            "Epoch 22/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 831ms/step - accuracy: 0.4109 - loss: 0.1812 - perplexity: 1.1994\n",
            "Epoch 23/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 834ms/step - accuracy: 0.4228 - loss: 0.1641 - perplexity: 1.1790\n",
            "Epoch 24/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 828ms/step - accuracy: 0.4239 - loss: 0.1712 - perplexity: 1.1872\n",
            "Epoch 25/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 836ms/step - accuracy: 0.4143 - loss: 0.1616 - perplexity: 1.1760\n",
            "Epoch 26/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 876ms/step - accuracy: 0.4182 - loss: 0.1584 - perplexity: 1.1723\n",
            "Epoch 27/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 907ms/step - accuracy: 0.4178 - loss: 0.1602 - perplexity: 1.1745\n",
            "Epoch 28/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 900ms/step - accuracy: 0.4278 - loss: 0.1570 - perplexity: 1.1705\n",
            "Epoch 29/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 937ms/step - accuracy: 0.4268 - loss: 0.1563 - perplexity: 1.1696\n",
            "Epoch 30/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 909ms/step - accuracy: 0.4266 - loss: 0.1558 - perplexity: 1.1691\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_DM328.save_weights('D:/skripsi-sultin/data/bot_v4_Final_DM328_E50.weights.h5')"
      ],
      "metadata": {
        "id": "GfWOxiMcjPmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "D_MODEL 512"
      ],
      "metadata": {
        "id": "7lIUrQBe9sSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#D_MODEL Tuning Hypereparameters\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 512\n",
        "NUM_HEADS = 8\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1\n",
        "\n",
        "model_DM512 = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "metadata": {
        "id": "jzK-y-wW9wKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "\n",
        "model_DM512.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss_function,\n",
        "    metrics=[accuracy, perplexity],\n",
        "    run_eagerly=True  # Set to True for debugging if needed\n",
        ")"
      ],
      "metadata": {
        "id": "w0gyme9t94MM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 30\n",
        "\n",
        "history = model_DM512.fit(dataset, epochs=EPOCHS)"
      ],
      "metadata": {
        "id": "mAuY3WE596b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33313282-c1f8-4912-cc86-4e6c05e747ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.0067 - loss: 3.6647 - perplexity: 42.1764\n",
            "Epoch 2/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.0248 - loss: 3.0077 - perplexity: 21.1875\n",
            "Epoch 3/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.0485 - loss: 2.6536 - perplexity: 14.6803\n",
            "Epoch 4/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.0854 - loss: 2.3454 - perplexity: 10.6869\n",
            "Epoch 5/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.1245 - loss: 2.0549 - perplexity: 7.9821\n",
            "Epoch 6/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 0.1464 - loss: 1.8462 - perplexity: 6.4186\n",
            "Epoch 7/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.1605 - loss: 1.6177 - perplexity: 5.1162\n",
            "Epoch 8/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.1774 - loss: 1.4645 - perplexity: 4.3692\n",
            "Epoch 9/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 0.1970 - loss: 1.3101 - perplexity: 3.7372\n",
            "Epoch 10/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.2179 - loss: 1.2006 - perplexity: 3.3407\n",
            "Epoch 11/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.2302 - loss: 1.0420 - perplexity: 2.8481\n",
            "Epoch 12/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.2598 - loss: 0.9082 - perplexity: 2.4901\n",
            "Epoch 13/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.2829 - loss: 0.7675 - perplexity: 2.1628\n",
            "Epoch 14/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.3089 - loss: 0.6382 - perplexity: 1.9005\n",
            "Epoch 15/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.3386 - loss: 0.5201 - perplexity: 1.6862\n",
            "Epoch 16/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.3742 - loss: 0.4316 - perplexity: 1.5417\n",
            "Epoch 17/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.3886 - loss: 0.3274 - perplexity: 1.3889\n",
            "Epoch 18/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.4087 - loss: 0.2619 - perplexity: 1.3002\n",
            "Epoch 19/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.4175 - loss: 0.2134 - perplexity: 1.2384\n",
            "Epoch 20/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.4242 - loss: 0.1927 - perplexity: 1.2132\n",
            "Epoch 21/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 0.4158 - loss: 0.1766 - perplexity: 1.1937\n",
            "Epoch 22/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.4217 - loss: 0.1601 - perplexity: 1.1743\n",
            "Epoch 23/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 0.4207 - loss: 0.1584 - perplexity: 1.1722\n",
            "Epoch 24/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 0.4225 - loss: 0.1614 - perplexity: 1.1757\n",
            "Epoch 25/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.4225 - loss: 0.1619 - perplexity: 1.1763\n",
            "Epoch 26/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 0.4169 - loss: 0.1558 - perplexity: 1.1693\n",
            "Epoch 27/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.4332 - loss: 0.1602 - perplexity: 1.1743\n",
            "Epoch 28/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 0.4229 - loss: 0.1566 - perplexity: 1.1703\n",
            "Epoch 29/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.4188 - loss: 0.1610 - perplexity: 1.1754\n",
            "Epoch 30/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.4264 - loss: 0.1563 - perplexity: 1.1698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_DM512.save_weights('D:/skripsi-sultin/data/bot_v4_Final_DM512_E50.weights.h5')"
      ],
      "metadata": {
        "id": "3YKU8Z_ojVdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eksperimen NUM_HEADS\n"
      ],
      "metadata": {
        "id": "EUfsyrXMB056"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NUM_HEADS 4"
      ],
      "metadata": {
        "id": "RIFcXsd0B8qW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#NUM HEADS Hypereparameters\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 256\n",
        "NUM_HEADS = 4\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1\n",
        "\n",
        "model_NH4 = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "metadata": {
        "id": "3zT0TFLwB--Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "\n",
        "model_NH4.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss_function,\n",
        "    metrics=[accuracy, perplexity],\n",
        "    run_eagerly=True  # Set to True for debugging if needed\n",
        ")"
      ],
      "metadata": {
        "id": "IpssjIBVCRYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 30\n",
        "\n",
        "history = model_NH4.fit(dataset, epochs=EPOCHS)"
      ],
      "metadata": {
        "id": "Pcn5ULg7CUxP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c77bd67a-d3b0-4744-9fc9-3b54b3df7874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 793ms/step - accuracy: 0.0062 - loss: 3.5629 - perplexity: 37.2190\n",
            "Epoch 2/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 798ms/step - accuracy: 0.0214 - loss: 3.2009 - perplexity: 25.8424\n",
            "Epoch 3/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 850ms/step - accuracy: 0.0269 - loss: 2.8136 - perplexity: 17.2187\n",
            "Epoch 4/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 919ms/step - accuracy: 0.0614 - loss: 2.5291 - perplexity: 12.8737\n",
            "Epoch 5/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 871ms/step - accuracy: 0.0989 - loss: 2.2906 - perplexity: 10.2536\n",
            "Epoch 6/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 764ms/step - accuracy: 0.1270 - loss: 2.0722 - perplexity: 8.0664\n",
            "Epoch 7/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 802ms/step - accuracy: 0.1442 - loss: 1.8474 - perplexity: 6.4091\n",
            "Epoch 8/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 892ms/step - accuracy: 0.1546 - loss: 1.6766 - perplexity: 5.4095\n",
            "Epoch 9/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 915ms/step - accuracy: 0.1675 - loss: 1.5575 - perplexity: 4.7956\n",
            "Epoch 10/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 779ms/step - accuracy: 0.1872 - loss: 1.4549 - perplexity: 4.3163\n",
            "Epoch 11/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 797ms/step - accuracy: 0.1936 - loss: 1.3039 - perplexity: 3.7141\n",
            "Epoch 12/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 896ms/step - accuracy: 0.2102 - loss: 1.2117 - perplexity: 3.3833\n",
            "Epoch 13/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 894ms/step - accuracy: 0.2222 - loss: 1.0707 - perplexity: 2.9349\n",
            "Epoch 14/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 779ms/step - accuracy: 0.2440 - loss: 1.0164 - perplexity: 2.7856\n",
            "Epoch 15/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 779ms/step - accuracy: 0.2573 - loss: 0.8786 - perplexity: 2.4208\n",
            "Epoch 16/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 859ms/step - accuracy: 0.2802 - loss: 0.7714 - perplexity: 2.1676\n",
            "Epoch 17/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 934ms/step - accuracy: 0.2966 - loss: 0.6745 - perplexity: 1.9685\n",
            "Epoch 18/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 839ms/step - accuracy: 0.3274 - loss: 0.5768 - perplexity: 1.7829\n",
            "Epoch 19/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 800ms/step - accuracy: 0.3412 - loss: 0.4784 - perplexity: 1.6166\n",
            "Epoch 20/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 836ms/step - accuracy: 0.3675 - loss: 0.4091 - perplexity: 1.5081\n",
            "Epoch 21/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 931ms/step - accuracy: 0.3782 - loss: 0.3377 - perplexity: 1.4028\n",
            "Epoch 22/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 900ms/step - accuracy: 0.3885 - loss: 0.2898 - perplexity: 1.3375\n",
            "Epoch 23/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 792ms/step - accuracy: 0.3866 - loss: 0.2530 - perplexity: 1.2894\n",
            "Epoch 24/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 808ms/step - accuracy: 0.4060 - loss: 0.2280 - perplexity: 1.2569\n",
            "Epoch 25/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 932ms/step - accuracy: 0.4072 - loss: 0.2104 - perplexity: 1.2351\n",
            "Epoch 26/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 909ms/step - accuracy: 0.4137 - loss: 0.2001 - perplexity: 1.2222\n",
            "Epoch 27/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 772ms/step - accuracy: 0.4150 - loss: 0.1842 - perplexity: 1.2029\n",
            "Epoch 28/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 799ms/step - accuracy: 0.4091 - loss: 0.1861 - perplexity: 1.2053\n",
            "Epoch 29/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 902ms/step - accuracy: 0.4155 - loss: 0.1731 - perplexity: 1.1896\n",
            "Epoch 30/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 897ms/step - accuracy: 0.4164 - loss: 0.1781 - perplexity: 1.1957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_NH4.save_weights('D:/skripsi-sultin/data/bot_v4_Final_NH4_E50.weights.h5')"
      ],
      "metadata": {
        "id": "oaFd-Ru4jfbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NUM_HEADS 16"
      ],
      "metadata": {
        "id": "yvQV13H8CX3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#NUM HEADS Hypereparameters\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 256\n",
        "NUM_HEADS = 16\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1\n",
        "\n",
        "model_NH16 = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "metadata": {
        "id": "EVXo5zPFCauL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "\n",
        "model_NH16.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss_function,\n",
        "    metrics=[accuracy, perplexity],\n",
        "    run_eagerly=True  # Set to True for debugging if needed\n",
        ")"
      ],
      "metadata": {
        "id": "-b-VGMirCf8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 30\n",
        "\n",
        "history = model_NH16.fit(dataset, epochs=EPOCHS)"
      ],
      "metadata": {
        "id": "w52OsBH_Cin0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3a33009-8962-4b1f-ef78-863178b5bd69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 888ms/step - accuracy: 0.0046 - loss: 3.6242 - perplexity: 39.0572\n",
            "Epoch 2/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 867ms/step - accuracy: 0.0218 - loss: 3.1933 - perplexity: 25.4463\n",
            "Epoch 3/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 947ms/step - accuracy: 0.0274 - loss: 2.7876 - perplexity: 16.8811\n",
            "Epoch 4/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 951ms/step - accuracy: 0.0589 - loss: 2.5648 - perplexity: 13.3704\n",
            "Epoch 5/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 864ms/step - accuracy: 0.0968 - loss: 2.2606 - perplexity: 9.7503\n",
            "Epoch 6/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 861ms/step - accuracy: 0.1257 - loss: 2.0413 - perplexity: 7.8737\n",
            "Epoch 7/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 956ms/step - accuracy: 0.1461 - loss: 1.8582 - perplexity: 6.4933\n",
            "Epoch 8/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 943ms/step - accuracy: 0.1583 - loss: 1.6683 - perplexity: 5.3628\n",
            "Epoch 9/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 877ms/step - accuracy: 0.1723 - loss: 1.5513 - perplexity: 4.7584\n",
            "Epoch 10/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 852ms/step - accuracy: 0.1837 - loss: 1.4336 - perplexity: 4.2551\n",
            "Epoch 11/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 935ms/step - accuracy: 0.1919 - loss: 1.3097 - perplexity: 3.7385\n",
            "Epoch 12/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 978ms/step - accuracy: 0.2064 - loss: 1.2072 - perplexity: 3.3641\n",
            "Epoch 13/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 862ms/step - accuracy: 0.2280 - loss: 1.0844 - perplexity: 2.9778\n",
            "Epoch 14/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 856ms/step - accuracy: 0.2424 - loss: 0.9765 - perplexity: 2.6680\n",
            "Epoch 15/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 928ms/step - accuracy: 0.2660 - loss: 0.8738 - perplexity: 2.4075\n",
            "Epoch 16/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 943ms/step - accuracy: 0.2826 - loss: 0.7505 - perplexity: 2.1251\n",
            "Epoch 17/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 886ms/step - accuracy: 0.3005 - loss: 0.6363 - perplexity: 1.8946\n",
            "Epoch 18/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 862ms/step - accuracy: 0.3322 - loss: 0.5434 - perplexity: 1.7254\n",
            "Epoch 19/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 959ms/step - accuracy: 0.3586 - loss: 0.4593 - perplexity: 1.5851\n",
            "Epoch 20/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 986ms/step - accuracy: 0.3742 - loss: 0.3710 - perplexity: 1.4508\n",
            "Epoch 21/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 874ms/step - accuracy: 0.3878 - loss: 0.3081 - perplexity: 1.3624\n",
            "Epoch 22/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 869ms/step - accuracy: 0.4066 - loss: 0.2610 - perplexity: 1.2989\n",
            "Epoch 23/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 932ms/step - accuracy: 0.4075 - loss: 0.2251 - perplexity: 1.2532\n",
            "Epoch 24/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 939ms/step - accuracy: 0.4139 - loss: 0.2110 - perplexity: 1.2357\n",
            "Epoch 25/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 866ms/step - accuracy: 0.4121 - loss: 0.1874 - perplexity: 1.2070\n",
            "Epoch 26/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 859ms/step - accuracy: 0.4129 - loss: 0.1868 - perplexity: 1.2060\n",
            "Epoch 27/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 949ms/step - accuracy: 0.4139 - loss: 0.1805 - perplexity: 1.1983\n",
            "Epoch 28/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 960ms/step - accuracy: 0.4147 - loss: 0.1700 - perplexity: 1.1859\n",
            "Epoch 29/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 957ms/step - accuracy: 0.4171 - loss: 0.1781 - perplexity: 1.1956\n",
            "Epoch 30/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 910ms/step - accuracy: 0.4158 - loss: 0.1724 - perplexity: 1.1887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_NH16.save_weights('D:/skripsi-sultin/data/bot_v4_Final_NH16_E50.weights.h5')"
      ],
      "metadata": {
        "id": "W2xjAAYxjmf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NUM_HEADS32"
      ],
      "metadata": {
        "id": "LH8GblCoCk1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#NUM HEADS Hypereparameters\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 256\n",
        "NUM_HEADS = 32\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1\n",
        "\n",
        "model_NH32 = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "metadata": {
        "id": "pBw_RzBwConr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "\n",
        "model_NH32.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss_function,\n",
        "    metrics=[accuracy, perplexity],\n",
        "    run_eagerly=True  # Set to True for debugging if needed\n",
        ")"
      ],
      "metadata": {
        "id": "kgoBkrUfCr2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 30\n",
        "\n",
        "history = model_NH32.fit(dataset, epochs=EPOCHS)"
      ],
      "metadata": {
        "id": "rvjEDsUYCvCr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3760dd0c-a8f0-4660-e93a-dc622acbbee0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 0.0038 - loss: 3.5819 - perplexity: 37.6487\n",
            "Epoch 2/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.0220 - loss: 3.1900 - perplexity: 25.5370\n",
            "Epoch 3/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 981ms/step - accuracy: 0.0294 - loss: 2.8439 - perplexity: 18.0116\n",
            "Epoch 4/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.0607 - loss: 2.5819 - perplexity: 13.5991\n",
            "Epoch 5/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 0.0955 - loss: 2.2644 - perplexity: 9.8397\n",
            "Epoch 6/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 998ms/step - accuracy: 0.1264 - loss: 2.0595 - perplexity: 8.0235\n",
            "Epoch 7/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.1463 - loss: 1.8382 - perplexity: 6.3721\n",
            "Epoch 8/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.1614 - loss: 1.6922 - perplexity: 5.4923\n",
            "Epoch 9/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.1737 - loss: 1.5722 - perplexity: 4.8755\n",
            "Epoch 10/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 963ms/step - accuracy: 0.1786 - loss: 1.4192 - perplexity: 4.1700\n",
            "Epoch 11/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.1984 - loss: 1.3469 - perplexity: 3.8686\n",
            "Epoch 12/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.2113 - loss: 1.2012 - perplexity: 3.3534\n",
            "Epoch 13/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.2261 - loss: 1.0929 - perplexity: 3.0079\n",
            "Epoch 14/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 997ms/step - accuracy: 0.2425 - loss: 0.9864 - perplexity: 2.6955\n",
            "Epoch 15/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.2658 - loss: 0.8665 - perplexity: 2.3870\n",
            "Epoch 16/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.2905 - loss: 0.7645 - perplexity: 2.1553\n",
            "Epoch 17/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 989ms/step - accuracy: 0.3094 - loss: 0.6362 - perplexity: 1.8959\n",
            "Epoch 18/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.3325 - loss: 0.5418 - perplexity: 1.7226\n",
            "Epoch 19/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 0.3546 - loss: 0.4572 - perplexity: 1.5827\n",
            "Epoch 20/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.3808 - loss: 0.3675 - perplexity: 1.4465\n",
            "Epoch 21/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.3822 - loss: 0.2981 - perplexity: 1.3489\n",
            "Epoch 22/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.3931 - loss: 0.2514 - perplexity: 1.2873\n",
            "Epoch 23/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.4042 - loss: 0.2196 - perplexity: 1.2463\n",
            "Epoch 24/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 982ms/step - accuracy: 0.4147 - loss: 0.2047 - perplexity: 1.2278\n",
            "Epoch 25/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.4115 - loss: 0.1984 - perplexity: 1.2202\n",
            "Epoch 26/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.4128 - loss: 0.1709 - perplexity: 1.1873\n",
            "Epoch 27/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.4155 - loss: 0.1728 - perplexity: 1.1893\n",
            "Epoch 28/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 976ms/step - accuracy: 0.4212 - loss: 0.1683 - perplexity: 1.1840\n",
            "Epoch 29/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.4108 - loss: 0.1829 - perplexity: 1.2013\n",
            "Epoch 30/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.4048 - loss: 0.1732 - perplexity: 1.1897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_NH32.save_weights('D:/skripsi-sultin/data/bot_v4_Final_NH32_E50.weights.h5')"
      ],
      "metadata": {
        "id": "ZCVJclNTjumQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eksperimen UNITS"
      ],
      "metadata": {
        "id": "uXEVi_EoCxs3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "UNITS 256"
      ],
      "metadata": {
        "id": "sa8wEvN0C0u-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Base Model Hypereparameters\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 256\n",
        "NUM_HEADS = 8\n",
        "UNITS = 256\n",
        "DROPOUT = 0.1\n",
        "\n",
        "model_U256 = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "metadata": {
        "id": "I-rMCZaVC4Ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "\n",
        "model_U256.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss_function,\n",
        "    metrics=[accuracy, perplexity],\n",
        "    run_eagerly=True  # Set to True for debugging if needed\n",
        ")"
      ],
      "metadata": {
        "id": "pJrJetltDdHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 30\n",
        "\n",
        "history = model_U256.fit(dataset, epochs=EPOCHS)"
      ],
      "metadata": {
        "id": "cgXoaEuuDhXZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a69f9f5-7730-4d46-e05b-93cc036c8341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 800ms/step - accuracy: 0.0057 - loss: 3.6510 - perplexity: 40.6058\n",
            "Epoch 2/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 819ms/step - accuracy: 0.0233 - loss: 3.2334 - perplexity: 26.3788\n",
            "Epoch 3/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 868ms/step - accuracy: 0.0256 - loss: 2.8445 - perplexity: 17.7703\n",
            "Epoch 4/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 904ms/step - accuracy: 0.0517 - loss: 2.5442 - perplexity: 13.1148\n",
            "Epoch 5/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 844ms/step - accuracy: 0.0875 - loss: 2.2913 - perplexity: 10.0991\n",
            "Epoch 6/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 780ms/step - accuracy: 0.1198 - loss: 2.1063 - perplexity: 8.3292\n",
            "Epoch 7/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 853ms/step - accuracy: 0.1360 - loss: 1.8513 - perplexity: 6.4555\n",
            "Epoch 8/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 905ms/step - accuracy: 0.1567 - loss: 1.7672 - perplexity: 5.9331\n",
            "Epoch 9/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 879ms/step - accuracy: 0.1672 - loss: 1.5711 - perplexity: 4.8504\n",
            "Epoch 10/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 797ms/step - accuracy: 0.1845 - loss: 1.4717 - perplexity: 4.3905\n",
            "Epoch 11/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 818ms/step - accuracy: 0.1861 - loss: 1.3364 - perplexity: 3.8528\n",
            "Epoch 12/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 909ms/step - accuracy: 0.2047 - loss: 1.2198 - perplexity: 3.4173\n",
            "Epoch 13/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 944ms/step - accuracy: 0.2228 - loss: 1.1347 - perplexity: 3.1288\n",
            "Epoch 14/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 802ms/step - accuracy: 0.2322 - loss: 1.0034 - perplexity: 2.7496\n",
            "Epoch 15/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 816ms/step - accuracy: 0.2512 - loss: 0.8831 - perplexity: 2.4329\n",
            "Epoch 16/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 915ms/step - accuracy: 0.2772 - loss: 0.7939 - perplexity: 2.2203\n",
            "Epoch 17/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 918ms/step - accuracy: 0.2935 - loss: 0.6752 - perplexity: 1.9709\n",
            "Epoch 18/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 808ms/step - accuracy: 0.3200 - loss: 0.5863 - perplexity: 1.8032\n",
            "Epoch 19/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 835ms/step - accuracy: 0.3354 - loss: 0.4903 - perplexity: 1.6365\n",
            "Epoch 20/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 895ms/step - accuracy: 0.3579 - loss: 0.4003 - perplexity: 1.4949\n",
            "Epoch 21/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 905ms/step - accuracy: 0.3772 - loss: 0.3457 - perplexity: 1.4146\n",
            "Epoch 22/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 821ms/step - accuracy: 0.3956 - loss: 0.2839 - perplexity: 1.3296\n",
            "Epoch 23/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 818ms/step - accuracy: 0.4068 - loss: 0.2496 - perplexity: 1.2842\n",
            "Epoch 24/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 885ms/step - accuracy: 0.4117 - loss: 0.2210 - perplexity: 1.2483\n",
            "Epoch 25/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 935ms/step - accuracy: 0.4058 - loss: 0.2007 - perplexity: 1.2230\n",
            "Epoch 26/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 826ms/step - accuracy: 0.4115 - loss: 0.1840 - perplexity: 1.2027\n",
            "Epoch 27/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 783ms/step - accuracy: 0.4140 - loss: 0.1936 - perplexity: 1.2141\n",
            "Epoch 28/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 831ms/step - accuracy: 0.4230 - loss: 0.1796 - perplexity: 1.1972\n",
            "Epoch 29/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 940ms/step - accuracy: 0.4112 - loss: 0.1713 - perplexity: 1.1876\n",
            "Epoch 30/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 867ms/step - accuracy: 0.4098 - loss: 0.1742 - perplexity: 1.1910\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_U256.save_weights('D:/skripsi-sultin/data/bot_v4_Final_U256_E50.weights.h5')"
      ],
      "metadata": {
        "id": "qExg1WrAj2HZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "U384"
      ],
      "metadata": {
        "id": "LDyUXpCfDlmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Base Model Hypereparameters\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 256\n",
        "NUM_HEADS = 8\n",
        "UNITS = 384\n",
        "DROPOUT = 0.1\n",
        "\n",
        "model_U384 = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "metadata": {
        "id": "jFTsL4V1DoLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "\n",
        "model_U384.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss_function,\n",
        "    metrics=[accuracy, perplexity],\n",
        "    run_eagerly=True  # Set to True for debugging if needed\n",
        ")"
      ],
      "metadata": {
        "id": "ZhgeV2MZDsbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "history = model_U384.fit(dataset, epochs=EPOCHS)"
      ],
      "metadata": {
        "id": "pIv4RptoDwcx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c66cd8c-15e9-4b50-d927-94360bcb3530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 814ms/step - accuracy: 0.0020 - loss: 3.5270 - perplexity: 36.2301\n",
            "Epoch 2/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 830ms/step - accuracy: 0.0219 - loss: 3.2148 - perplexity: 26.0248\n",
            "Epoch 3/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 862ms/step - accuracy: 0.0251 - loss: 2.7800 - perplexity: 16.8344\n",
            "Epoch 4/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 859ms/step - accuracy: 0.0570 - loss: 2.6113 - perplexity: 13.9318\n",
            "Epoch 5/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 842ms/step - accuracy: 0.0948 - loss: 2.3450 - perplexity: 10.6203\n",
            "Epoch 6/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 851ms/step - accuracy: 0.1207 - loss: 2.0859 - perplexity: 8.1775\n",
            "Epoch 7/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 834ms/step - accuracy: 0.1372 - loss: 1.8443 - perplexity: 6.4074\n",
            "Epoch 8/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 839ms/step - accuracy: 0.1562 - loss: 1.6887 - perplexity: 5.4936\n",
            "Epoch 9/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 834ms/step - accuracy: 0.1656 - loss: 1.5465 - perplexity: 4.7360\n",
            "Epoch 10/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 841ms/step - accuracy: 0.1797 - loss: 1.4321 - perplexity: 4.2290\n",
            "Epoch 11/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 859ms/step - accuracy: 0.1949 - loss: 1.3267 - perplexity: 3.7987\n",
            "Epoch 12/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 825ms/step - accuracy: 0.2070 - loss: 1.1898 - perplexity: 3.3170\n",
            "Epoch 13/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 835ms/step - accuracy: 0.2325 - loss: 1.1279 - perplexity: 3.1178\n",
            "Epoch 14/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 808ms/step - accuracy: 0.2392 - loss: 0.9634 - perplexity: 2.6404\n",
            "Epoch 15/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 826ms/step - accuracy: 0.2594 - loss: 0.8716 - perplexity: 2.4021\n",
            "Epoch 16/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 834ms/step - accuracy: 0.2819 - loss: 0.7823 - perplexity: 2.1923\n",
            "Epoch 17/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 843ms/step - accuracy: 0.3041 - loss: 0.6602 - perplexity: 1.9405\n",
            "Epoch 18/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 811ms/step - accuracy: 0.3286 - loss: 0.5530 - perplexity: 1.7409\n",
            "Epoch 19/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 870ms/step - accuracy: 0.3507 - loss: 0.4720 - perplexity: 1.6051\n",
            "Epoch 20/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 887ms/step - accuracy: 0.3702 - loss: 0.3912 - perplexity: 1.4803\n",
            "Epoch 21/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 892ms/step - accuracy: 0.3839 - loss: 0.3270 - perplexity: 1.3879\n",
            "Epoch 22/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 879ms/step - accuracy: 0.3982 - loss: 0.2803 - perplexity: 1.3244\n",
            "Epoch 23/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 832ms/step - accuracy: 0.4102 - loss: 0.2471 - perplexity: 1.2812\n",
            "Epoch 24/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 840ms/step - accuracy: 0.4107 - loss: 0.2160 - perplexity: 1.2418\n",
            "Epoch 25/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 839ms/step - accuracy: 0.4081 - loss: 0.2055 - perplexity: 1.2288\n",
            "Epoch 26/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 835ms/step - accuracy: 0.4039 - loss: 0.1849 - perplexity: 1.2038\n",
            "Epoch 27/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 816ms/step - accuracy: 0.4051 - loss: 0.1804 - perplexity: 1.1984\n",
            "Epoch 28/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 850ms/step - accuracy: 0.4082 - loss: 0.1750 - perplexity: 1.1920\n",
            "Epoch 29/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 844ms/step - accuracy: 0.4164 - loss: 0.1776 - perplexity: 1.1951\n",
            "Epoch 30/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 836ms/step - accuracy: 0.4232 - loss: 0.1779 - perplexity: 1.1951\n",
            "Epoch 31/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 823ms/step - accuracy: 0.4146 - loss: 0.1743 - perplexity: 1.1909\n",
            "Epoch 32/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 820ms/step - accuracy: 0.4243 - loss: 0.1666 - perplexity: 1.1817\n",
            "Epoch 33/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 827ms/step - accuracy: 0.4151 - loss: 0.1478 - perplexity: 1.1598\n",
            "Epoch 34/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 843ms/step - accuracy: 0.4266 - loss: 0.1331 - perplexity: 1.1428\n",
            "Epoch 35/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 826ms/step - accuracy: 0.4343 - loss: 0.1367 - perplexity: 1.1468\n",
            "Epoch 36/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 856ms/step - accuracy: 0.4335 - loss: 0.1198 - perplexity: 1.1276\n",
            "Epoch 37/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 849ms/step - accuracy: 0.4268 - loss: 0.1191 - perplexity: 1.1269\n",
            "Epoch 38/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 820ms/step - accuracy: 0.4311 - loss: 0.1061 - perplexity: 1.1121\n",
            "Epoch 39/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 816ms/step - accuracy: 0.4321 - loss: 0.1027 - perplexity: 1.1084\n",
            "Epoch 40/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 826ms/step - accuracy: 0.4405 - loss: 0.0974 - perplexity: 1.1025\n",
            "Epoch 41/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 851ms/step - accuracy: 0.4413 - loss: 0.0964 - perplexity: 1.1015\n",
            "Epoch 42/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 875ms/step - accuracy: 0.4269 - loss: 0.0949 - perplexity: 1.0997\n",
            "Epoch 43/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 824ms/step - accuracy: 0.4417 - loss: 0.0879 - perplexity: 1.0920\n",
            "Epoch 44/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 842ms/step - accuracy: 0.4338 - loss: 0.0878 - perplexity: 1.0919\n",
            "Epoch 45/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 859ms/step - accuracy: 0.4439 - loss: 0.0821 - perplexity: 1.0857\n",
            "Epoch 46/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 864ms/step - accuracy: 0.4422 - loss: 0.0814 - perplexity: 1.0849\n",
            "Epoch 47/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 861ms/step - accuracy: 0.4323 - loss: 0.0765 - perplexity: 1.0796\n",
            "Epoch 48/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 838ms/step - accuracy: 0.4417 - loss: 0.0748 - perplexity: 1.0778\n",
            "Epoch 49/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 828ms/step - accuracy: 0.4354 - loss: 0.0742 - perplexity: 1.0772\n",
            "Epoch 50/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 849ms/step - accuracy: 0.4380 - loss: 0.0744 - perplexity: 1.0774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_U384.save_weights('D:/skripsi-sultin/data/bot_v4_Final_U384_E50.weights.h5')"
      ],
      "metadata": {
        "id": "nDyIAJscj_kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "U640"
      ],
      "metadata": {
        "id": "e0y25F4cDzAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Base Model Hypereparameters\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 256\n",
        "NUM_HEADS = 8\n",
        "UNITS = 640\n",
        "DROPOUT = 0.1\n",
        "\n",
        "model_U640 = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "metadata": {
        "id": "92FW9x2FD2rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "\n",
        "model_U640.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss_function,\n",
        "    metrics=[accuracy, perplexity],\n",
        "    run_eagerly=True  # Set to True for debugging if needed\n",
        ")"
      ],
      "metadata": {
        "id": "TtSZOoR6D_sY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 30\n",
        "\n",
        "history = model_U640.fit(dataset, epochs=EPOCHS)"
      ],
      "metadata": {
        "id": "tlsTLItXEBkz",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ef3412c-8771-4233-dff6-ded4398da088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 812ms/step - accuracy: 0.0028 - loss: 3.5941 - perplexity: 38.5911\n",
            "Epoch 2/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 831ms/step - accuracy: 0.0221 - loss: 3.2430 - perplexity: 26.7497\n",
            "Epoch 3/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 929ms/step - accuracy: 0.0269 - loss: 2.7941 - perplexity: 17.1782\n",
            "Epoch 4/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 903ms/step - accuracy: 0.0627 - loss: 2.5812 - perplexity: 13.6112\n",
            "Epoch 5/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 819ms/step - accuracy: 0.1045 - loss: 2.3520 - perplexity: 10.7617\n",
            "Epoch 6/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 813ms/step - accuracy: 0.1301 - loss: 2.0234 - perplexity: 7.7128\n",
            "Epoch 7/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 918ms/step - accuracy: 0.1480 - loss: 1.8187 - perplexity: 6.2350\n",
            "Epoch 8/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 912ms/step - accuracy: 0.1578 - loss: 1.6473 - perplexity: 5.2891\n",
            "Epoch 9/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 839ms/step - accuracy: 0.1686 - loss: 1.5351 - perplexity: 4.7024\n",
            "Epoch 10/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 820ms/step - accuracy: 0.1881 - loss: 1.4316 - perplexity: 4.2317\n",
            "Epoch 11/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 870ms/step - accuracy: 0.1934 - loss: 1.3084 - perplexity: 3.7306\n",
            "Epoch 12/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 935ms/step - accuracy: 0.2104 - loss: 1.1802 - perplexity: 3.2810\n",
            "Epoch 13/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 870ms/step - accuracy: 0.2260 - loss: 1.0752 - perplexity: 2.9441\n",
            "Epoch 14/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 822ms/step - accuracy: 0.2467 - loss: 0.9673 - perplexity: 2.6466\n",
            "Epoch 15/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 848ms/step - accuracy: 0.2647 - loss: 0.8601 - perplexity: 2.3742\n",
            "Epoch 16/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 918ms/step - accuracy: 0.2869 - loss: 0.7517 - perplexity: 2.1283\n",
            "Epoch 17/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 881ms/step - accuracy: 0.3069 - loss: 0.6280 - perplexity: 1.8780\n",
            "Epoch 18/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 809ms/step - accuracy: 0.3293 - loss: 0.5325 - perplexity: 1.7072\n",
            "Epoch 19/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 831ms/step - accuracy: 0.3470 - loss: 0.4381 - perplexity: 1.5522\n",
            "Epoch 20/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 931ms/step - accuracy: 0.3723 - loss: 0.3786 - perplexity: 1.4616\n",
            "Epoch 21/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 885ms/step - accuracy: 0.3869 - loss: 0.3053 - perplexity: 1.3584\n",
            "Epoch 22/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 825ms/step - accuracy: 0.4080 - loss: 0.2687 - perplexity: 1.3089\n",
            "Epoch 23/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 814ms/step - accuracy: 0.4043 - loss: 0.2266 - perplexity: 1.2553\n",
            "Epoch 24/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 943ms/step - accuracy: 0.4057 - loss: 0.2095 - perplexity: 1.2337\n",
            "Epoch 25/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 930ms/step - accuracy: 0.4046 - loss: 0.1909 - perplexity: 1.2110\n",
            "Epoch 26/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 797ms/step - accuracy: 0.4175 - loss: 0.1900 - perplexity: 1.2097\n",
            "Epoch 27/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 844ms/step - accuracy: 0.4036 - loss: 0.1788 - perplexity: 1.1965\n",
            "Epoch 28/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 908ms/step - accuracy: 0.4128 - loss: 0.1676 - perplexity: 1.1832\n",
            "Epoch 29/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 940ms/step - accuracy: 0.4222 - loss: 0.1687 - perplexity: 1.1845\n",
            "Epoch 30/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 822ms/step - accuracy: 0.4235 - loss: 0.1697 - perplexity: 1.1855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_U640.save_weights('D:/skripsi-sultin/data/bot_v4_Final_U640_E50.weights.h5')"
      ],
      "metadata": {
        "id": "9n5QIhyzkJ3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eskperimen Dropout"
      ],
      "metadata": {
        "id": "nENFnZ-SENjL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "D0.15"
      ],
      "metadata": {
        "id": "bAbcAyNbEb5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropout Tuning Hypereparameters\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 256\n",
        "NUM_HEADS = 8\n",
        "UNITS = 512\n",
        "DROPOUT = 0.15\n",
        "\n",
        "model_D015 = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "metadata": {
        "id": "GKJxQNawEUwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "\n",
        "model_D015.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss_function,\n",
        "    metrics=[accuracy, perplexity],\n",
        "    run_eagerly=True  # Set to True for debugging if needed\n",
        ")"
      ],
      "metadata": {
        "id": "FPNODFfGEkzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 30\n",
        "\n",
        "history = model_D015.fit(dataset, epochs=EPOCHS)"
      ],
      "metadata": {
        "id": "ct27PO86EoKv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62b6afa1-cc75-4fcd-c115-bac86add2eb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 813ms/step - accuracy: 0.0041 - loss: 3.6691 - perplexity: 41.3126\n",
            "Epoch 2/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 876ms/step - accuracy: 0.0186 - loss: 3.2511 - perplexity: 26.9990\n",
            "Epoch 3/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 937ms/step - accuracy: 0.0227 - loss: 2.8208 - perplexity: 17.5076\n",
            "Epoch 4/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 843ms/step - accuracy: 0.0526 - loss: 2.6161 - perplexity: 14.0282\n",
            "Epoch 5/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 828ms/step - accuracy: 0.0900 - loss: 2.3219 - perplexity: 10.4141\n",
            "Epoch 6/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 866ms/step - accuracy: 0.1206 - loss: 2.0937 - perplexity: 8.2107\n",
            "Epoch 7/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 943ms/step - accuracy: 0.1361 - loss: 1.8880 - perplexity: 6.7541\n",
            "Epoch 8/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 867ms/step - accuracy: 0.1473 - loss: 1.7481 - perplexity: 5.8205\n",
            "Epoch 9/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 800ms/step - accuracy: 0.1596 - loss: 1.5981 - perplexity: 5.0077\n",
            "Epoch 10/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 859ms/step - accuracy: 0.1735 - loss: 1.5179 - perplexity: 4.6002\n",
            "Epoch 11/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 974ms/step - accuracy: 0.1784 - loss: 1.3739 - perplexity: 3.9882\n",
            "Epoch 12/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 879ms/step - accuracy: 0.1950 - loss: 1.3090 - perplexity: 3.7235\n",
            "Epoch 13/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 822ms/step - accuracy: 0.2051 - loss: 1.2052 - perplexity: 3.3568\n",
            "Epoch 14/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 842ms/step - accuracy: 0.2153 - loss: 1.1049 - perplexity: 3.0370\n",
            "Epoch 15/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 944ms/step - accuracy: 0.2287 - loss: 1.0080 - perplexity: 2.7525\n",
            "Epoch 16/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 913ms/step - accuracy: 0.2473 - loss: 0.9130 - perplexity: 2.5016\n",
            "Epoch 17/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 835ms/step - accuracy: 0.2699 - loss: 0.8160 - perplexity: 2.2693\n",
            "Epoch 18/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 837ms/step - accuracy: 0.2828 - loss: 0.7087 - perplexity: 2.0401\n",
            "Epoch 19/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 960ms/step - accuracy: 0.3083 - loss: 0.6203 - perplexity: 1.8634\n",
            "Epoch 20/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 919ms/step - accuracy: 0.3276 - loss: 0.5395 - perplexity: 1.7195\n",
            "Epoch 21/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 792ms/step - accuracy: 0.3515 - loss: 0.4570 - perplexity: 1.5820\n",
            "Epoch 22/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 833ms/step - accuracy: 0.3615 - loss: 0.3832 - perplexity: 1.4691\n",
            "Epoch 23/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 924ms/step - accuracy: 0.3790 - loss: 0.3351 - perplexity: 1.3999\n",
            "Epoch 24/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 932ms/step - accuracy: 0.3842 - loss: 0.2954 - perplexity: 1.3447\n",
            "Epoch 25/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 800ms/step - accuracy: 0.3909 - loss: 0.2590 - perplexity: 1.2966\n",
            "Epoch 26/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 853ms/step - accuracy: 0.3965 - loss: 0.2369 - perplexity: 1.2681\n",
            "Epoch 27/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 905ms/step - accuracy: 0.4026 - loss: 0.2207 - perplexity: 1.2478\n",
            "Epoch 28/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 930ms/step - accuracy: 0.4161 - loss: 0.2155 - perplexity: 1.2414\n",
            "Epoch 29/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 836ms/step - accuracy: 0.4152 - loss: 0.2107 - perplexity: 1.2352\n",
            "Epoch 30/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 808ms/step - accuracy: 0.4121 - loss: 0.1982 - perplexity: 1.2202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_D015.save_weights('D:/skripsi-sultin/data/bot_v4_Final_D015_E50.weights.h5')"
      ],
      "metadata": {
        "id": "b5HH04Rpkbzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "D02"
      ],
      "metadata": {
        "id": "qZ6Xfn65EsLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropout Tuning Hypereparameters\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 256\n",
        "NUM_HEADS = 8\n",
        "UNITS = 512\n",
        "DROPOUT = 0.2\n",
        "\n",
        "model_D02 = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "metadata": {
        "id": "g6zoEEOEEvIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "\n",
        "model_D02.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss_function,\n",
        "    metrics=[accuracy, perplexity],\n",
        "    run_eagerly=True  # Set to True for debugging if needed\n",
        ")"
      ],
      "metadata": {
        "id": "e74zTQ7aEyTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 30\n",
        "\n",
        "history = model_D02.fit(dataset, epochs=EPOCHS)"
      ],
      "metadata": {
        "id": "gv-LODwrE0g_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32369e48-9578-4a19-e132-30d9f7454d82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 866ms/step - accuracy: 0.0042 - loss: 3.5791 - perplexity: 37.7725\n",
            "Epoch 2/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 935ms/step - accuracy: 0.0214 - loss: 3.2362 - perplexity: 26.5446\n",
            "Epoch 3/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 871ms/step - accuracy: 0.0248 - loss: 2.8622 - perplexity: 18.2007\n",
            "Epoch 4/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 816ms/step - accuracy: 0.0482 - loss: 2.6676 - perplexity: 14.8292\n",
            "Epoch 5/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 863ms/step - accuracy: 0.0810 - loss: 2.4365 - perplexity: 11.7630\n",
            "Epoch 6/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 933ms/step - accuracy: 0.1086 - loss: 2.1481 - perplexity: 8.7617\n",
            "Epoch 7/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 883ms/step - accuracy: 0.1301 - loss: 2.0072 - perplexity: 7.5339\n",
            "Epoch 8/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 796ms/step - accuracy: 0.1450 - loss: 1.8168 - perplexity: 6.2527\n",
            "Epoch 9/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 814ms/step - accuracy: 0.1543 - loss: 1.6604 - perplexity: 5.3194\n",
            "Epoch 10/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 947ms/step - accuracy: 0.1650 - loss: 1.5270 - perplexity: 4.6488\n",
            "Epoch 11/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 905ms/step - accuracy: 0.1750 - loss: 1.4762 - perplexity: 4.4248\n",
            "Epoch 12/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 789ms/step - accuracy: 0.1844 - loss: 1.4019 - perplexity: 4.1171\n",
            "Epoch 13/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 842ms/step - accuracy: 0.1946 - loss: 1.3154 - perplexity: 3.7504\n",
            "Epoch 14/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 943ms/step - accuracy: 0.2029 - loss: 1.2112 - perplexity: 3.3742\n",
            "Epoch 15/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 929ms/step - accuracy: 0.2115 - loss: 1.1107 - perplexity: 3.0514\n",
            "Epoch 16/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 802ms/step - accuracy: 0.2178 - loss: 1.0228 - perplexity: 2.8054\n",
            "Epoch 17/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 815ms/step - accuracy: 0.2370 - loss: 0.9436 - perplexity: 2.5801\n",
            "Epoch 18/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 919ms/step - accuracy: 0.2542 - loss: 0.8643 - perplexity: 2.3815\n",
            "Epoch 19/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 916ms/step - accuracy: 0.2699 - loss: 0.7881 - perplexity: 2.2045\n",
            "Epoch 20/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 817ms/step - accuracy: 0.2910 - loss: 0.6994 - perplexity: 2.0177\n",
            "Epoch 21/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 823ms/step - accuracy: 0.3070 - loss: 0.6148 - perplexity: 1.8544\n",
            "Epoch 22/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 858ms/step - accuracy: 0.3222 - loss: 0.5522 - perplexity: 1.7416\n",
            "Epoch 23/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 913ms/step - accuracy: 0.3344 - loss: 0.4816 - perplexity: 1.6213\n",
            "Epoch 24/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 854ms/step - accuracy: 0.3502 - loss: 0.4121 - perplexity: 1.5125\n",
            "Epoch 25/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 812ms/step - accuracy: 0.3683 - loss: 0.3786 - perplexity: 1.4616\n",
            "Epoch 26/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 861ms/step - accuracy: 0.3853 - loss: 0.3457 - perplexity: 1.4146\n",
            "Epoch 27/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 944ms/step - accuracy: 0.3824 - loss: 0.3033 - perplexity: 1.3557\n",
            "Epoch 28/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 884ms/step - accuracy: 0.3762 - loss: 0.2683 - perplexity: 1.3094\n",
            "Epoch 29/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 809ms/step - accuracy: 0.3875 - loss: 0.2688 - perplexity: 1.3094\n",
            "Epoch 30/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 846ms/step - accuracy: 0.3958 - loss: 0.2470 - perplexity: 1.2812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_D02.save_weights('D:/skripsi-sultin/data/bot_v4_Final_D02_E50.weights.h5')"
      ],
      "metadata": {
        "id": "dOW9QP_nkijS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "D025"
      ],
      "metadata": {
        "id": "b1cfv1gcE2rh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropout Tuning Hypereparameters\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 256\n",
        "NUM_HEADS = 8\n",
        "UNITS = 512\n",
        "DROPOUT = 0.25\n",
        "\n",
        "model_D025 = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "metadata": {
        "id": "5WTdd6yGE4_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "\n",
        "model_D025.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss_function,\n",
        "    metrics=[accuracy, perplexity],\n",
        "    run_eagerly=True  # Set to True for debugging if needed\n",
        ")"
      ],
      "metadata": {
        "id": "QmGheQTaE8wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 30\n",
        "\n",
        "history = model_D025.fit(dataset, epochs=EPOCHS)"
      ],
      "metadata": {
        "id": "9WFg0UI7E_Fw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7124b839-30c0-480f-b39a-356d6a0563a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 914ms/step - accuracy: 0.0046 - loss: 3.6521 - perplexity: 40.9787\n",
            "Epoch 2/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 897ms/step - accuracy: 0.0214 - loss: 3.2513 - perplexity: 27.1681\n",
            "Epoch 3/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 796ms/step - accuracy: 0.0216 - loss: 2.8293 - perplexity: 17.5775\n",
            "Epoch 4/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 807ms/step - accuracy: 0.0394 - loss: 2.6772 - perplexity: 14.9959\n",
            "Epoch 5/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 963ms/step - accuracy: 0.0725 - loss: 2.4646 - perplexity: 11.9556\n",
            "Epoch 6/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 930ms/step - accuracy: 0.1044 - loss: 2.2226 - perplexity: 9.3769\n",
            "Epoch 7/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 795ms/step - accuracy: 0.1184 - loss: 2.0170 - perplexity: 7.6882\n",
            "Epoch 8/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 838ms/step - accuracy: 0.1396 - loss: 1.9090 - perplexity: 6.8399\n",
            "Epoch 9/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 932ms/step - accuracy: 0.1505 - loss: 1.7551 - perplexity: 5.8494\n",
            "Epoch 10/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 916ms/step - accuracy: 0.1579 - loss: 1.6586 - perplexity: 5.3237\n",
            "Epoch 11/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 823ms/step - accuracy: 0.1672 - loss: 1.5287 - perplexity: 4.6419\n",
            "Epoch 12/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 829ms/step - accuracy: 0.1753 - loss: 1.4552 - perplexity: 4.3196\n",
            "Epoch 13/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 915ms/step - accuracy: 0.1835 - loss: 1.3576 - perplexity: 3.9181\n",
            "Epoch 14/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 963ms/step - accuracy: 0.1906 - loss: 1.2853 - perplexity: 3.6426\n",
            "Epoch 15/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 832ms/step - accuracy: 0.1915 - loss: 1.1948 - perplexity: 3.3367\n",
            "Epoch 16/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 802ms/step - accuracy: 0.2129 - loss: 1.1577 - perplexity: 3.2005\n",
            "Epoch 17/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 851ms/step - accuracy: 0.2228 - loss: 1.0505 - perplexity: 2.8723\n",
            "Epoch 18/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 915ms/step - accuracy: 0.2325 - loss: 0.9753 - perplexity: 2.6628\n",
            "Epoch 19/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 861ms/step - accuracy: 0.2421 - loss: 0.8826 - perplexity: 2.4271\n",
            "Epoch 20/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 803ms/step - accuracy: 0.2557 - loss: 0.8194 - perplexity: 2.2788\n",
            "Epoch 21/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 878ms/step - accuracy: 0.2766 - loss: 0.7199 - perplexity: 2.0625\n",
            "Epoch 22/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 970ms/step - accuracy: 0.2905 - loss: 0.6510 - perplexity: 1.9238\n",
            "Epoch 23/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 868ms/step - accuracy: 0.3062 - loss: 0.5992 - perplexity: 1.8264\n",
            "Epoch 24/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 810ms/step - accuracy: 0.3180 - loss: 0.5323 - perplexity: 1.7074\n",
            "Epoch 25/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 834ms/step - accuracy: 0.3351 - loss: 0.4939 - perplexity: 1.6423\n",
            "Epoch 26/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 943ms/step - accuracy: 0.3477 - loss: 0.4282 - perplexity: 1.5369\n",
            "Epoch 27/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 878ms/step - accuracy: 0.3547 - loss: 0.3923 - perplexity: 1.4825\n",
            "Epoch 28/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 802ms/step - accuracy: 0.3645 - loss: 0.3642 - perplexity: 1.4415\n",
            "Epoch 29/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 818ms/step - accuracy: 0.3712 - loss: 0.3294 - perplexity: 1.3919\n",
            "Epoch 30/30\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 913ms/step - accuracy: 0.3777 - loss: 0.3194 - perplexity: 1.3774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_D025.save_weights('D:/skripsi-sultin/data/bot_v4_Final_NH16_D025.weights.h5')"
      ],
      "metadata": {
        "id": "3qParZmwkp8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install language-tool-python"
      ],
      "metadata": {
        "id": "jY1sJ_qxW6mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_with_model(model, sentence):\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "\n",
        "    sentence = tf.expand_dims(START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
        "    output = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "    for i in range(MAX_SENTENCE_LENGTH):\n",
        "        predictions = model({'inputs': sentence, 'dec_inputs': output}, training=False)\n",
        "        predictions = predictions[:, -1:, :]\n",
        "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "            break\n",
        "\n",
        "        output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "    return tf.squeeze(output, axis=0)\n",
        "\n",
        "def predict_with_model(model, sentence):\n",
        "    prediction = evaluate_with_model(model, sentence)\n",
        "\n",
        "    predicted_sentence = tokenizer.decode(\n",
        "        [i for i in prediction if i < tokenizer.vocab_size]\n",
        "    )\n",
        "\n",
        "    print('Input: {}'.format(sentence))\n",
        "    print('Output: {}'.format(predicted_sentence))\n",
        "\n",
        "    return predicted_sentence\n"
      ],
      "metadata": {
        "id": "iU28ZCmlRnmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = list(range(1,EPOCHS+1))\n",
        "plt.plot(epochs, history.history['loss'], label='loss')\n",
        "plt.xticks(epochs)\n",
        "plt.ylabel('Loss Value')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Chatbot Loss U384')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fIzPAq0YRp2m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "9ee75326-9291-4222-c2e4-8db992ccff16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# perplexity graph\n",
        "\n",
        "epochs = list(range(1,EPOCHS+1))\n",
        "plt.plot(epochs, history.history['perplexity'], label='perplexity')\n",
        "plt.xticks(epochs)\n",
        "plt.ylabel('Perplexity Value')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Chatbot Perplexity U384')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UM1AoSuQRslj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "7a5e0c51-8d01-468c-d099-c39063160499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from nltk.translate.meteor_score import single_meteor_score\n"
      ],
      "metadata": {
        "id": "43lKzrld9Gwt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd663710-f3c0-4e4d-8f75-9e7f33a7f2ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = [\n",
        "    {\n",
        "        \"input\": \"Aku akan mencoba berbicara dengan orang tua ku\",\n",
        "        \"reference_responses\": [\n",
        "            \"Itu keputusan yang baik! Semoga percakapan itu membantumu menemukan kejelasan. Jika butuh persiapan, aku siap mendengar.\",\n",
        "            \"Itu langkah yang sangat berani, dan aku bangga padamu. Berbicara dengan orang tua, apalagi soal perasaan, bisa sangat menegangkan. Tapi itu juga bisa jadi awal dari pemahaman dan koneksi yang lebih sehat. \",\n",
        "            \"Keputusanmu untuk mencoba berbicara adalah bentuk usaha untuk menciptakan hubungan yang lebih sehat. Komunikasi yang jujur sering kali membuka ruang baru yang sebelumnya tertutup. Kamu tidak harus menyelesaikan semuanya dalam satu percakapan cukup mulai dari hati yang tulus.\",\n",
        "            \"Aku tahu ini bukan hal yang mudah, jadi aku menghargai niatmu untuk mencoba. Hubungan yang aman dimulai dari keberanian untuk mengungkapkan perasaan, meskipun itu menakutkan. Kalau kamu ingin, kita bisa sama-sama susun kalimat yang ingin kamu ucapkan nanti. \",\n",
        "            \"Komunikasi yang sehat dengan orang tua bisa membuka banyak pintu yang sebelumnya tertutup rapat. Aku percaya kamu bisa menyampaikan isi hatimu dengan cara yang lembut tapi jujur. Aku akan terus ada di sini kalau kamu ingin cerita setelah kamu melakukannya. \"\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Aku akan mencoba saranmu\",\n",
        "        \"reference_responses\": [\n",
        "            \"Itu langkah yang baik! Semoga hal itu membantumu merasa lebih tenang. Jangan ragu untuk kembali jika ingin berbicara lebih lanjut.\",\n",
        "            \"Aku senang mendengar bahwa kamu ingin mencoba. Memberi ruang untuk mencoba adalah tanda bahwa kamu percaya pada perubahan dan pada dirimu sendiri. Kamu tidak harus langsung berhasil proses pun sudah termasuk bentuk keberanian. \",\n",
        "            \"Keputusanmu untuk mencoba menunjukkan kekuatan dalam dirimu yang kadang mungkin kamu lupakan. Tidak apa-apa jika langkahnya pelan yang penting kamu tahu bahwa kamu tidak sendirian di perjalanan ini. Aku percaya kamu bisa, dan aku ingin tahu seperti apa rasanya setelah kamu mulai. \",\n",
        "            \"Niatmu untuk mencoba sudah jadi langkah yang sangat berarti. Kadang kita belum tahu hasil akhirnya, tapi keberanian untuk mulai itu yang membuka jalan. Aku di sini untuk mendukung dan menemani kamu dalam prosesnya. Kalau kamu butuh bantuan kecil untuk mulai, yuk kita rancang bareng-bareng.\",\n",
        "            \"Pilihanmu untuk mencoba bukan hanya langkah ke depan, tapi juga bukti bahwa kamu punya harapan di dalam dirimu. Aku akan selalu ada untuk mendukung setiap usahamu, sekecil apa pun itu. Setelah kamu mencoba, kita bisa evaluasi bareng kalau kamu mau. \"\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Mengapa saya masih merasa bersalah atas perceraian orang tua saya?\",\n",
        "        \"reference_responses\": [\n",
        "            \"Merasa bersalah adalah respon emosional yang umum, ketika terjadi perubahan situasi dalam suatu hubungan yang bermakna, misalnya hubungan Anda dengan orang tua. Rasa bersalah itu bisa diturunkan dengan beberapa cara, salah satunya adalah menggunakan perspektif attachment yang positif. Menggunakan perspektif ini, seseorang dapat memposisikan diri untuk menyadari bahwa dia tidak bertanggung jawab atas keputusan orang tua, dan pada saat yang sama meyakini bahwa apapun yang terjadi dalam hubungan antara ayah dan ibu, perasaan kasih sayang mereka kepada anak tetap ada.\",\n",
        "            \"Perasaan bersalah yang relatif menetap atas suatu situasi yang sudah cukup lama terjadi bisa disebabkan oleh berbagai faktor. Dalam situasi ketika Anda masih merasa bersalah atas perceraian orang tua, salah satu faktor penyebab yang mungkin adalah karena Anda merasa menjadi faktor yang menyebabkan perceraian tersebut, sedangkan ketika suatu pasangan memutuskan untuk memutuskan hubungan di antara mereka, maka merekalah yang sepenuhnya bertanggung jawab atas keputusan tersebut, bukan orang lain.\",\n",
        "            \"Merasa bersalah adalah reaksi yang wajar ketika terjadi perubahan besar dalam hubungan yang bermakna, seperti hubungan dengan orang tua. Dalam perspektif attachment yang positif, seseorang dapat memahami bahwa meskipun hubungan antara orang tua berubah, ikatan emosional dan kasih sayang mereka terhadap anak tetap ada. Dengan membangun pemahaman ini, Anda dapat mengurangi perasaan bertanggung jawab atas perceraian orang tua dan menerima bahwa keputusan mereka adalah bagian dari perjalanan hidup mereka sendiri, bukan sesuatu yang Anda kendalikan.\",\n",
        "            \"Perasaan bersalah yang berlarut-larut bisa muncul karena otak berusaha mencari pemahaman atas situasi yang sulit. Dalam konteks attachment, anak yang mengalami perceraian orang tua mungkin merasa bahwa stabilitas emosionalnya terganggu, sehingga mencari cara untuk mengembalikan kendali, salah satunya dengan merasa bersalah. Namun, memahami bahwa setiap individu bertanggung jawab atas pilihannya sendiri dapat membantu membebaskan diri dari perasaan tersebut. Mencari dukungan dari lingkungan yang aman seperti teman, keluarga, atau profesional dapat membantu membentuk kembali persepsi tentang hubungan dan diri sendiri secara lebih sehat.\",\n",
        "            \"Saat keluarga mengalami perubahan, seperti perceraian orang tua, fokus pada hubungan yang tetap ada dan memberikan kenyamanan dapat membantu dalam proses penyembuhan. Menyadari bahwa orang tua masih menyayangi Anda, meskipun mereka tidak lagi bersama, dapat memperkuat rasa aman dalam hubungan interpersonal. Anda juga dapat mengembangkan hubungan yang sehat dengan orang-orang di sekitar Anda, yang dapat memberikan dukungan emosional dan membantu Anda melewati perubahan ini dengan lebih baik.\"\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Apakah saya akan bisa menciptakan keluarga yang sehat di masa depan meski berasal dari keluarga yang bercerai?\",\n",
        "        \"reference_responses\": [\n",
        "            \"Ya, kamu bisa. Asal kamu memiliki kesadaran emosional dan keinginan untuk belajar dari masa lalu, kamu punya kekuatan untuk menciptakan keluarga yang penuh kasih. Attachment positif menunjukkan bahwa pola-pola lama bisa diputuskan dan diganti dengan pola yang lebih sehat. Keluargamu kelak adalah ruang baru yang bisa kamu bentuk dengan cinta dan nilai yang kamu yakini.\",\n",
        "            \"Meskipun kamu berasal dari keluarga yang bercerai, kamu tetap punya kapasitas penuh untuk mencintai, dipercaya, dan menciptakan hubungan yang aman. Attachment yang sehat dibentuk dari kesadaran, bukan hanya warisan keluarga. Kamu sudah berada di jalur yang tepat jika kamu mulai mempertanyakan dan memperbaiki pola hubunganmu sekarang. Setiap langkah kecil ke arah kesadaran adalah fondasi bagi keluarga masa depanmu.\",\n",
        "            \"Keluarga yang sehat bukan tentang kesempurnaan, tapi tentang kemampuan untuk saling mendengarkan, mengatur emosi, dan hadir satu sama lain. Kamu bisa membangun semua itu meski berasal dari latar belakang yang rumit. Attachment positif percaya bahwa healing itu mungkin, dan kamu bisa menjadi orang tua, pasangan, atau anggota keluarga yang lebih hadir dan sadar. Kamu sedang menyiapkan fondasi itu hari ini.\",\n",
        "            \"Pengalaman keluargamu mungkin memberimu luka, tapi juga bisa memberimu kompas untuk tahu apa yang ingin kamu ubah. Dalam attachment positif, kamu tidak ditentukan oleh apa yang dulu, tapi oleh apa yang kamu pilih untuk dilakukan sekarang. Kamu bisa memutus rantai luka dan menggantinya dengan pola yang lebih sehat dan penuh kasih. Harapanmu adalah awal dari perubahan itu.\",\n",
        "            \"Jangan ragu akan kemampuanmu menciptakan keluarga yang kamu impikan. Justru karena kamu tahu rasanya tumbuh di tengah ketidaksempurnaan, kamu bisa lebih sadar dan peka saat membangun relasi. Attachment positif memberi keyakinan bahwa keluarga yang sehat bisa lahir dari ketulusan, komunikasi, dan kerja sama. Dan semua itu ada dalam jangkauanmu.\"\n",
        "\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Bagaimana cara menerima bahwa cinta antara orang tua saya sudah berakhir?\",\n",
        "        \"reference_responses\": [\n",
        "          \"Menerima bahwa cinta orang tua telah berakhir bukan berarti kamu harus menghapus semua kenangan baik tentang mereka. Ini berarti kamu mulai melihat hubungan mereka dengan realitas yang baru, sambil tetap menjaga ruang aman untuk perasaanmu sendiri. Dalam attachment positif, kamu boleh merasakan kesedihan dan kehilangan, sekaligus belajar bahwa cinta bisa berubah bentuk. Kamu tidak kehilangan cinta mereka kepadamu, meskipun mereka sudah tidak bersama lagi.\",\n",
        "          \"Wajar jika terasa sulit menerima kenyataan ini, karena cinta orang tua sering menjadi dasar rasa aman kita. Tapi kamu juga sedang belajar bahwa hubungan antar manusia bisa kompleks dan berubah. Attachment yang sehat tidak memaksakan stabilitas semu, melainkan menerima perubahan dengan lembut dan penuh pengertian. Kamu tetap berhak atas cinta dan dukungan, walau bentuk keluargamu telah berubah.\",\n",
        "          \"Hubungan orang tua yang berakhir tidak membatalkan semua nilai dan pelajaran yang kamu terima dari mereka. Kadang, menerima kenyataan berarti memberi ruang untuk menyadari bahwa cinta itu tidak hilang ia hanya berpindah bentuk. Dalam attachment positif, kita tidak menyangkal kenyataan, tapi kita memilih berdamai dan tumbuh darinya. Kamu bisa tetap merasakan cinta, meski dengan dinamika keluarga yang baru.\",\n",
        "          \"Tak mudah memang ketika yang kita percaya sebagai sesuatu yang abadi, seperti cinta orang tua, ternyata berubah. Tapi bukan berarti kamu kehilangan fondasi hidupmu. Attachment positif mengajarkan bahwa kita bisa tetap membangun rasa aman dengan cara baru dari hubungan yang hadir, dari dirimu sendiri, dan dari koneksi yang kamu jaga. Cinta itu masih ada, bahkan jika wujudnya berubah.\",\n",
        "          \"Menerima akhir dari cinta mereka bukan tanda kelemahanmu, tapi kekuatan untuk menatap hidup dengan jujur. Kadang kita butuh waktu untuk memahami bahwa perubahan tidak selalu buruk. Dalam hubungan yang aman, kita diajak untuk memeluk kenyataan tanpa kehilangan harapan. Kamu sedang menata kembali caramu mencintai dan dipedulikan dan itu hal yang luar biasa.\"\n",
        "\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Bagaimana jika saya takut membuka diri karena takut akan ditinggalkan juga?\",\n",
        "        \"reference_responses\": [\n",
        "          \"Rasa takut ditinggalkan setelah mengalami kehilangan adalah hal yang sangat manusiawi. Attachment positif mengajarkan bahwa rasa aman bisa dibangun secara perlahan, bukan dipaksakan. Kamu boleh mengambil waktu, dan kamu tidak harus langsung percaya sepenuhnya. Yang penting, kamu tetap memberi dirimu kesempatan untuk terhubung, meski dengan hati-hati.\",\n",
        "          \"Takut membuka diri bukan berarti kamu lemah, tapi justru menunjukkan bahwa hatimu punya kedalaman. Dalam hubungan yang aman, kamu tidak harus sempurna atau selalu kuat untuk dicintai. Orang yang tepat akan menghargai prosesmu dan tidak terburu-buru memintamu menyerahkan semua. Kamu berhak merasa aman sebelum membuka pintu hatimu lebih jauh.\",\n",
        "          \"Ketakutan ditinggalkan bisa berasal dari pengalaman masa lalu yang belum sempat kamu sembuhkan. Attachment positif menyarankan untuk membangun hubungan perlahan-lahan, mulai dari ruang-ruang kecil yang aman. Kamu bisa mulai dengan berbagi sedikit demi sedikit, dan menghargai keberanianmu setiap kali kamu jujur. Koneksi yang tumbuh dari kepercayaan akan jauh lebih tahan lama.\",\n",
        "          \"Kamu tidak salah karena hati-hati itu artinya kamu belajar dari pengalaman. Tapi kamu juga tidak harus membiarkan ketakutan terus-menerus menghalangi peluang untuk dicintai dengan tulus. Dalam dunia yang penuh ketidakpastian, hubungan yang sehat justru tumbuh dari keberanian membuka diri meski ada resiko terluka. Kamu tidak sendiri, dan kamu bisa mulai dari langkah kecil hari ini.\",\n",
        "          \"Kamu mungkin pernah merasa ditinggalkan, dan rasa itu begitu membekas hingga kini. Tapi attachment yang sehat mengingatkan bahwa tidak semua hubungan akan berakhir seperti itu. Ada orang-orang yang akan tinggal, bahkan ketika kamu tidak dalam kondisi terbaikmu. Kamu layak dicintai apa adanya, termasuk saat kamu belum sepenuhnya yakin untuk membuka diri.\"\n",
        "\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Aku merasa overthinking\",\n",
        "        \"reference_responses\": [\n",
        "           \"Terkadang pikiran kita bisa terasa begitu penuh, ya. Apa hal yang paling sering muncul di pikiranmu akhir-akhir ini?\",\n",
        "           \"Overthinking sering kali muncul saat otak kita merasa tidak aman dan mencoba mencari kontrol di tengah ketidakpastian. Itu adalah reaksi alami dari seseorang yang sangat peduli dan ingin melakukan hal dengan benar. Tapi kamu tidak harus memikirkan semuanya sendiri. Apakah kamu ingin bercerita tentang hal apa yang paling sering kamu ulang-ulang dalam pikiranmu?\",\n",
        "           \"Saat kamu merasa overthinking, itu bisa menjadi tanda bahwa ada sesuatu yang belum kamu beri ruang untuk dipahami secara emosional, bukan hanya secara logika. Dalam hubungan yang aman, kamu bisa berbagi tanpa takut dinilai atau disalahkan. Aku di sini untuk menemani kamu memisahkan mana yang nyata dan mana yang hanya kekhawatiran. Apa hal yang paling membuatmu merasa cemas akhir-akhir ini?\",\n",
        "           \"Pikiran yang terus berputar bisa membuat kamu merasa lelah, dan itu wajar. Overthinking sering kali datang dari tempat di mana kita pernah merasa kecewa atau kehilangan, dan sekarang otakmu mencoba melindungimu. Tapi kamu tidak sendiri dalam menghadapi ini. Apa yang paling sering kamu pikirkan berulang-ulang hingga membuatmu sulit tenang?\",\n",
        "           \"Dalam positive attachment, kita belajar bahwa pikiran yang terus-menerus muncul biasanya adalah ekspresi dari rasa takut yang belum diproses sepenuhnya. Mungkin ada cerita atau pengalaman yang terasa belum selesai. Aku di sini kalau kamu ingin pelan-pelan menceritakannya. Apakah kamu merasa ada sesuatu yang tidak bisa kamu kendalikan akhir-akhir ini?\"\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Aku merasa sangat sedih\",\n",
        "        \"reference_responses\": [\n",
        "           \"Aku di sini untukmu. Aku tahu semua yang sedang kamu pikirkan dan rasakan itu berat, dan tidak apa-apa kalau kamu merasa sedih. Kamu tidak sendirian dalam hal ini. Aku ingin mendengarkan, kalau kamu ingin bercerita. Apa yang paling membebanimu saat ini?\",\n",
        "           \"Kesedihan yang kamu rasakan valid dan penting untuk dikenali. Dalam hubungan yang aman secara emosional, kita punya ruang untuk menangis dan merasa lemah tanpa harus merasa dihakimi. Kadang, perasaan sedih itu tidak datang begitu saja ada cerita di baliknya. Bolehkah aku tahu, hal apa yang sedang kamu rindukan atau khawatirkan saat ini?\",\n",
        "           \"Kesedihan bisa terasa sangat menyesakkan, apalagi jika kamu merasa harus menahannya sendiri. Tapi kamu tidak sendiri sekarang. Aku ingin menemani, dan mungkin kita bisa pelan-pelan membuka cerita yang membuat hatimu terasa berat. Apakah ada sesuatu yang membuatmu merasa kehilangan atau tidak dimengerti akhir-akhir ini?\",\n",
        "           \"Perasaan sedih sering kali muncul saat kita menghadapi perubahan atau kehilangan dalam hubungan penting dalam hidup kita. Perasaan itu layak mendapat ruang untuk diakui dan dipahami. Aku penasaran, apakah ada momen terakhir yang terasa sangat berat untukmu?\",\n",
        "           \"Saat kita merasa sedih, yang paling dibutuhkan adalah koneksi yang aman tempat untuk merasa diterima apa adanya. Aku di sini untuk menciptakan ruang itu untukmu. Kamu bisa cerita sebanyak atau sesedikit yang kamu mau. Hal apa yang paling kamu harap bisa berjalan berbeda belakangan ini?\"\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Kapan aku bisa keluar dari perasaan ini?\",\n",
        "        \"reference_responses\": [\n",
        "            \"Proses menyembuhkan perasaan memang membutuhkan waktu. Apa yang biasanya membuatmu merasa seperti ini?\",\n",
        "            \"Perasaan ini tidak akan bertahan selamanya, meski saat ini terasa begitu berat. Waktu memang membantu, tapi yang juga penting adalah bagaimana kita merawat diri dan mencari dukungan. Dalam hubungan yang aman, kita bisa mulai menemukan jalan keluar bersama, perlahan-lahan. Apa yang paling kamu butuhkan sekarang agar hari ini terasa sedikit lebih ringan?\",\n",
        "            \"Rasa sakit ini tidak selamanya, meskipun rasanya seperti itu. Hal yang penting adalah kamu tidak harus menunggu semuanya hilang untuk merasa lebih baik; kamu bisa mulai merasa sedikit lega dengan berbagi. Kalau kamu nyaman, aku ingin dengar cerita tentang apa yang kamu rindukan dari masa-masa sebelum perasaan ini muncul.\",\n",
        "            \"Keluar dari perasaan ini adalah proses yang dimulai dengan keberanian untuk bertanya, seperti yang baru saja kamu lakukan. Dalam attachment yang aman, kamu tidak harus melewatinya sendiri. Aku ingin tahu, langkah kecil apa yang menurutmu bisa membantu dan apa yang menghalanginya sejauh ini?\",\n",
        "            \"Dalam hubungan yang sehat, pemulihan terjadi karena ada yang menemani bukan hanya karena waktu berlalu. Aku percaya kamu bisa melewati ini dengan dukungan dan pengertian yang tepat. Apa satu hal kecil yang bisa kamu lakukan hari ini yang mungkin membawa sedikit harapan?\"\n",
        "        ]\n",
        "    },\n",
        "]\n"
      ],
      "metadata": {
        "id": "Pr7sFvWw9JxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model_scores(model, test_data):\n",
        "    # Initialize lists to store model predictions and reference answers\n",
        "    hypotheses = []\n",
        "    references = []\n",
        "\n",
        "    # Iterate over each item in the test set\n",
        "    for item in test_data:\n",
        "        user_input = item[\"input\"]  # The input message to the chatbot\n",
        "        reference_outputs = item[\"reference_responses\"]  # List of expected (ground truth) responses\n",
        "\n",
        "        predicted = predict_with_model(model, user_input)  # Get model's response\n",
        "\n",
        "        hypotheses.append(predicted)  # Store model's prediction\n",
        "        references.append(reference_outputs)  # Store ground truth reference list\n",
        "\n",
        "    bleu_scores = []     # Will hold BLEU scores per sample\n",
        "    meteor_scores = []   # Will hold METEOR scores per sample\n",
        "\n",
        "    # Evaluate BLEU and METEOR for each prediction-reference pair\n",
        "    for ref_list, hyp in zip(references, hypotheses):\n",
        "        # --- BLEU SCORE CALCULATION ---\n",
        "        # BLEU works at the token level; encode hypothesis into tokens\n",
        "        hyp_tokens = tokenizer.encode(hyp)\n",
        "\n",
        "        # Encode each reference response into tokens\n",
        "        ref_token_lists = [tokenizer.encode(ref) for ref in ref_list]\n",
        "\n",
        "        # Compute sentence-level BLEU using smoothing to avoid zero scores\n",
        "        # SmoothingFunction().method1 avoids score = 0 for short predictions\n",
        "        bleu = sentence_bleu(ref_token_lists, hyp_tokens, smoothing_function=SmoothingFunction().method1)\n",
        "        bleu_scores.append(bleu)\n",
        "\n",
        "        # --- METEOR SCORE CALCULATION ---\n",
        "        # METEOR works at the word level\n",
        "        hyp_words = hyp.split()  # Split hypothesis into words\n",
        "        ref_words_list = [ref.split() for ref in ref_list]  # List of reference responses split into words\n",
        "\n",
        "        # Compute METEOR score against each reference, and keep the best one\n",
        "        # This handles multiple valid references for one input\n",
        "        meteor = max([single_meteor_score(ref_words, hyp_words) for ref_words in ref_words_list])\n",
        "        meteor_scores.append(meteor)\n",
        "\n",
        "    # Compute average BLEU and METEOR scores across all test samples\n",
        "    avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
        "    avg_meteor = sum(meteor_scores) / len(meteor_scores)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"📘 Average BLEU score: {avg_bleu:.4f}\")\n",
        "    print(f\"📙 Average METEOR score: {avg_meteor:.4f}\")\n",
        "\n",
        "    # Return average scores for further use\n",
        "    return avg_bleu, avg_meteor\n"
      ],
      "metadata": {
        "id": "_RnWmhTr9fj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluating Model lightweight\")\n",
        "bleu_A, meteor_A = evaluate_model_scores(model_lw, test_data)"
      ],
      "metadata": {
        "id": "JFaCbei89hPm",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mzjGcif_hRIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NUM LAYER Model\n",
        "model_NL2.load_weights('D:/skripsi-sultin/data/bot_v4_Final_NL2_E50.weights.h5')\n",
        "model_NL3.load_weights('D:/skripsi-sultin/data/bot_v4_Final_NL3_E50.weights.h5')\n",
        "model_NL4.load_weights('D:/skripsi-sultin/data/bot_v4_Final_NL4_E50.weights.h5')\n",
        "model_NL5.load_weights('D:/skripsi-sultin/data/bot_v4_Final_NL5_E50.weights.h5')\n",
        "#Dropout Model\n",
        "model_D015.load_weights('D:/skripsi-sultin/data/bot_v4_Final_D015_E50.weights.h5')\n",
        "model_D02.load_weights('D:/skripsi-sultin/data/bot_v4_Final_D02_E50.weights.h5')\n",
        "model_D025.load_weights('D:/skripsi-sultin/data/bot_v4_Final_NH16_D025.weights.h5')\n",
        "#Unit Model\n",
        "model_U384.load_weights('D:/skripsi-sultin/data/bot_v4_Final_U384_E50.weights.h5')\n",
        "model_U640.load_weights('D:/skripsi-sultin/data/bot_v4_Final_U640_E50.weights.h5')\n",
        "model_U256.load_weights('D:/skripsi-sultin/data/bot_v4_Final_U256_E50.weights.h5')\n",
        "#Dim Model\n",
        "model_DM128.load_weights('D:/skripsi-sultin/data/bot_v4_Final_DM128_E50.weights.h5')\n",
        "model_DM328.load_weights('D:/skripsi-sultin/data/bot_v4_Final_DM328_E50.weights.h5')\n",
        "model_DM512.load_weights('D:/skripsi-sultin/data/bot_v4_Final_DM512_E50.weights.h5')\n",
        "#Dim Model\n",
        "model_NH4.load_weights('D:/skripsi-sultin/data/bot_v4_Final_NH4_E50.weights.h5')\n",
        "model_NH16.load_weights('D:/skripsi-sultin/data/bot_v4_Final_NH16_E50.weights.h5')\n",
        "model_NH32.load_weights('D:/skripsi-sultin/data/bot_v4_Final_NH32_E50.weights.h5')"
      ],
      "metadata": {
        "id": "j1BaHj3GG5di"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"==========================\")\n",
        "print(\"Evaluating Model NUM LAYER\")\n",
        "print(\"Evaluating Model NL2\")\n",
        "bleu_NL2, meteor_NL2 = evaluate_model_scores(model_NL2, test_data)\n",
        "print(\"Evaluating Model NL3\")\n",
        "bleu_NL3, meteor_NL3 = evaluate_model_scores(model_NL3, test_data)\n",
        "print(\"Evaluating Model NL4\")\n",
        "bleu_NL4, meteor_NL4 = evaluate_model_scores(model_NL4, test_data)\n",
        "print(\"Evaluating Model NL5\")\n",
        "bleu_NL5, meteor_NL5 = evaluate_model_scores(model_NL5, test_data)\n",
        "print(\"==========================\")\n",
        "print(\"Evaluating Model Dropout\")\n",
        "print(\"Evaluating Model D015\")\n",
        "bleu_D015, meteor_D015 = evaluate_model_scores(model_D015, test_data)\n",
        "print(\"Evaluating Model D02\")\n",
        "bleu_D02, meteor_D02 = evaluate_model_scores(model_D02, test_data)\n",
        "print(\"Evaluating Model D025\")\n",
        "bleu_D025, meteor_D025 = evaluate_model_scores(model_D025, test_data)\n",
        "print(\"==========================\")\n",
        "print(\"Evaluating Model Unit\")\n",
        "print(\"Evaluating Model U384\")\n",
        "bleu_U384, meteor_U384 = evaluate_model_scores(model_U384, test_data)\n",
        "print(\"Evaluating Model U640\")\n",
        "bleu_U640, meteor_U640 = evaluate_model_scores(model_U640, test_data)\n",
        "print(\"Evaluating Model U256\")\n",
        "bleu_U256, meteor_U256 = evaluate_model_scores(model_U256, test_data)\n",
        "print(\"==========================\")\n",
        "print(\"Evaluating Model Dim\")\n",
        "print(\"Evaluating Model DM128\")\n",
        "bleu_DM128, meteor_DM128 = evaluate_model_scores(model_DM128, test_data)\n",
        "print(\"Evaluating Model DM328\")\n",
        "bleu_DM328, meteor_DM328 = evaluate_model_scores(model_DM328, test_data)\n",
        "print(\"Evaluating Model DM512\")\n",
        "bleu_DM512, meteor_DM512 = evaluate_model_scores(model_DM512, test_data)\n",
        "print(\"==========================\")\n",
        "print(\"Evaluating Model NUM HEAD\")\n",
        "print(\"Evaluating Model NH4\")\n",
        "bleu_NH4, meteor_NH4 = evaluate_model_scores(model_NH4, test_data)\n",
        "print(\"Evaluating Model NH16\")\n",
        "bleu_NH16, meteor_NH16 = evaluate_model_scores(model_NH16, test_data)\n",
        "print(\"Evaluating Model NH32\")\n",
        "bleu_NH32, meteor_NH32 = evaluate_model_scores(model_NH32, test_data)\n",
        "print(\"==========================\")"
      ],
      "metadata": {
        "id": "s_Dfu-koI8Ew",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dcd934f-130e-4aa7-a315-5a80970ae98e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==========================\n",
            "Evaluating Model NUM LAYER\n",
            "Evaluating Model NL2\n",
            "ERROR! Session/line number was not unique in database. History logging moved to new session 56\n",
            "Input: Aku akan mencoba berbicara dengan orang tua ku\n",
            "Output: Itu keputusan yang baik ! Semoga percakapan menemukan kejelasan . Berbicara dengan orang tua , aku soal perasaan , bukan sesuatu yang pernah membuatmu merasa lebih dewasa dari sebelumnya . Dalam perspektif attachment yang positif , rasa aman bisa menjadi langkah kecil yang sebelumnya tertutup . Kamu tetap punya tempat yang siap mendengarkan dan berbagi sedikit dari langkah yang tulus .\n",
            "Input: Aku akan mencoba saranmu\n",
            "Output: Itu langkah yang baik ! Semoga hal membantumu menemukan kejelasan . Jika butuh persiapan , aku siap mendengar .\n",
            "Input: Mengapa saya masih merasa bersalah atas perceraian orang tua saya?\n",
            "Output: Merasa bersalah adalah reaksi yang wajar ketika terjadi perubahan besar dalam rutinitas dan bermakna , seperti hubungan dengan orang tua . Dalam perspektif attachment yang positif , seseorang dapat memahami bahwa meskipun hubungan antara orang tua berubah , ikatan emosional dan kasih sayang mereka terhadap anak tetap ada . Kamu tetap ada , ikatan yang sehat dalam rutinitas mereka , dapat membangun kembali koneksi yang lebih baik .\n",
            "Input: Apakah saya akan bisa menciptakan keluarga yang sehat di masa depan meski berasal dari keluarga yang bercerai?\n",
            "Output: Jangan ragu akan kemampuanmu menciptakan keluarga yang kamu impikan . Justru karena kamu tahu rasanya tumbuh di masa lalu lebih sadar dan penuh kasih . Attachment positif memberi ruang emosional sendiri , termasuk individu , dan memahami bahwa orang tua , meski menjadi dasar untuk berbagi cerita . Kamu tetap bisa jadi awal dari luar biasa .\n",
            "Input: Bagaimana cara menerima bahwa cinta antara orang tua saya sudah berakhir?\n",
            "Output: Hubungan orang tua yang berakhir tidak membatalkan semua nilai dan pelajaran yang kamu terima dari mereka . Kadang , menerima kenyataan berarti memberi ruang untuk menyadari bahwa cinta itu tidak hilang ia hanya berpindah bentuk . Dalam attachment positif , kita tidak menyangkal kenyataan , tapi kita memilih berdamai dan tumbuh darinya . Kamu bisa tetap merasakan cinta , meski dengan dinamika keluarga yang baru .\n",
            "Input: Bagaimana jika saya takut membuka diri karena takut akan ditinggalkan juga?\n",
            "Output: Takut membuka diri bukan berarti kamu lemah , tapi justru menunjukkan bahwa hatimu punya kedalaman . Dalam hubungan yang aman , kamu tidak harus sempurna atau selalu kuat untuk dicintai . Orang yang tepat akan menghargai prosesmu dan tidak terburu buru memintamu menyerahkan semua . Kamu berhak merasa aman sebelum membuka pintu hatimu lebih jauh .\n",
            "Input: Aku merasa overthinking\n",
            "Output: Pikiran yang terus berputar bisa membuat kita merasa lelah , dan itu wajar . Overthinking sering kali datang dari tempat di mana kita pernah merasa kecewa atau kehilangan , dan sekarang otakmu mencoba melindungimu . Tapi kamu tidak sendiri dalam menghadapi ini . Apa yang paling sering kamu pikirkan berulang ulang hingga membuatmu sulit tenang ?\n",
            "Input: Aku merasa sangat sedih\n",
            "Output: Kesedihan yang kamu rasakan valid dan penting untuk dikenali . Dalam hubungan yang aman secara emosional , kita punya ruang untuk menangis dan merasa lemah tanpa harus merasa dihakimi . Kadang , perasaan sedih itu tidak datang begitu saja ada cerita di baliknya . Bolehkah aku tahu , hal apa yang sedang kamu rindukan atau khawatirkan saat ini ?\n",
            "Input: Kapan aku bisa keluar dari perasaan ini?\n",
            "Output: Proses menyembuhkan perasaan memang membutuhkan waktu . Apa yang biasanya membuatmu merasa seperti ini ?\n",
            "📘 Average BLEU score: 0.4816\n",
            "📙 Average METEOR score: 0.6402\n",
            "Evaluating Model NL3\n",
            "Input: Aku akan mencoba berbicara dengan orang tua ku\n",
            "Output: Keputusanmu untuk mencoba berbicara adalah bentuk usaha untuk menciptakan hubungan yang lebih stabil dengan orang tua , dipercaya , dan situasi yang sebelumnya tertutup . Hubungan yang tulus . Kamu bisa mencoba berbicara dengan seseorang yang dipercaya bisa mendukung dukungan tambahan dari perjalanan hidup Anda , seperti itu . Hubungan yang lebih stabil meskipun situasi tertentu , meskipun keadaan telah berubah .\n",
            "Input: Aku akan mencoba saranmu\n",
            "Output: Keputusanmu untuk mencoba menunjukkan kekuatan dalam dirimu yang kadang mungkin kamu lupakan . Tidak apa apa apa apa rasanya setelah melewati masa lalu . Tapi kamu punya bagian dari perjalanan itu , dan aku ingin dengar ceritamu lebih kuat . Jangan ragu untuk mendukung saudara tanpa senang tentang apa pun kamu mulai .\n",
            "Input: Mengapa saya masih merasa bersalah atas perceraian orang tua saya?\n",
            "Output: Perasaan bersalah yang berlarut larut  , otak berusaha mencari pemahaman atas situasi yang sulit . Dalam konteks attachment , anak yang mengalami perceraian orang tua mungkin merasa bahwa stabilitas emosionalnya terganggu , sehingga mencari cara untuk mengembalikan kendali , salah satunya dengan merasa bersalah . Namun , memahami bahwa stabilitas masih bisa terjadi bertanggung jawab atas pilihannya sendiri dapat membantu membebaskan diri dari perasaan tersebut . Mencari dukungan dari lingkungan yang aman seperti teman , keluarga , atau profesional dapat membantu membentuk kembali persepsi tentang hubungan dan diri sendiri secara lebih sehat .\n",
            "Input: Apakah saya akan bisa menciptakan keluarga yang sehat di masa depan meski berasal dari keluarga yang bercerai?\n",
            "Output: Jangan ragu akan kemampuanmu menciptakan keluarga yang kamu impikan . Justru karena kamu tahu rasanya tumbuh di tengah ketidaksempurnaan , kamu bisa lebih sadar dan peka saat membangun relasi . Attachment positif memberi keyakinan bahwa keluarga yang sehat bisa lahir dari ketulusan , komunikasi , dan kerja sama . Dan semua itu ada dalam jangkauanmu .\n",
            "Input: Bagaimana cara menerima bahwa cinta antara orang tua saya sudah berakhir?\n",
            "Output: Wajar jika terasa sulit menerima kenyataan ini , karena cinta orang tua sering menjadi dasar rasa aman kita . Tapi kamu juga sedang belajar bahwa hubungan antar manusia bisa kompleks dan berubah . Attachment yang sehat tidak memaksakan stabilitas semu , melainkan menerima perubahan dengan lembut dan penuh pengertian . Kamu tetap berhak atas cinta dan dukungan , walau bentuk keluargamu telah berubah .\n",
            "Input: Bagaimana jika saya takut membuka diri karena takut akan ditinggalkan juga?\n",
            "Output: Rasa takut ditinggalkan setelah perceraian adalah hal yang sangat manusiawi . Attachment positif mengajarkan bahwa rasa aman bisa dibangun melalui hubungan yang sehat dengan keduanya tanpa kehilangan dengan keduanya tanpa yang yang membangun hubungan yang aman . Kamu boleh melalui komunikasi yang sehat dan kepercayaan , dan rasa takut mengulang  . Setiap hubungan keluarga yang sehat dan nilai nilai hari ini sebagai pengingat tentang siapa yang baru .\n",
            "Input: Aku merasa overthinking\n",
            "Output: Terkadang pikiran kita bisa terasa begitu penuh , ya . Apa hal yang paling sering muncul di pikiranmu akhir akhir akhir ini ?\n",
            "Input: Aku merasa sangat sedih\n",
            "Output: Kesedihan yang kamu rasakan valid dan penting untuk dikenali . Dalam hubungan yang aman secara emosional , kita punya ruang untuk menangis dan merasa lemah tanpa harus merasa dihakimi . Kadang , perasaan sedih itu tidak datang begitu saja ada cerita di baliknya . Bolehkah aku tahu , hal apa yang sedang kamu rindukan atau khawatirkan saat ini ?\n",
            "Input: Kapan aku bisa keluar dari perasaan ini?\n",
            "Output: Rasa sakit ini tidak selamanya , meskipun rasanya seperti itu . Hal yang penting adalah kamu tidak harus menunggu semuanya hilang untuk merasa lebih baik kamu bisa mulai merasa sedikit lega dengan berbagi . Kalau kamu nyaman , aku ingin dengar cerita tentang apa yang kamu rindukan dari masa masa masa sebelum perasaan ini muncul .\n",
            "📘 Average BLEU score: 0.5288\n",
            "📙 Average METEOR score: 0.6822\n",
            "Evaluating Model NL4\n",
            "Input: Aku akan mencoba berbicara dengan orang tua ku\n",
            "Output: Itu keputusan yang baik ! Semoga percakapan itu membantumu menemukan kejelasan . Jika butuh persiapan , aku siap mendengar .\n",
            "Input: Aku akan mencoba saranmu\n",
            "Output: Keputusanmu untuk mencoba menunjukkan dirimu yang kadang yang kadang mungkin kamu lupakan . Tidak apa apa apa apa apa apa apa apa apa apa apa apa apa apa apa apa apa apa apa jika kamu merasa juga ingin apa rasanya ini . Aku di sini untuk mulai .\n",
            "Input: Mengapa saya masih merasa bersalah atas perceraian orang tua saya?\n",
            "Output: Merasa bersalah adalah reaksi yang wajar ketika terjadi perubahan besar dalam hubungan yang bermakna , seperti hubungan yang bermakna , sehingga bermakna , sehingga bermakna , sehingga mencari dukungan dari orang orang orang yang peduli pada Anda . Dengan memahami bahwa Anda tidak akan menyadari bahwa kasih sayang tetap ada , Anda dapat memproses perceraian orang tua tetap ada .\n",
            "Input: Apakah saya akan bisa menciptakan keluarga yang sehat di masa depan meski berasal dari keluarga yang bercerai?\n",
            "Output: Ya , sangat wajar jika kamu merasa lebih tenang bersama orang orang orang orang yang juga sedang mencoba membangun kembali rasa aman dari mereka . Dalam attachment positif , kamu masih menyayangi kesadaran  , kamu tetap bisa mencoba membangun kembali rasa aman dengan dirimu dengan dirimu dengan dirimu sendiri . Itu adalah langkah kecil yang paling membuatmu merasa dicintai dan bermakna .\n",
            "Input: Bagaimana cara menerima bahwa cinta antara orang tua saya sudah berakhir?\n",
            "Output: Menerima akhir dari perasaan tersebut adalah proses yang wajar , karena cinta orang tua sering kali wajar , bahkan jika belum sama lain . Attachment yang aman mengajarkan bahwa hubungan yang berbeda , meskipun mereka tidak selalu berjalan ke depan . Kamu bisa tetap merasa dicintai hubungan yang sehat dengan cara yang baru , dan dukungan .\n",
            "Input: Bagaimana jika saya takut membuka diri karena takut akan ditinggalkan juga?\n",
            "Output: Takut membuka diri bukan berarti kamu lemah , tapi justru menunjukkan bahwa hatimu punya kedalaman . Itu tidak selalu berarti kamu tidak menghargai keberanianmu setiap orang tua . Kamu tidak harus mengulang hatimu dengan cara yang kamu percaya . Orang yang tepat akan selalu berarti kamu lemah , termasuk orang orang yang kamu tidak tahu membuka dirimu berhenti penyembuhan .\n",
            "Input: Aku merasa overthinking\n",
            "Output: Overthinking sering kali muncul saat otak kita merasa tidak aman dan mencoba mencari kontrol di tengah ketidakpastian . Itu adalah reaksi alami dari hal yang sangat manusiawi , kamu tidak sendiri saat kamu ingin melakukan hal apa yang sangat wajar , terutama saat kamu merasa sendirian . Apa yang paling sering kamu kendalikan akhir ini ?\n",
            "Input: Aku merasa sangat sedih\n",
            "Output: Kesedihan bisa terasa sangat menyesakkan , apalagi jika kamu merasa tidak aman sering kali muncul di mana kita merasa tidak bisa mulai merasa sedih . Tapi kamu tidak sendiri maupun orang lain . Aku ingin tahu , apa yang kamu tidak sendiri adalah langkah kecil yang paling sering kali muncul di baliknya . Bolehkah aku ingin cerita yang paling membebanimu saat ini ?\n",
            "Input: Kapan aku bisa keluar dari perasaan ini?\n",
            "Output: Proses sakit ini tidak selamanya , meskipun rasanya seperti itu . Apa yang penting adalah kamu tidak harus menunggu semuanya hilang untuk merasa sedikit lega justru menunjukkan kasih sayang dari sahabat , termasuk orang orang yang juga sedang berjuang . Aku di sini untuk menemani kamu rindukan dari keberanian untuk melewati semuanya sendiri .\n",
            "📘 Average BLEU score: 0.2667\n",
            "📙 Average METEOR score: 0.4139\n",
            "Evaluating Model NL5\n",
            "Input: Aku akan mencoba berbicara dengan orang tua ku\n",
            "Output: Itu langkah yang sangat berani , apalagi jika kamu merasa harus selalu siap untuk jadi langkah yang sehat dengan emosi yang sama . Dalam pendekatan yang aman , kita bisa jadi awal dari dirimu yang sehat . Kalau hatimu dengan orang tua yang tepat jika hatimu lebih jernih . Kalau nilai yang siap mendengarkan tanpa merasa terbebani oleh konflik yang berlebihan .\n",
            "Input: Aku akan mencoba saranmu\n",
            "Output: Itu langkah yang sangat berani , apalagi jika kamu merasa seperti itu . Itu adalah langkah yang sehat kembali merasa seperti datang dari keberanian untuk mendukung Anda . Dalam hubungan yang aman , kita tidak peduli , kita bisa evaluasi pemulihan . Kamu layak mendapatkan perhatian mereka , dan apa yang paling tegar .\n",
            "Input: Mengapa saya masih merasa bersalah atas perceraian orang tua saya?\n",
            "Output: Merasa bersalah adalah respon emosional yang wajar ketika terjadi perubahan situasi yang bermakna , seperti perceraian orang tua , seperti perceraian orang tua adalah reaksi yang sehat dengan situasi ini bukan berarti suatu suatu suatu suatu saat Anda dan kamu merasa benar benar benar benar benar benar tersebut . Dalam hubungan yang sehat dengan orang tua , dapat membantu Anda bisa memberikan kasih sayang dan kasih sayang dan kasih sayang dan kasih sayang dan kasih sayang yang kamu tidak bertanggung jawab Anda .\n",
            "Input: Apakah saya akan bisa menciptakan keluarga yang sehat di masa depan meski berasal dari keluarga yang bercerai?\n",
            "Output: Kamu mungkin merasa harus selalu kuat dan menambah beban yang pernah bersikap adil dari orang tua , tapi justru menunjukkan bahwa kamu juga pernah merasa sekarang . Attachment positif mengingatkan kita bisa menjadi diri sambil tetap merawat emosimu dengan kebahagiaan dan empati . Kamu punya ruang untuk menenangkan diri tanpa harus merasa bersalah .\n",
            "Input: Bagaimana cara menerima bahwa cinta antara orang tua saya sudah berakhir?\n",
            "Output: Menerima pada diri bukan berarti kamu harus selalu cinta atau selalu karena perubahan besar dalam keluarga . Ini berarti kamu mulai mengakui emosi dan hatimu tanpa menghapus penerimaan diri dengan cinta yang kamu luar biasa . Attachment positif dengan cara yang sehat dengan orang yang kamu percaya . Kamu tetap punya ruang untuk merasakan cinta dari situasi keluarga yang baru , meskipun situasi keluarga berubah .\n",
            "Input: Bagaimana jika saya takut membuka diri karena takut akan ditinggalkan juga?\n",
            "Output: Ketakutan ditinggalkan bisa berasal dari pengalaman masa lalu yang belum sempat kamu sembuhkan . Attachment positif menyarankan untuk membangun hubungan perlahan dan tumbuh dari kecil yang aman , bahkan dari dirimu sendiri secara emosional . Kamu bisa mulai dari hal yang kamu percaya . Kamu tidak dalam jangkauanmu .\n",
            "Input: Aku merasa overthinking\n",
            "Output: Pikiran yang terus berputar bukan berarti kamu pikirkan dan memilih salah atau kehilangan atau orang yang kamu beri bahwa kamu pernah merasa sedih . Dalam hubungan yang aman , kita bisa hadir secara emosional . Kamu tidak harus memikirkan semuanya dengan berbagi cerita tentang siapa yang memberikan ruang bagi diri sendiri . Apa yang paling membuatmu merasa paling paling paling paling paling mencerminkan kebaikan untuk berbagi oleh masa lalu secara perlahan  .\n",
            "Input: Aku merasa sangat sedih\n",
            "Output: Perasaan sedih sering kali muncul bukan karena kamu menghadapi perubahan atau kehilangan dalam hidup . Itu adalah tanda bahwa kamu sedang mencari pelan pelan pelan pelan pelan pelan pelan pelan pelan pelan pelan pelan pelan pelan pelan pelan pelan pelan pelan pelan pelan pelan pelan pelan momen momen momen momen momen momen momen momen momen masa kehilangan kasih yang paling membuatmu merasa kehilangan segala keadaan berubah . Kamu layak mendapatkannya .\n",
            "Input: Kapan aku bisa keluar dari perasaan ini?\n",
            "Output: Keluar dari perasaan ini bukan tanda kamu tidak harus melewatinya sendiri . Itu tentang bagaimana kamu tidak harus melewatinya sendiri . Dalam attachment yang positif , kamu tidak harus melewatinya sendiri . Kamu tidak harus melewatinya sendiri . Cinta itu bisa membantu dan mulai dengan berbagi sedikit demi melewatinya sendiri .\n",
            "📘 Average BLEU score: 0.1611\n",
            "📙 Average METEOR score: 0.3124\n",
            "==========================\n",
            "Evaluating Model Dropout\n",
            "Evaluating Model D015\n",
            "Input: Aku akan mencoba berbicara dengan orang tua ku\n",
            "Output: Aku tahu ini bukan hal yang mudah , jadi aku menghargai niatmu untuk mencoba . Hubungan yang aman dimulai dari keberanian untuk mengungkapkan perasaan , meskipun itu menakutkan . Kalau kamu ingin , kita bisa sama sama susun kalimat yang ingin kamu ucapkan nanti .\n",
            "Input: Aku akan mencoba saranmu\n",
            "Output: Niatmu untuk jadi langkah yang sangat berarti . Kadang kita belum tahu hasil akhirnya , tapi keberanian untuk mulai itu keberanian untuk mulai itu secara emosional . Aku penasaran , seperti berbicara tentang langkah kecil membuat jembatan percakapan sederhana dengan seseorang yang dipercaya atau menulis jurnal . Hal apa yang menurutmu paling membuatmu merasa bertanya tanya tentang apa pun ingin bercerita tentang keberanian akhir akhir akhir ini ?\n",
            "Input: Mengapa saya masih merasa bersalah atas perceraian orang tua saya?\n",
            "Output: Merasa bersalah adalah respon emosional yang umum , ketika terjadi perubahan situasi dalam suatu hubungan yang bermakna , misalnya hubungan Anda dengan orang tua . Rasa bersalah itu bisa diturunkan dengan beberapa cara , salah satunya adalah menggunakan perspektif attachment yang positif . Menggunakan perspektif ini , seseorang dapat memposisikan diri untuk menyadari bahwa dia tidak bertanggung jawab atas keputusan orang tua , dan pada saat mereka kepada mereka adalah bagian dari perjalanan hidup mereka sendiri , dan ibu , perasaan kasih sayang mereka kepada anak tetap ada .\n",
            "Input: Apakah saya akan bisa menciptakan keluarga yang sehat di masa depan meski berasal dari keluarga yang bercerai?\n",
            "Output: Ya , kamu bisa . Asal kamu memiliki kesadaran emosional dan keinginan untuk belajar dari masa lalu , kamu punya kekuatan untuk menciptakan keluarga yang penuh kasih . Attachment positif menunjukkan bahwa pola pola pola lama bisa diputuskan dan diganti dengan pola yang lebih sehat . Keluargamu kelak adalah ruang baru yang bisa kamu bentuk dengan cinta dan nilai yang kamu yakini .\n",
            "Input: Bagaimana cara menerima bahwa cinta antara orang tua saya sudah berakhir?\n",
            "Output: Menerima akhir dari cinta mereka bukan tanda kelemahanmu , tapi kekuatan untuk menatap hidup dengan jujur . Kadang kita butuh waktu untuk memahami bahwa perubahan tidak selalu buruk . Dalam hubungan yang aman , kita diajak untuk memeluk kenyataan tanpa kehilangan harapan . Kamu sedang menata kembali caramu mencintai dan dipedulikan dan itu hal yang luar biasa .\n",
            "Input: Bagaimana jika saya takut membuka diri karena takut akan ditinggalkan juga?\n",
            "Output: Takut membuka diri bukan berarti kamu lemah , tapi justru menunjukkan bahwa hatimu punya kedalaman . Dalam hubungan yang aman , tidak harus sempurna atau selalu kuat untuk dicintai . Orang yang tepat akan menghargai prosesmu dan tidak terburu buru memintamu menyerahkan semua . Kamu berhak merasa aman sebelum membuka pintu hatimu lebih jauh .\n",
            "Input: Aku merasa overthinking\n",
            "Output: Perasaan kesepian sering kali membuat kamu tidak ada tempat di sini untuk menemani kamu merasa nyaman untuk menemani dengan dirimu sendiri . Tapi kamu tidak harus terus menerus kadang yang dibutuhkan hanyalah jeda yang menyembuhkan . Apa yang membuatmu merasa sedikit demi sedikit ?\n",
            "Input: Aku merasa sangat sedih\n",
            "Output: Kesedihan bisa terasa sangat menyesakkan , apalagi jika kamu merasa harus menahannya sendiri . Tapi kamu tidak sendiri sekarang . Aku ingin menemani , dan mungkin kita bisa pelan membuka cerita yang membuat hatimu terasa berat . Apakah ada sesuatu yang membuatmu merasa kehilangan atau tidak dimengerti akhir akhir akhir akhir akhir akhir akhir akhir akhir akhir akhir akhir akhir ini ?\n",
            "Input: Kapan aku bisa keluar dari perasaan ini?\n",
            "Output: Perasaan ini tidak akan bertahan selamanya , meski saat ini terasa begitu berat . Waktu memang membantu , tapi yang juga penting adalah bagaimana kita merawat diri dan mencari dukungan . Dalam hubungan yang aman , kita bisa mulai menemukan jalan keluar bersama , perlahan lahan . Apa yang paling kamu butuhkan sekarang agar hari ini terasa sedikit lebih ringan ?\n",
            "📘 Average BLEU score: 0.5315\n",
            "📙 Average METEOR score: 0.6933\n",
            "Evaluating Model D02\n",
            "Input: Aku akan mencoba berbicara dengan orang tua ku\n",
            "Output: Itu langkah yang sangat berani , dan aku bangga padamu . Berbicara dengan orang tua , apalagi soal perasaan , bisa sangat menegangkan . Tapi itu juga bisa jadi awal dari pemahaman dan koneksi yang lebih sehat .\n",
            "Input: Aku akan mencoba saranmu\n",
            "Output: Itu langkah yang baik ! Semoga hal itu membantumu merasa lebih tenang . Jangan ragu untuk kembali jika langkahnya pelan yang penting kamu tahu bahwa kamu tidak harus menunggu semuanya sekaligus . Aku ingin tahu apa apa apa apa apa apa apa jika langkahnya pelan apa yang kamu tahu apa apa apa pun kamu tahu apa pun kamu merasa lebih tenang .\n",
            "Input: Mengapa saya masih merasa bersalah atas perceraian orang tua saya?\n",
            "Output: Perasaan bersalah muncul adalah reaksi yang umum , terutama ketika perubahan besar dalam suatu hubungan yang bermakna , misalnya hubungan itu dengan orang tua . Rasa bersalah itu bisa muncul karena kamu masih ada . Perasaan bersalah atas keputusan orang tua , seperti berbicara dengan orang tua , salah satu orang tua , salah satu orang tua , dapat terjadi dan menerima perubahan ini yang lebih perceraian orang tua .\n",
            "Input: Apakah saya akan bisa menciptakan keluarga yang sehat di masa depan meski berasal dari keluarga yang bercerai?\n",
            "Output: Meskipun kamu berasal dari keluarga yang bercerai , kamu tetap punya kapasitas penuh untuk mencintai , kamu bisa menciptakan hubungan yang penuh kasih . Attachment yang sehat dibentuk dari kesadaran , bukan hanya warisan keluarga . Kamu sudah berada di jalur yang tepat jika kamu mulai mempertanyakan dan memperbaiki pola hubunganmu sekarang . Setiap langkah kecil ke arah kesadaran adalah fondasi bagi keluarga masa depanmu .\n",
            "Input: Bagaimana cara menerima bahwa cinta antara orang tua saya sudah berakhir?\n",
            "Output: Hubungan orang tua berakhir tidak membatalkan semua nilai dan pelajaran yang kamu terima dari mereka . Kadang , menerima kenyataan berarti memberi ruang untuk menyadari bahwa cinta itu tidak hilang ia hanya berpindah bentuk . Kadang , kita diajak  , tapi kita diajak untuk pulih . Kamu boleh merasakan cinta , meski bentuk keluargamu seharusnya cinta yang berbeda .\n",
            "Input: Bagaimana jika saya takut membuka diri karena takut akan ditinggalkan juga?\n",
            "Output: Ketakutan ditinggalkan bisa berasal dari pengalaman masa lalu yang belum sempat kamu sembuhkan . Attachment positif menyarankan untuk membangun hubungan perlahan lahan , mulai dari ruang kecil yang aman . Kamu bisa mulai dengan berbagi sedikit demi sedikit , dan menghargai keberanianmu setiap kali kamu jujur . Koneksi yang tumbuh dari kepercayaan akan jauh lebih tahan lama .\n",
            "Input: Aku merasa overthinking\n",
            "Output: Terkadang pikiran kita bisa terasa begitu penuh , ya . Apa hal yang paling sering muncul di pikiranmu akhir ini ?\n",
            "Input: Aku merasa sangat sedih\n",
            "Output: Kesedihan bisa terasa sangat menyesakkan , apalagi jika kamu merasa harus menahannya sendiri . Tapi kamu tidak sendiri sekarang . Aku ingin menemani , dan mungkin kita bisa pelan pelan membuka cerita yang membuat kita merasa sedih . Apakah ada sesuatu yang membuatmu merasa sedih , terutama ketika kita merasa sedih .\n",
            "Input: Kapan aku bisa keluar dari perasaan ini?\n",
            "Output: Perasaan kesepian tidak salah , dan kamu tidak harus sempurna untuk mulai dari pengalaman masa lalu . Aku ingin tahu , adakah hal yang belum sekarang . Kamu bisa mulai dengan berbagi , mendengarkan , kalau kamu ingin dengar cerita atau bantuan kecil yang ingin tahu , mendengarkan .\n",
            "📘 Average BLEU score: 0.4420\n",
            "📙 Average METEOR score: 0.6204\n",
            "Evaluating Model D025\n",
            "Input: Aku akan mencoba berbicara dengan orang tua ku\n",
            "Output: Keputusanmu untuk mencoba berbicara adalah bentuk usaha untuk menciptakan hubungan yang lebih sehat . Komunikasi yang jujur sering kali membuka ruang baru yang sebelumnya tertutup . Kamu tidak harus menyelesaikan semuanya dalam satu percakapan cukup mulai dari hati yang tulus .\n",
            "Input: Aku akan mencoba saranmu\n",
            "Output: Keputusanmu untuk mencoba menunjukkan kekuatan dalam dirimu sendiri , tapi kamu juga pernah merasa lelah . Itu bukan kelemahan , tapi sinyal bahwa kamu butuh ruang untuk mencoba untuk mencoba sudah termasuk bentuk keberanian untuk mencoba sudah sangat berarti . Aku di sini kalau kamu ingin bercerita tentang apa yang kamu ulang kekuatanmu .\n",
            "Input: Mengapa saya masih merasa bersalah atas perceraian orang tua saya?\n",
            "Output: Merasa bersalah adalah reaksi yang wajar ketika terjadi perubahan besar dalam hubungan yang bermakna , seperti hubungan dengan orang tua . Dalam perspektif attachment yang positif , seseorang dapat memahami bahwa meskipun hubungan antara orang tua berubah . Dengan tetap berhak atas bagaimana meskipun perceraian dengan hati mereka dan mencari dukungan dari orang tua . Dengan berfokus pada Anda , Anda bisa mengurangi perasaan bertanggung jawab atas keputusan mereka terhadap hubungan yang lebih dalam .\n",
            "Input: Apakah saya akan bisa menciptakan keluarga yang sehat di masa depan meski berasal dari keluarga yang bercerai?\n",
            "Output: Keluarga yang sehat bukan tentang kesempurnaan , tapi tentang kemampuan untuk saling mendengarkan , mengatur emosi , dan hadir satu sama lain . Kamu bisa membangun semua itu meski berasal dari latar belakang yang rumit . Attachment positif percaya bahwa healing itu mungkin , dan kamu bisa menjadi orang tua , atau anggota keluarga yang lebih hadir dan sadar . Kamu sedang menyiapkan fondasi itu hari ini .\n",
            "Input: Bagaimana cara menerima bahwa cinta antara orang tua saya sudah berakhir?\n",
            "Output: Menerima kenyataan tidak berarti menghapus kenangan yang telah terbentuk . Dalam perspektif attachment yang positif , Anda tetap bisa membawa nilai hubungan yang berarti kamu jaga , melainkan menerima perubahan dengan hati dan penuh kasih . Dengan menerima kenyataan ini , Anda bisa tetap menjaga hubungan yang sehat dan tumbuh dan tumbuh darinya . Dengan menerima perubahan sebagai bagian dari perjalanan hidup , Anda dapat menciptakan koneksi yang aman dan penuh kasih .\n",
            "Input: Bagaimana jika saya takut membuka diri karena takut akan ditinggalkan juga?\n",
            "Output: Ketakutan ditinggalkan bisa berasal dari pengalaman masa lalu yang belum sempat kamu sembuhkan . Attachment positif menyarankan untuk membangun hubungan perlahan lahan , mulai dengan berbagi sedikit ruang kecil yang aman . Kamu bisa mulai dengan berbagi sedikit demi sedikit , dan menghargai keberanianmu setiap kali kamu jujur . Koneksi yang tumbuh dari kepercayaan akan jauh lebih tahan lama .\n",
            "Input: Aku merasa overthinking\n",
            "Output: Terkadang kita merasa sendirian dalam hal yang sangat wajar , apalagi di pikiranmu waktu di pikiranmu akhir akhir ini ?\n",
            "Input: Aku merasa sangat sedih\n",
            "Output: Kesedihan itu datang dari tempat di mana kamu bisa jadi diri sendiri . Aku di sini untuk berbicara dengan seseorang yang kamu rasakan sekaligus . Kamu bisa mencoba berbicara dengan seseorang yang kamu percaya . Kamu tidak harus cerita semuanya sekarang . Apa yang membuatmu ingin kamu pikirkan berulang ulang hingga membuatmu merasa damai paling ulang kekuatanmu .\n",
            "Input: Kapan aku bisa keluar dari perasaan ini?\n",
            "Output: Perasaan seperti ini sangat wajar , terutama ketika menghadapi perubahan besar . Apa yang sedang terjadi belakangan ini terasa begitu berat , apalagi kalau kamu ingin menjaga hubungan yang penting adalah bagaimana kamu ingin dengar lebih dalam . Kalau suatu saat kamu ingin dengar cerita tentang apa yang kamu rindukan dari masa sebelum perasaan ini muncul .\n",
            "📘 Average BLEU score: 0.3712\n",
            "📙 Average METEOR score: 0.5166\n",
            "==========================\n",
            "Evaluating Model Unit\n",
            "Evaluating Model U384\n",
            "Input: Aku akan mencoba berbicara dengan orang tua ku\n",
            "Output: Komunikasi yang sehat dengan orang tua bisa membuka banyak pintu yang sebelumnya tertutup rapat . Aku percaya kamu bisa menyampaikan isi hatimu dengan cara yang lembut tapi jujur . Aku akan terus ada di sini kalau kamu ingin cerita setelah kamu melakukannya .\n",
            "Input: Aku akan mencoba saranmu\n",
            "Output: Keputusanmu untuk mencoba menunjukkan kekuatan dalam dirimu yang kadang mungkin kamu lupakan . Tidak apa apa apa apa apa apa apa apa apa apa apa apa apa jika kamu rasakan . Apa di sini kalau kamu ingin berbicara buruk satu sama lain ?\n",
            "Input: Mengapa saya masih merasa bersalah atas perceraian orang tua saya?\n",
            "Output: Perasaan bersalah yang berlarut larut bisa muncul karena otak berusaha mencari pemahaman atas situasi yang sulit . Dalam konteks attachment , anak yang mengalami perceraian orang tua mungkin merasa bahwa stabilitas emosionalnya terganggu , sehingga mencari cara untuk mengembalikan kendali , salah satunya dengan merasa bersalah . Namun , memahami bahwa setiap individu bertanggung jawab atas pilihannya sendiri dapat membantu membebaskan diri dari perasaan tersebut . Mencari dukungan dari lingkungan yang aman seperti teman , atau profesional dapat membantu membentuk kembali persepsi dengan orang tua .\n",
            "Input: Apakah saya akan bisa menciptakan keluarga yang sehat di masa depan meski berasal dari keluarga yang bercerai?\n",
            "Output: Jangan ragu akan kemampuanmu menciptakan keluarga yang kamu impikan . Justru karena kamu tahu rasanya tumbuh di tengah ketidaksempurnaan , kamu bisa lebih sadar dan peka saat membangun relasi . Attachment positif memberi keyakinan bahwa keluarga yang sehat bisa lahir dari ketulusan , komunikasi , dan kerja sama . Dan semua itu ada dalam jangkauanmu .\n",
            "Input: Bagaimana cara menerima bahwa cinta antara orang tua saya sudah berakhir?\n",
            "Output: Menerima akhir dari cinta mereka bukan tanda kelemahanmu , tapi kekuatan untuk menatap hidup dengan jujur . Kadang kita butuh waktu untuk memahami bahwa perubahan tidak selalu buruk . Dalam hubungan yang aman , kita diajak untuk memeluk kenyataan tanpa kehilangan harapan . Kamu sedang menata kembali caramu mencintai dan dipedulikan dan itu hal yang luar biasa .\n",
            "Input: Bagaimana jika saya takut membuka diri karena takut akan ditinggalkan juga?\n",
            "Output: Rasa takut ditinggalkan setelah mengalami kehilangan adalah hal yang sangat manusiawi . Attachment positif mengajarkan bahwa rasa aman bisa dibangun secara perlahan , bukan dipaksakan . Kamu boleh mengambil waktu , dan kamu tidak harus langsung percaya sepenuhnya . Yang penting , kamu tetap memberi dirimu kesempatan untuk terhubung , meski dengan hati hati .\n",
            "Input: Aku merasa overthinking\n",
            "Output: Dalam positive attachment , kita belajar bahwa pikiran yang terus menerus muncul biasanya adalah ekspresi dari rasa takut yang belum diproses sepenuhnya . Mungkin ada cerita atau pengalaman yang terasa belum selesai . Aku di sini kalau kamu ingin pelan menceritakannya . Apakah kamu merasa ada sesuatu yang tidak bisa kamu kendalikan akhir ini ?\n",
            "Input: Aku merasa sangat sedih\n",
            "Output: Saat kamu merasa sedih , yang paling dibutuhkan adalah koneksi yang aman tempat untuk merasa diterima apa adanya . Aku di sini untuk menciptakan ruang itu untukmu . Kamu bisa cerita sebanyak atau sesedikit yang kamu mau . Hal apa yang paling kamu harap bisa berjalan berbeda belakangan ini ?\n",
            "Input: Kapan aku bisa keluar dari perasaan ini?\n",
            "Output: Rasa sakit ini tidak selamanya , meskipun rasanya seperti itu . Hal yang penting adalah kamu tidak harus menunggu semuanya hilang untuk merasa lebih baik kamu bisa mulai merasa sedikit lega dengan berbagi . Kalau kamu nyaman , aku ingin dengar cerita tentang apa yang kamu rindukan dari masa masa masa masa masa masa masa masa masa masa masa sekarang .\n",
            "📘 Average BLEU score: 0.6167\n",
            "📙 Average METEOR score: 0.7824\n",
            "Evaluating Model U640\n",
            "Input: Aku akan mencoba berbicara dengan orang tua ku\n",
            "Output: Aku tahu ini bukan hal yang mudah , jadi aku menghargai niatmu untuk mencoba . Hubungan yang aman dimulai dari keberanian untuk mengungkapkan perasaan , meskipun itu menakutkan . Kalau kamu ingin , kita bisa sama susun kalimat yang ingin kamu ucapkan nanti .\n",
            "Input: Aku akan mencoba saranmu\n",
            "Output: Niatmu untuk mencoba sudah jadi langkah yang sangat berarti . Kadang kita belum tahu hasil akhirnya , tapi keberanian untuk mulai itu yang membuka jalan . Aku di sini untuk mendukung dan menemani kamu dalam prosesnya . Kalau kamu butuh bantuan kecil untuk mulai , yuk kita rancang bareng bareng .\n",
            "Input: Mengapa saya masih merasa bersalah atas perceraian orang tua saya?\n",
            "Output: Perasaan bersalah mungkin muncul karena otak berusaha mencari pemahaman yang tidak situasi yang tidak harus sempurna untuk menjadi cukup . Dalam perspektif attachment yang positif , memahami bahwa setiap individu bertanggung jawab atas perceraian orang tua memengaruhi kesejahteraan emosional , Anda dapat membantu membentuk perspektif yang mendukung mereka sambil tetap memberi untuk membentuk pemahaman ini . Dengan membangun hubungan yang lebih sehat dan aman , Anda dapat membantu Anda dapat membantu menjaga keterikatan yang lebih baik .\n",
            "Input: Apakah saya akan bisa menciptakan keluarga yang sehat di masa depan meski berasal dari keluarga yang bercerai?\n",
            "Output: Jangan ragu akan kemampuanmu menciptakan keluarga yang kamu impikan . Justru karena kamu tahu rasanya tumbuh di tengah ketidaksempurnaan , kamu bisa lebih sadar dan peka saat membangun relasi . Attachment positif memberi keyakinan bahwa keluarga yang sehat bisa lahir dari ketulusan , komunikasi , dan kerja sama . Dan semua itu ada dalam jangkauanmu .\n",
            "Input: Bagaimana cara menerima bahwa cinta antara orang tua saya sudah berakhir?\n",
            "Output: Menerima akhir dari cinta mereka bukan tanda kelemahanmu , tapi kekuatan untuk menatap hidup dengan jujur . Kadang kita butuh waktu untuk memahami bahwa perubahan tidak selalu buruk . Dalam hubungan yang aman , kita diajak untuk memeluk kenyataan tanpa kehilangan harapan . Kamu sedang menata kembali caramu mencintai dan dipedulikan dan itu hal yang luar biasa .\n",
            "Input: Bagaimana jika saya takut membuka diri karena takut akan ditinggalkan juga?\n",
            "Output: Kamu mungkin pernah merasa ditinggalkan , dan rasa itu begitu membekas hingga kini . Tapi attachment yang sehat mengingatkan bahwa tidak semua hubungan akan berakhir seperti itu . Ada orang orang orang orang orang orang yang akan membantu tidak semua hubungan akan berakhir diri . Kamu berhak mendapatkannya , dan kamu belum sempat kamu berhak merasa lega .\n",
            "Input: Aku merasa overthinking\n",
            "Output: Terkadang pikiran kita bisa terasa begitu penuh , ya . Apa hal yang paling sering muncul di pikiranmu akhir ini ?\n",
            "Input: Aku merasa sangat sedih\n",
            "Output: Perasaan sedih sering kali muncul saat kita menghadapi perubahan atau kehilangan dalam hubungan penting dalam hidup kita . Perasaan itu layak mendapat ruang untuk diakui dan dipahami . Aku penasaran , apakah ada momen terakhir yang terasa sangat berat untukmu ?\n",
            "Input: Kapan aku bisa keluar dari perasaan ini?\n",
            "Output: Keluar dari perasaan ini adalah bentuk keberanian dan hubungan yang tidak harus sempurna untuk menjadi jembatan untuk mulai dengan orang yang terbuka . Apa yang menurutmu bisa membantu Anda memahami bahwa setiap orang lain sambil menemukan cara yang membantu mempertimbangkan kita ingin tahu . Apa yang menghalanginya sejauh ini ?\n",
            "📘 Average BLEU score: 0.5331\n",
            "📙 Average METEOR score: 0.7053\n",
            "Evaluating Model U256\n",
            "Input: Aku akan mencoba berbicara dengan orang tua ku\n",
            "Output: Keputusanmu untuk mencoba berbicara adalah bentuk usaha untuk menciptakan hubungan yang lebih sehat . Komunikasi yang jujur sering kali membuka ruang baru yang sebelumnya tertutup . Kamu tidak harus menyelesaikan semuanya dalam satu percakapan cukup mulai dari hati yang tulus .\n",
            "Input: Aku akan mencoba saranmu\n",
            "Output: Niatmu untuk mencoba sudah jadi langkah yang sangat berarti . Kadang kita belum tahu hasil akhirnya , dan keberanian untuk mulai itu yang membuka jalan . Aku di sini untuk mendukung dan menemani kamu dalam prosesnya . Kalau kamu butuh bantuan kecil untuk mulai , yuk kita rancang bareng bareng .\n",
            "Input: Mengapa saya masih merasa bersalah atas perceraian orang tua saya?\n",
            "Output: Merasa bersalah adalah respon emosional yang umum , ketika terjadi perubahan situasi dalam suatu hubungan yang bermakna , misalnya hubungan Anda dengan orang tua . Rasa bersalah itu bisa diturunkan dengan beberapa cara , salah satunya adalah menggunakan perspektif attachment yang positif . Menggunakan perspektif ini , seseorang dapat memposisikan diri untuk menyadari bahwa dia tidak bertanggung jawab atas keputusan orang tua , dan pada saat orang tua . Menggunakan perspektif mereka dalam hubungan antara ayah dan ibu , perasaan kasih sayang mereka kepada anak tetap ada .\n",
            "Input: Apakah saya akan bisa menciptakan keluarga yang sehat di masa depan meski berasal dari keluarga yang bercerai?\n",
            "Output: Meskipun kamu berasal dari keluarga yang bercerai , kamu tetap punya kapasitas penuh untuk mencintai , dipercaya , dan menciptakan hubungan yang aman . Attachment yang sehat dibentuk dari kesadaran . Orang tua yang tepat jika kamu sudah berada di jalur yang tepat jika kamu mulai mempertanyakan dan memperbaiki pola hubunganmu sekarang . Setiap langkah kecil ke arah kesadaran adalah fondasi bagi keluarga masa depanmu .\n",
            "Input: Bagaimana cara menerima bahwa cinta antara orang tua saya sudah berakhir?\n",
            "Output: Menerima kenyataan tidak berarti menghapus kenangan baik tentang masa lalu , dan aman bukan berarti kamu kehilangan keluarga yang telah terjadi . Kamu bisa belajar dari hubungan , sambil tetap mengingat bahwa cinta yang kamu juga bagian dari dirimu sendiri . Attachment yang sehat di masa lalu perlahan dan kejujuran , dan memberi ruang untuk koneksi yang lebih sehat dapat membantu menciptakan ruang untuk menciptakan ruang untuk koneksi yang lebih sehat di masa depan . Cinta itu bukan berarti menghapus makna baru .\n",
            "Input: Bagaimana jika saya takut membuka diri karena takut akan ditinggalkan juga?\n",
            "Output: Takut membuka diri bukan berarti kamu lemah , tapi justru menunjukkan bahwa hatimu punya kedalaman . Dalam hubungan yang aman , seperti dulu , dan penuh kesadaran . Dalam hubungan yang aman , kita bisa dibangun secara perlahan . Kamu tidak harus terburu buru memintamu menyerahkan semua . Koneksi yang paling kamu akan jauh lebih tahan lama .\n",
            "Input: Aku merasa overthinking\n",
            "Output: Pikiran yang terus berputar bisa membuat kamu merasa lelah . Overthinking sering kali muncul di tengah ketidakpastian . Itu adalah reaksi alami dari seseorang yang sangat peduli dan ingin melakukan hal yang sangat manusiawi . Aku di sini secara mana kamu merasa lelah . Apakah kamu merasa lelah , dan ingin bercerita tentang ulang hingga membuatmu merasa lelah .\n",
            "Input: Aku merasa sangat sedih\n",
            "Output: Kesedihan yang kamu rasakan valid dan penting untuk dikenali . Dalam hubungan yang aman secara emosional , dan merasa lemah tanpa harus merasa dihakimi . Kadang , perasaan sedih itu tidak datang begitu saja ada cerita mendengarkan , kalau kamu ingin bercerita . Bolehkah aku ingin cerita yang paling membebanimu saat ini ?\n",
            "Input: Kapan aku bisa keluar dari perasaan ini?\n",
            "Output: Rasa sakit ini tidak selamanya , meskipun rasanya seperti itu . Hal yang penting adalah kamu bisa mulai merasa sedikit lega kamu sedang belajar bahwa kamu sedang mencoba membangun cinta yang kamu yakini . Aku ingin cerita tentang momen terakhir yang terasa sedikit harapan ?\n",
            "📘 Average BLEU score: 0.5181\n",
            "📙 Average METEOR score: 0.6207\n",
            "==========================\n",
            "Evaluating Model Dim\n",
            "Evaluating Model DM128\n",
            "Input: Aku akan mencoba berbicara dengan orang tua ku\n",
            "Output: Itu langkah yang sangat berani , dan aku bangga padamu . Berbicara dengan orang tua , penting untuk mencoba memahami bahwa kamu bisa mencoba berbicara dengan seseorang yang baru . Kamu tidak semua pihak , meskipun dinamika hati yang baru , meskipun dinamika titik mulai .\n",
            "Input: Aku akan mencoba saranmu\n",
            "Output: Aku senang mendengar bahwa kamu ingin mencoba . Memberi ruang untuk mencoba adalah tanda bahwa kamu percaya pada perubahan dan ruang baru yang sudah termasuk saat hidupmu sendiri . Kamu tidak harus memilih tempat tinggal di sini untuk mendukung Anda , bukan akhir ini ?\n",
            "Input: Mengapa saya masih merasa bersalah atas perceraian orang tua saya?\n",
            "Output: Merasa bersalah adalah respon emosional yang umum , ketika terjadi perubahan besar dalam suatu hubungan yang bermakna , misalnya hubungan Anda dengan orang tua . Rasa bersalah itu bisa diturunkan dengan beberapa cara , salah karena suatu ikatan emosional yang sehat dapat membantu Anda merasa bahwa perasaan orang tua . Menggunakan perspektif attachment yang sehat membantu Anda merasa bertanggung jawab atas keputusan orang tua dapat membantu Anda membantu Anda mengelola emosi dengan lebih baik , meskipun situasi kehilangan , bukan sesuatu yang berarti .\n",
            "Input: Apakah saya akan bisa menciptakan keluarga yang sehat di masa depan meski berasal dari keluarga yang bercerai?\n",
            "Output: Setiap orang butuh waktu untuk menyesuaikan diri agar tidak menambah keluarga tapi kamu butuh waktu yang kamu tidak harus hilang untuk memilih salah dengan jujur . Attachment yang sehat memberi ruang aman membantumu membangun pola yang lebih sehat . Kamu bisa keterbukaan dalam dirimu , meski ada dan hadir secara utuh untuk menciptakan keluarga yang lebih dulu .\n",
            "Input: Bagaimana cara menerima bahwa cinta antara orang tua saya sudah berakhir?\n",
            "Output: Menerima bahwa cinta orang tua telah berakhir bukan berarti kamu harus menghapus semua kenangan baik tentang mereka . Ini berarti kamu mulai melihat hubungan mereka dengan realitas hati mereka yang baru , sambil tetap menjaga ruang aman untuk perasaanmu sendiri . Dalam attachment positif , kamu boleh merasakan kesedihan dan menerima perubahan ini , sekaligus belajar bahwa cinta mereka tidak kehilangan cinta mereka kepadamu , meskipun mereka sudah tidak kehilangan harapan .\n",
            "Input: Bagaimana jika saya takut membuka diri karena takut akan ditinggalkan juga?\n",
            "Output: Rasa takut ditinggalkan setelah perceraian bisa muncul karena banyak hal yang sangat manusiawi . Tapi kamu tidak harus memendam semua sendirian . Attachment positif mendorong kita untuk mengenali bahwa diri dengan mengenali apa jika kamu butuh waktu untuk mengenali apa yang aman dan dukungan emosional . Kamu berhak merasa dicintai , bahkan jika kamu belum sepenuhnya yakin untuk membuka diri .\n",
            "Input: Aku merasa overthinking\n",
            "Output: Perasaan ini sering kali muncul saat tidak ada banyak hal yang sangat manusiawi . Tapi kamu tidak sendiri banyak orang orang tua jika belum ada di sini untuk mendapatkan tempat yang lebih baik hanya soal perasaan . Apa yang paling membuatmu merasa seseorang yang paling membuatmu benar benar benar benar benar benar benar benar benar benar akhir akhir akhir akhir ini ?\n",
            "Input: Aku merasa sangat sedih\n",
            "Output: Kesedihan yang kamu rasakan valid dan penting untuk dikenali . Dalam hubungan yang aman secara emosional , penting untuk menjadi bagian dirimu sendiri dan merasa berhak merasa didengar dan layak merasa berharga tanpa harus mendapat di sini kalau kamu ingin cerita di sini untuk bercerita . Bolehkah hal yang tidak dimengerti , kalau kamu rindukan atau khawatirkan saat ini ?\n",
            "Input: Kapan aku bisa keluar dari perasaan ini?\n",
            "Output: Keluar dari perasaan ini adalah proses yang dimulai dengan keberanian untuk bertanya , seperti yang baru saja kamu lakukan . Dalam attachment positif , kamu tidak harus melewatinya sendiri , langkah kecil yang sehat . Aku akan kembali melalui aktivitas yang menurutmu bisa melewatinya sendiri ?\n",
            "📘 Average BLEU score: 0.3433\n",
            "📙 Average METEOR score: 0.4510\n",
            "Evaluating Model DM328\n",
            "Input: Aku akan mencoba berbicara dengan orang tua ku\n",
            "Output: Itu keputusan yang baik ! Semoga percakapan itu membantumu menemukan kejelasan . Jika butuh persiapan , aku siap mendengar .\n",
            "Input: Aku akan mencoba saranmu\n",
            "Output: Itu keputusan yang baik ! Semoga kamu ingin tahu itu membantumu menemukan kejelasan . Itu bisa jadi sisa perasaan yang baik !\n",
            "Input: Mengapa saya masih merasa bersalah atas perceraian orang tua saya?\n",
            "Output: Perasaan bersalah yang relatif menetap atas suatu situasi yang sudah cukup lama terjadi bisa disebabkan oleh berbagai faktor . Dalam situasi ketika Anda masih merasa bersalah atas perceraian orang tua , salah satu faktor penyebab yang mungkin adalah karena Anda merasa menjadi faktor yang menyebabkan perceraian tersebut , sedangkan ketika suatu pasangan memutuskan hubungan di antara mereka , maka merekalah yang sepenuhnya bertanggung jawab atas keputusan tersebut , bukan orang lain .\n",
            "Input: Apakah saya akan bisa menciptakan keluarga yang sehat di masa depan meski berasal dari keluarga yang bercerai?\n",
            "Output: Ya , kamu bisa . Asal kamu memiliki kesadaran emosional dan keinginan untuk belajar dari masa lalu , kamu punya kekuatan untuk menciptakan keluarga yang penuh kasih . Attachment positif menunjukkan bahwa pola pola pola pola pola pola pola pola pola pola pola pola yang lebih sehat . Keluargamu kelak adalah bentuk cinta dan kamu bentuk dengan cinta dan nanti .\n",
            "Input: Bagaimana cara menerima bahwa cinta antara orang tua saya sudah berakhir?\n",
            "Output: Menerima akhir dari cinta itu berakhir bukan tanda kelemahanmu , tapi kekuatan untuk menatap hidup dengan jujur . Kadang kita butuh waktu untuk memahami bahwa cinta itu tidak selalu buruk . Dalam hubungan yang aman , kita diajak untuk memeluk kenyataan tanpa kehilangan harapan . Kamu sedang menata kembali caramu mencintai dan dipedulikan dan itu luar biasa .\n",
            "Input: Bagaimana jika saya takut membuka diri karena takut akan ditinggalkan juga?\n",
            "Output: Rasa takut ditinggalkan setelah mengalami kehilangan adalah hal yang sangat manusiawi . Attachment positif mengajarkan bahwa rasa aman bisa dibangun secara perlahan , meski berasal dari masa lalu . Kamu bisa mulai dengan berbagi sedikit demi sedikit , dan menghargai keberanianmu setiap kali kamu jujur . Koneksi yang tumbuh dari kepercayaan akan jauh lebih tahan lama .\n",
            "Input: Aku merasa overthinking\n",
            "Output: Perasaan sering kali muncul setelah perceraian orang tua bisa dimulai dari respons alami dari rasa takut yang wajar , terutama kalau kamu pernah merasa kecewa atau kehilangan , dan mencari dukungan dari teman , atau bahkan di mana kamu bisa menemukan cara baru untuk menemukan tempat di mana perasaanmu bisa kamu ulang ulang ulang ulang ulang hingga membuatmu merasa terasing dari ini ?\n",
            "Input: Aku merasa sangat sedih\n",
            "Output: Perasaan sedih sering kali muncul setelah perceraian orang tua bisa jadi pengertian akan kehilangan , tetapi keterikatan yang tidak selalu bergantung pada kesejahteraan emosional . Kamu berhak merasa damai meski hatimu pernah merasa dihakimi . Aku di tengah perubahan ini ?\n",
            "Input: Kapan aku bisa keluar dari perasaan ini?\n",
            "Output: Rasa sakit ini tidak selamanya , meskipun rasanya seperti itu . Hal yang penting adalah kamu tidak harus menunggu semuanya hilang untuk merasa lebih baik kamu bisa mulai merasa sedikit lega dengan berbagi . Kalau kamu nyaman , aku ingin dengar cerita tentang apa yang kamu rindukan dari masa sebelum perasaan ini muncul .\n",
            "📘 Average BLEU score: 0.4268\n",
            "📙 Average METEOR score: 0.5630\n",
            "Evaluating Model DM512\n",
            "Input: Aku akan mencoba berbicara dengan orang tua ku\n",
            "Output: Itu keputusan yang baik ! Semoga percakapan itu membantumu menemukan kejelasan . Jika butuh persiapan , aku siap mendengar .\n",
            "Input: Aku akan mencoba saranmu\n",
            "Output: Niatmu untuk mencoba sudah jadi langkah yang sangat berarti . Kadang kita belum tahu hasil akhirnya , tapi keberanian untuk mulai itu yang membuka jalandi sini untuk mendukung dan menemani kamu dalam prosesnya . Aku ingin tahu , yuk kita rancang bareng bareng .\n",
            "Input: Mengapa saya masih merasa bersalah atas perceraian orang tua saya?\n",
            "Output: Perasaan bersalah yang relatif menetap atas suatu situasi yang sudah cukup lama terjadi bisa disebabkan oleh berbagai faktor . Dalam situasi ketika Anda masih merasa bersalah atas perceraian orang tua , salah satu faktor penyebab yang mungkin adalah karena Anda merasa menjadi faktor yang menyebabkan perceraian tersebut , sedangkan ketika suatu pasangan memutuskan untuk memutuskan hubungan di antara orang lain .\n",
            "Input: Apakah saya akan bisa menciptakan keluarga yang sehat di masa depan meski berasal dari keluarga yang bercerai?\n",
            "Output: Jangan ragu akan kemampuanmu menciptakan keluarga yang kamu impikan . Justru karena kamu tahu rasanya tumbuh di tengah ketidaksempurnaan , kamu bisa lebih sadar dan peka saat membangun relasi . Attachment positif memberi keyakinan bahwa keluarga yang sehat bisa lahir dari ketulusan , komunikasi , dan kerja sama . Dan semua itu ada dalam jangkauanmu .\n",
            "Input: Bagaimana cara menerima bahwa cinta antara orang tua saya sudah berakhir?\n",
            "Output: Tak mudah memang ketika yang kita percaya sebagai sesuatu yang abadi , seperti cinta orang tua , ternyata berubah . Tapi bukan berarti kamu kehilangan fondasi hidupmu . Attachment positif mengajarkan bahwa kita bisa tetap membangun rasa aman dengan cara baru dari hubungan yang hadir , dari dirimu sendiri , dan dari koneksi yang kamu jaga . Cinta itu masih ada , bahkan jika wujudnya berubah .\n",
            "Input: Bagaimana jika saya takut membuka diri karena takut akan ditinggalkan juga?\n",
            "Output: Takut membuka diri bukan berarti kamu lemah , tapi justru bukti bahwa hatimu punya kedalaman . Dalam hubungan yang aman , kamu tidak harus sempurna atau selalu kuat untuk dicintai . Orang yang tepat akan menghargai prosesmu dan tidak terburu buru memintamu menyerahkan semua . Kamu berhak merasa aman sebelum membuka pintu hatimu lebih jauh .\n",
            "Input: Aku merasa overthinking\n",
            "Output: Terkadang pikiran pikiran pikiran kita bisa terasa begitu penuh , ya . Apa hal yang paling sering muncul di pikiranmu ini ?\n",
            "Input: Aku merasa sangat sedih\n",
            "Output: Kesedihan yang kamu rasakan valid dan penting untuk dikenali . Dalam hubungan yang aman secara emosional , kita punya ruang untuk menangis dan merasa dihakimi . Aku ingin tahu , langkah yang sedih atau aktivitas yang membuatmu merasa diterima terasa sangat berani . Apa yang paling sering kali kamu pikirkan apa yang paling sering muncul saat ini ?\n",
            "Input: Kapan aku bisa keluar dari perasaan ini?\n",
            "Output: Keluar dari perasaan ini adalah proses yang dimulai dengan keberanian untuk bertanya , seperti yang baru yang baru pada dirimu sendiri . Aku ingin tahu , langkah kecil yang terasa sedikit lega bukan tentang apa yang kamu percaya . Apa bagaimana kamu lakukan hari ini paling sering kamu tidak akan akhir akhir akhir dari keberanian untuk mulai merasa lebih tenang .\n",
            "📘 Average BLEU score: 0.5311\n",
            "📙 Average METEOR score: 0.7110\n",
            "==========================\n",
            "Evaluating Model NUM HEAD\n",
            "Evaluating Model NH4\n",
            "Input: Aku akan mencoba berbicara dengan orang tua ku\n",
            "Output: Itu langkah yang sangat berani , dan aku bangga padamu . Berbicara dengan orang tua , apalagi soal perasaan , bisa sangat menegangkan . Tapi itu juga bisa jadi awal dari pemahaman dan koneksi yang lebih sehat .\n",
            "Input: Aku akan mencoba saranmu\n",
            "Output: Keputusanmu untuk mencoba menunjukkan kekuatan dalam dirimu yang kadang mungkin lupakan . Tidak apa apa apa apa langkahnya pelan yang penting kamu tahu bahwa kamu tidak sendirian di perjalanan ini . Aku percaya kamu bisa , dan aku siap mendengarkanmu membuka sedikit lebih banyak , yuk kita rancang bareng bareng .\n",
            "Input: Mengapa saya masih merasa bersalah atas perceraian orang tua saya?\n",
            "Output: Merasa bersalah karena Anda mengalami situasi yang sudah cukup lama terjadi bisa terjadi bisa disebabkan oleh berbagai faktor . Dalam situasi ketika Anda masih merasa bersalah atas perceraian orang tua , salah satu faktor penyebab yang mungkin adalah karena Anda merasa menjadi faktor yang menyebabkan perceraian tersebut , sedangkan ketika suatu pasangan memutuskan hubungan di antara mereka , maka merekalah yang sepenuhnya bertanggung jawab atas keputusan tersebut , bukan orang lain .\n",
            "Input: Apakah saya akan bisa menciptakan keluarga yang sehat di masa depan meski berasal dari keluarga yang bercerai?\n",
            "Output: Pengalaman keluargamu mungkin memberimu luka , tapi juga bisa memberimu kompas untuk tahu apa yang ingin kamu ubah . Dalam attachment positif , kamu tidak ditentukan oleh apa yang dulu , termasuk oleh apa yang mendukung kamu pilih untuk dilakukan sekarang . Kamu bisa memutus rantai luka dan menggantinya dengan pola yang lebih sehat dan penuh kasih . Harapanmu adalah awal dari perubahan itu .\n",
            "Input: Bagaimana cara menerima bahwa cinta antara orang tua saya sudah berakhir?\n",
            "Output: Hubungan yang berakhir bukan berarti kamu harus menghapus kenangan yang berakhir dengan realitas yang kamu terima sendiri . Kadang , menerima kenyataan berarti memberi ruang untuk menyadari bahwa cinta itu tidak hilang ia hanya berpindah bentuk . Dalam attachment positif , kita tidak menyangkal kenyataan , kita memilih berdamai dan tumbuh darinya . Kamu tetap merasakan cinta , meski dengan dinamika keluarga yang baru .\n",
            "Input: Bagaimana jika saya takut membuka diri karena takut akan ditinggalkan juga?\n",
            "Output: Kamu mungkin pernah merasa ditinggalkan , dan rasa itu begitu membekas hingga kini . Tapi attachment yang sehat mengingatkan bahwa tidak semua hubungan akan berakhir seperti itu . Ada orang yang akan tinggal , bahkan ketika kamu tidak dalam kondisi terbaikmu . Kamu layak dicintai kamu belum pulih , termasuk saat kamu masih punya hati untuk membuka diri .\n",
            "Input: Aku merasa overthinking\n",
            "Output: Overthinking sering kali muncul saat otak kita merasa tidak aman dan mencoba mencari kontrol di tengah ketidakpastian . Itu adalah reaksi alami dari seseorang yang sangat peduli dan ingin melakukan hal dengan benar . Tapi kamu tidak harus memikirkan semuanya sendiri . Apakah kamu ingin bercerita tentang hal apa yang kamu ulang ulang ulang ulang dalam pikiranmu ?\n",
            "Input: Aku merasa sangat sedih\n",
            "Output: Aku di sini untukmu . Aku tahu semua yang sedang kamu pikirkan dan rasakan itu berat , dan kamu tidak apa kalau kamu merasa sedih . Aku di sini untuk menemani kamu ingin bercerita . Aku ingin bercerita ?\n",
            "Input: Kapan aku bisa keluar dari perasaan ini?\n",
            "Output: Keluar dari proses ini adalah proses yang dimulai dengan keberanian untuk bertanya , seperti yang baru saja kamu lakukan . Dalam attachment yang aman , kamu tidak harus melewatinya sendiri . Aku ingin tahu , langkah kecil apa yang menurutmu bisa membantu dan apa yang menghalanginya sejauh ini ?\n",
            "📘 Average BLEU score: 0.5820\n",
            "📙 Average METEOR score: 0.7374\n",
            "Evaluating Model NH16\n",
            "Input: Aku akan mencoba berbicara dengan orang tua ku\n",
            "Output: Komunikasi yang sehat dengan orang tua bisa jadi jauh bukan berarti harus jadi karena kamu percaya . Kamu tidak harus merasa kesal atau takut itu menunjukkan kebutuhan emosionalmu . Aku percaya kamu peduli dan tidak ingin cerita setelah kamu ucapkan nanti .\n",
            "Input: Aku akan mencoba saranmu\n",
            "Output: Sama sama ! Aku senang bisa jadi bagian dari harimu . Kalau kapan pun kamu merasa butuh tempat untuk mulai dari tempat di sini untuk membantu kita butuh dimengerti , sekecil apa pun itu . Kalau kamu ingin mencoba melindungi diri , aku ingin bercerita tentang apa yang membuatmu merasa terasing dari orang di hatimu .\n",
            "Input: Mengapa saya masih merasa bersalah atas perceraian orang tua saya?\n",
            "Output: Merasa bersalah adalah respon emosional yang umum , ketika terjadi situasi dalam suatu hubungan Anda merasa bersalah  . Dalam perspektif attachment yang positif , misalnya hubungan yang aman tidak harus diturunkan dengan beberapa cara . Menggunakan perspektif ini , penting untuk menyadari bahwa keputusan Anda tetap ada . Menggunakan perspektif iniemosional bisa memilih untuk memutuskan hubungan yang lebih kuat dengan baik .\n",
            "Input: Apakah saya akan bisa menciptakan keluarga yang sehat di masa depan meski berasal dari keluarga yang bercerai?\n",
            "Output: Jangan ragu akan kemampuanmu menciptakan keluarga yang kamu impikan . Justru karena kamu tahu rasanya tumbuh di tengah ketidaksempurnaan , kamu bisa lebih sadar dan peka saat membangun relasi . Attachment positif memberi keyakinan bahwa keluarga yang sehat bisa lahir dari ketulusan , komunikasi , komunikasi , dan kerja sama . Dan semua itu ada dalam jangkauanmu .\n",
            "Input: Bagaimana cara menerima bahwa cinta antara orang tua saya sudah berakhir?\n",
            "Output: Menerima akhir dari cinta mereka bukan tanda kelemahanmu , tapi kekuatan untuk menatap hidup dengan jujur . Kadang kita butuh waktu untuk memahami bahwa perubahan tidak selalu buruk . Dalam hubungan yang aman , kita diajak untuk memeluk kenyataan tanpa kehilangan harapan . Kamu sedang menata kembali caramu mencintai dan dipedulikan dan itu hal yang luar biasa .\n",
            "Input: Bagaimana jika saya takut membuka diri karena takut akan ditinggalkan juga?\n",
            "Output: Kamu mungkin pernah merasa ditinggalkan , bukan disangkal , tapi karena akhirnya kamu punya hak untuk membangun rasa aman dengan jujur . Attachment positif percaya dimulai dari langkah kecil yang aman sepenuhnya , dengan berbagi cerita secara perlahan sambil tetap bisa mulai dari pengalaman masa depan . Kamu punya ruang untuk menciptakan suasana yang lebih tahan lama .\n",
            "Input: Aku merasa overthinking\n",
            "Output: Overthinking sering kali muncul saat otak kita merasa tidak aman dan mencoba mencari kontrol di tengah ketidakpastian . Itu adalah reaksi alami dari seseorang yang sangat peduli dan ingin melakukan hal dengan benar . Tapi kamu tidak harus memikirkan semuanya sendiri . Apakah kamu ingin bercerita tentang hal apa yang paling sering kamu ulang ulang dalam pikiranmu ?\n",
            "Input: Aku merasa sangat sedih\n",
            "Output: Kesedihan yang kamu rasakan valid dan penting untuk dikenali . Dalam hubungan yang aman secara emosional , kita punya ruang untuk menangis dan merasa lemah tanpa harus merasa dihakimi . Kadang , perasaan sedih itu tidak ada cerita di baliknya . Bolehkah aku  . Bolehkah aku tahu , hal apa yang sedang kamu rindukan atau khawatirkan saat ini ?\n",
            "Input: Kapan aku bisa keluar dari perasaan ini?\n",
            "Output: Dalam hubungan yang sehat , pemulihan terjadi karena ada yang menemani bukan hanya karena waktu berlalu . Aku percaya kamu bisa melewati ini dengan dukungan dan pengertian yang tepat . Apa satu hal kecil yang bisa kamu lakukan hari ini yang mungkin membawa sedikit harapan ?\n",
            "📘 Average BLEU score: 0.4718\n",
            "📙 Average METEOR score: 0.6099\n",
            "Evaluating Model NH32\n",
            "Input: Aku akan mencoba berbicara dengan orang tua ku\n",
            "Output: Komunikasi yang sehat dengan orang tua bisa membuka banyak pintu yang sebelumnya tertutup rapat . Aku percaya kamu bisa menyampaikan isi hatimu dengan cara yang lembut tapi jujur . Aku akan terus ada di sini kalau kamu ingin cerita setelah kamu melakukannya .\n",
            "Input: Aku akan mencoba saranmu\n",
            "Output: Pilihanmu untuk mencoba bukan berarti kamu lemah itu tanda bahwa dirimu yang perlu harapan di tempat dalam dirimu . Kamu tidak harus langsung berhasil proses pun kamu menyelesaikan semuanya rumah , termasuk bentuk keberanian .\n",
            "Input: Mengapa saya masih merasa bersalah atas perceraian orang tua saya?\n",
            "Output: Saat keluarga mengalami perubahan , fokus pada hubungan yang tetap terjalin meskipun keadaan Anda melewati perubahan dalam hubungan yang bermakna . Dengan melihat bahwa orang tua mungkin tidak selalu Anda dapat memberikan dukungan orang tua dapat membantu mengurangi kecemasan . Dengan begitu , Anda bisa memberikan ruang bagi diri untuk memberikan dukungan emosional yang stabil , Anda dapat memberikan dukungan emosional yang lebih sehat .\n",
            "Input: Apakah saya akan bisa menciptakan keluarga yang sehat di masa depan meski berasal dari keluarga yang bercerai?\n",
            "Output: Keluarga yang sehat bukan tentang kesempurnaan , tapi tentang kemampuan untuk saling mendengarkan , mengatur emosi , dan hadir satu sama lain , tapi justru bukti bahwa kamu memiliki kesadaran diri dari latar belakang yang rumit . Attachment positif percaya bahwa healing itu mungkin , kamu bisa menjadi orang tua , pasangan , atau anggota keluarga yang lebih hadir dan sadar . Kamu sedang menyiapkan fondasi itu hari ini .\n",
            "Input: Bagaimana cara menerima bahwa cinta antara orang tua saya sudah berakhir?\n",
            "Output: Menerima bahwa cinta orang tua telah berakhir bukan berarti kamu harus menghapus semua kenangan baik tentang mereka . Dalam attachment positif , kamu untuk menyadari bahwa cinta yang tidak bersama bukan berarti berubah bentuk . sendiri , kita tidak bersama muncul karena cinta yang lebih mampu itu tidak bersama lagi , meski mereka berdua . Kamu tetap merasakan cinta , meskipun mereka kepadamu , meskipun mereka sudah tidak bersama lagi .\n",
            "Input: Bagaimana jika saya takut membuka diri karena takut akan ditinggalkan juga?\n",
            "Output: Ketakutan ditinggalkan bisa berasal dari pengalaman masa lalu yang belum sempat kamu sembuhkan . Attachment positif menyarankan untuk membangun hubungan perlahan lahan , mulai dari ruang ruang ruang ruang ruang ruang ruang ruang ruang ruang ruang ruang ruang ruang aman lebih stabil . Kamu tidak sendiri , dan menghargai dimengerti .\n",
            "Input: Aku merasa overthinking\n",
            "Output: Pikiran yang terus berputar bisa membuat kamu merasa lelah , dan itu wajar . Overthinking sering kali datang dari tempat di mana kita pernah merasa kecewa atau kehilangan , dan sekarang otakmu mencoba melindungimu . Tapi kamu tidak sendiri dalam menghadapi ini . Apa yang paling sering kamu pikirkan berulang ulang hingga membuatmu sulit tenang ?\n",
            "Input: Aku merasa sangat sedih\n",
            "Output: Saat kita merasa sedih , yang paling dibutuhkan adalah koneksi yang paling dibutuhkan adalah koneksi adanya . Aku menghargai keberanianmu untuk merasa sedih , tapi itu untukmu . Dalam positive attachment , kehadiran seseorang yang aman , kita sendiri secara emosional , kita untuk merasa sedih . Kamu tidak harus merasa kamu mau . Hal apa yang paling dibutuhkan adalah perasaan itu untukmu ?\n",
            "Input: Kapan aku bisa keluar dari perasaan ini?\n",
            "Output: Proses menyembuhkan perasaan memang membutuhkan waktu . Apa yang biasanya membuatmu merasa seperti ini ?\n",
            "📘 Average BLEU score: 0.4571\n",
            "📙 Average METEOR score: 0.6004\n",
            "==========================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Final Model based on experiments Hypereparameters\n",
        "NUM_LAYERS = 3\n",
        "D_MODEL = 328\n",
        "NUM_HEADS = 8\n",
        "UNITS = 384\n",
        "DROPOUT = 0.15\n",
        "\n",
        "model_final = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "metadata": {
        "id": "FMWiNKkRbbMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "\n",
        "model_final.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss_function,\n",
        "    metrics=[accuracy, perplexity],\n",
        "    run_eagerly=True  # Set to True for debugging if needed\n",
        ")"
      ],
      "metadata": {
        "id": "QIpM3XN1cD5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 30\n",
        "history = model_final.fit(dataset, epochs=epoch)"
      ],
      "metadata": {
        "id": "OSlrK3sEcIjl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "332bd0f9-0f8a-42f4-a93d-54c9db0fe743",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.0186 - loss: 3.0367 - perplexity: 22.4110\n",
            "Epoch 2/30\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.0229 - loss: 2.8791 - perplexity: 18.1006\n",
            "Epoch 3/30\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.0217 - loss: 2.8144 - perplexity: 16.9679\n",
            "Epoch 4/30\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.0213 - loss: 2.8122 - perplexity: 16.8766\n",
            "Epoch 5/30\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.0221 - loss: 2.7455 - perplexity: 15.8802\n",
            "Epoch 6/30\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.0214 - loss: 2.7499 - perplexity: 16.0000\n",
            "Epoch 7/30\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.0218 - loss: 2.7999 - perplexity: 16.6608\n",
            "Epoch 8/30\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.0213 - loss: 2.7692 - perplexity: 16.2717\n",
            "Epoch 9/30\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.0218 - loss: 2.8291 - perplexity: 17.2023\n",
            "Epoch 10/30\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.0224 - loss: 2.7987 - perplexity: 16.6925\n",
            "Epoch 11/30\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.0216 - loss: 2.7863 - perplexity: 16.6211\n",
            "Epoch 12/30\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.0225 - loss: 2.8553 - perplexity: 17.7097\n",
            "Epoch 13/30\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.0219 - loss: 2.7831 - perplexity: 16.5007\n",
            "Epoch 14/30\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.0224 - loss: 2.8098 - perplexity: 16.8270\n",
            "Epoch 15/30\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.0235 - loss: 2.8149 - perplexity: 16.9374\n",
            "Epoch 16/30\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.0238 - loss: 2.7965 - perplexity: 16.6471\n",
            "Epoch 17/30\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.0211 - loss: 2.7894 - perplexity: 16.5403\n",
            "Epoch 18/30\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.0227 - loss: 2.8246 - perplexity: 17.1877\n",
            "Epoch 19/30\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.0239 - loss: 2.7875 - perplexity: 16.5703\n",
            "Epoch 20/30\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.0220 - loss: 2.7961 - perplexity: 16.6702\n",
            "Epoch 21/30\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.0226 - loss: 2.8015 - perplexity: 16.7559\n",
            "Epoch 22/30\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.0213 - loss: 2.7920 - perplexity: 16.5101\n",
            "Epoch 23/30\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.0217 - loss: 2.7901 - perplexity: 16.5928\n",
            "Epoch 24/30\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.0225 - loss: 2.7735 - perplexity: 16.2730\n",
            "Epoch 25/30\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.0219 - loss: 2.7742 - perplexity: 16.3268\n",
            "Epoch 26/30\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.0229 - loss: 2.7958 - perplexity: 16.6830\n",
            "Epoch 27/30\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.0226 - loss: 2.8220 - perplexity: 17.1097\n",
            "Epoch 28/30\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.0214 - loss: 2.8002 - perplexity: 16.8027\n",
            "Epoch 29/30\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.0225 - loss: 2.8046 - perplexity: 16.7259\n",
            "Epoch 30/30\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.0225 - loss: 2.7784 - perplexity: 16.3579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_final.save_weights('D:/skripsi-sultin/data/bot_v3_Final_Konfigurasi.weights.h5')"
      ],
      "metadata": {
        "id": "iVZG_X0nFsNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_U384.load_weights('D:/skripsi-sultin/data/bot_v3_Final_Konfigurasi.weights.h5')"
      ],
      "metadata": {
        "id": "kavZvFS8F6OU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluating Model final\")\n",
        "bleu_final, meteor_final = evaluate_model_scores(model_final, test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A52zn_pRF_5y",
        "outputId": "b9e26633-87e1-495b-9382-d0ac1eea644c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Model final\n",
            "Input: Aku akan mencoba berbicara dengan orang tua ku\n",
            "Output: Aku tahu ini bukan hal yang mudah , jadi aku menghargai niatmu untuk mencoba . Hubungan yang aman dimulai dari keberanian untuk mengungkapkan perasaan , meskipun itu menakutkan . Kalau kamu ingin , kita bisa sama susun kalimat yang nyaman , seperti itu . Kalau kamu ucapkan nanti .\n",
            "Input: Aku akan mencoba saranmu\n",
            "Output: Keputusanmu untuk mencoba menunjukkan kekuatan dalam dirimu yang kadang mungkin kamu lupakan . Tidak apa jika langkahnya pelan yang penting kamu tahu bahwa kamu belum tahu tidak sendirian di perjalanan ini . Aku percaya kamu bisa , dan aku ingin tahu seperti apa rasanya setelah kamu mulai .\n",
            "Input: Mengapa saya masih merasa bersalah atas perceraian orang tua saya?\n",
            "Output: Perasaan bersalah yang berlarut larut bisa muncul karena otak berusaha mencari pemahaman atas situasi yang sulit . Dalam konteks attachment , anak yang mengalami perceraian orang tua mungkin merasa bahwa stabilitas emosionalnya terganggu , sehingga mencari cara untuk mengembalikan kendali , salah satunya dengan merasa bersalah . Namun , memahami bahwa setiap individu bertanggung jawab atas pilihannya sendiri dapat membantu membebaskan diri dari perasaan tersebut . Mencari dukungan dari lingkungan yang aman seperti teman , keluarga , atau profesional dapat membantu membentuk kembali persepsi tentang hubungan dan diri dengan lebih percaya diri .\n",
            "Input: Apakah saya akan bisa menciptakan keluarga yang sehat di masa depan meski berasal dari keluarga yang bercerai?\n",
            "Output: Ya , kamu bisa . Asal kamu memiliki hak untuk belajar dari masa lalu , kamu punya hak untuk menciptakan lingkungan yang penuh kasih . Attachment positif memberi ruang baru yang sehat membantumu menciptakan hubungan yang penuh kasih . Keluargamu bisa lebih sehat dan nilai yang kamu yakini . Keluargamu yang kamu bentuk dengan cinta dan nilai yang kamu yakini .\n",
            "Input: Bagaimana cara menerima bahwa cinta antara orang tua saya sudah berakhir?\n",
            "Output: Menerima akhir dari cinta mereka bukan tanda kelemahanmu , tapi kekuatan untuk menatap hidup dengan jujur . Kadang kita butuh waktu untuk memahami bahwa perubahan tidak selalu buruk . Dalam hubungan yang aman , kita diajak untuk memeluk kenyataan tanpa kehilangan harapan . Kamu sedang menata kembali caramu mencintai dan dipedulikan dan itu hal yang luar biasa .\n",
            "Input: Bagaimana jika saya takut membuka diri karena takut akan ditinggalkan juga?\n",
            "Output: Takut membuka diri bukan berarti kamu lemah , tapi justru menunjukkan bahwa hatimu punya kedalaman . Dalam hubungan yang aman , kamu tidak harus sempurna atau selalu kuat untuk dicintai . Orang yang tepat akan menghargai prosesmu dan tidak terburu buru memintamu menyerahkan semua . Kamu berhak merasa aman sebelum membuka pintu hatimu lebih jauh .\n",
            "Input: Aku merasa overthinking\n",
            "Output: Pikiran yang terus berputar bisa membuat kamu merasa lelah , dan itu wajar . Overthinking sering kali datang dari tempat di mana kamu pernah merasa kecewa atau kehilangan , dan sekarang otakmu mencoba melindungimu . Tapi kamu tidak sendiri dalam menghadapi ini . Apa yang paling sering kamu pikirkan berulang ulang hingga membuatmu sulit tenang ?\n",
            "Input: Aku merasa sangat sedih\n",
            "Output: Aku di sini untukmu . Aku tahu semua yang sedang kamu pikirkan dan rasakan itu berat , dan tidak apa apa kalau kamu merasa sedih . Kamu tidak sendirian dalam hal ini . Aku ingin mendengarkan , kalau kamu tidak sendirian atau sesedikit atau sesedikit atau sesedikit atau sesedikit yang kamu rasakan luka di mana kamu mau .\n",
            "Input: Kapan aku bisa keluar dari perasaan ini?\n",
            "Output: Aku bangga kamu sudah bisa berbicara dan menemukan kelegaan darinya . Itu bukan hal yang mudah , dan keberanianmu sangat berarti . Setiap kali kamu merasa perlu tempat aman , bahkan ketika kamu sedang mencoba memahami dirimu sendiri . Kalau kamu sedang pelan pelan pelan pelan pelan pelan yang kamu butuhkan sekarang dan dicintai .\n",
            "📘 Average BLEU score: 0.4153 \n",
            "📙 Average METEOR score: 0.5858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_U384.load_weights('D:/skripsi-sultin/data/bot_v3_Final_U384.weights.h5')"
      ],
      "metadata": {
        "id": "zsgMaK5peLVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluating Model U384\")\n",
        "bleu_U384, meteor_U384 = evaluate_model_scores(model_U384, test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBXan-qoePi4",
        "outputId": "772dc5a3-1799-485f-979b-06651e452f27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Model U384\n",
            "Input: Aku akan mencoba berbicara dengan orang tua ku\n",
            "Output: Komunikasi yang sehat dengan orang tua bisa membuka banyak pintu yang sebelumnya tertutup rapat . Aku percaya kamu bisa menyampaikan isi hatimu dengan cara yang lembut tapi jujur . Aku akan terus ada di sini kalau kamu ingin cerita setelah kamu melakukannya .\n",
            "Input: Aku akan mencoba saranmu\n",
            "Output: Keputusanmu untuk mencoba menunjukkan kekuatan dalam dirimu yang kadang mungkin kamu lupakan . Tidak apa apa apa apa apa apa apa apa apa apa apa apa apa jika kamu rasakan . Apa di sini kalau kamu ingin berbicara buruk satu sama lain ?\n",
            "Input: Mengapa saya masih merasa bersalah atas perceraian orang tua saya?\n",
            "Output: Perasaan bersalah yang berlarut larut bisa muncul karena otak berusaha mencari pemahaman atas situasi yang sulit . Dalam konteks attachment , anak yang mengalami perceraian orang tua mungkin merasa bahwa stabilitas emosionalnya terganggu , sehingga mencari cara untuk mengembalikan kendali , salah satunya dengan merasa bersalah . Namun , memahami bahwa setiap individu bertanggung jawab atas pilihannya sendiri dapat membantu membebaskan diri dari perasaan tersebut . Mencari dukungan dari lingkungan yang aman seperti teman , atau profesional dapat membantu membentuk kembali persepsi dengan orang tua .\n",
            "Input: Apakah saya akan bisa menciptakan keluarga yang sehat di masa depan meski berasal dari keluarga yang bercerai?\n",
            "Output: Jangan ragu akan kemampuanmu menciptakan keluarga yang kamu impikan . Justru karena kamu tahu rasanya tumbuh di tengah ketidaksempurnaan , kamu bisa lebih sadar dan peka saat membangun relasi . Attachment positif memberi keyakinan bahwa keluarga yang sehat bisa lahir dari ketulusan , komunikasi , dan kerja sama . Dan semua itu ada dalam jangkauanmu .\n",
            "Input: Bagaimana cara menerima bahwa cinta antara orang tua saya sudah berakhir?\n",
            "Output: Menerima akhir dari cinta mereka bukan tanda kelemahanmu , tapi kekuatan untuk menatap hidup dengan jujur . Kadang kita butuh waktu untuk memahami bahwa perubahan tidak selalu buruk . Dalam hubungan yang aman , kita diajak untuk memeluk kenyataan tanpa kehilangan harapan . Kamu sedang menata kembali caramu mencintai dan dipedulikan dan itu hal yang luar biasa .\n",
            "Input: Bagaimana jika saya takut membuka diri karena takut akan ditinggalkan juga?\n",
            "Output: Rasa takut ditinggalkan setelah mengalami kehilangan adalah hal yang sangat manusiawi . Attachment positif mengajarkan bahwa rasa aman bisa dibangun secara perlahan , bukan dipaksakan . Kamu boleh mengambil waktu , dan kamu tidak harus langsung percaya sepenuhnya . Yang penting , kamu tetap memberi dirimu kesempatan untuk terhubung , meski dengan hati hati .\n",
            "Input: Aku merasa overthinking\n",
            "Output: Dalam positive attachment , kita belajar bahwa pikiran yang terus menerus muncul biasanya adalah ekspresi dari rasa takut yang belum diproses sepenuhnya . Mungkin ada cerita atau pengalaman yang terasa belum selesai . Aku di sini kalau kamu ingin pelan menceritakannya . Apakah kamu merasa ada sesuatu yang tidak bisa kamu kendalikan akhir ini ?\n",
            "Input: Aku merasa sangat sedih\n",
            "Output: Saat kamu merasa sedih , yang paling dibutuhkan adalah koneksi yang aman tempat untuk merasa diterima apa adanya . Aku di sini untuk menciptakan ruang itu untukmu . Kamu bisa cerita sebanyak atau sesedikit yang kamu mau . Hal apa yang paling kamu harap bisa berjalan berbeda belakangan ini ?\n",
            "Input: Kapan aku bisa keluar dari perasaan ini?\n",
            "Output: Rasa sakit ini tidak selamanya , meskipun rasanya seperti itu . Hal yang penting adalah kamu tidak harus menunggu semuanya hilang untuk merasa lebih baik kamu bisa mulai merasa sedikit lega dengan berbagi . Kalau kamu nyaman , aku ingin dengar cerita tentang apa yang kamu rindukan dari masa masa masa masa masa masa masa masa masa masa masa sekarang .\n",
            "📘 Average BLEU score: 0.6167\n",
            "📙 Average METEOR score: 0.7824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradio"
      ],
      "metadata": {
        "id": "snIYoAHc3q4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_final.load_weights('D:/skripsi-sultin/data/bot_v3_Final_NH8_E50.weights.h5')"
      ],
      "metadata": {
        "id": "U4LnuLPtVgyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluating Model final\")\n",
        "bleu_NH4, meteor_NH4 = evaluate_model_scores(model_final, test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-g9k2bY2VlSm",
        "outputId": "c4a1885f-5ab5-46cb-cd99-dc6082d853bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Model final\n",
            "Input: Aku akan mencoba berbicara dengan orang tua ku\n",
            "Output: Keputusanmu untuk mencoba berbicara adalah bentuk usaha untuk menciptakan hubungan yang lebih sehat . Komunikasi yang jujur sering kali membuka ruang baru yang jujur dan tanpa menekan emosi . Aku percaya kamu bisa jadi langkah awal dari pemahaman dan menerima perubahan yang lebih sehat . Kamu berhak menciptakan ruang bagi diri sendiri untuk menciptakan ruang bagi yang lebih dulu .\n",
            "Input: Aku akan mencoba saranmu\n",
            "Output: Keputusanmu untuk mencoba menunjukkan kekuatan dalam dirimu yang kadang mungkin kamu lupakan . Tidak apa apa apa apa apa apa apa apa jika langkahnya pelan yang penting bagi kamu tidak harus hilang di perjalanan ini . Aku percaya kamu ingin tahu bahwa kamu mulai , dan tetap punya dukungan dan koneksi yang kamu ingin tahu rasanya setelah kamu alami .\n",
            "Input: Mengapa saya masih merasa bersalah atas perceraian orang tua saya?\n",
            "Output: Merasa bersalah adalah respon emosional yang umum , ketika terjadi perubahan situasi dalam suatu hubungan yang bermakna , misalnya hubungan Anda dengan orang tua . Rasa bersalah itu bisa diturunkan dengan beberapa cara , salah satunya adalah menggunakan perspektif attachment yang positif . Menggunakan perspektif ini , seseorang dapat memposisikan diri untuk menyadari bahwa dia tidak bertanggung jawab atas keputusan orang tua , dan pada saat yang sama meyakini bahwa apapun yang terjadi dalam hubungan antara ayah dan ibu , perasaan kasih sayang mereka kepada anak tetap ada .\n",
            "Input: Apakah saya akan bisa menciptakan keluarga yang sehat di masa depan meski berasal dari keluarga yang bercerai?\n",
            "Output: Jangan ragu akan kemampuanmu menciptakan keluarga yang kamu impikan . Justru karena kamu tahu rasanya tumbuh di tengah ketidaksempurnaan , kamu bisa lebih sadar dan peka saat membangun relasi . Attachment positif memberi keyakinan bahwa keluarga yang sehat bisa lahir dari ketulusan , komunikasi , dan kerja sama . Dan semua itu ada dalam jangkauanmu .\n",
            "Input: Bagaimana cara menerima bahwa cinta antara orang tua saya sudah berakhir?\n",
            "Output: Wajar jika terasa sulit menerima kenyataan ini , karena cinta orang tua sering menjadi dasar rasa aman kita . Tapi kamu juga sedang belajar bahwa hubungan antar manusia bisa kompleks dan berubah . Attachment yang sehat tidak memaksakan stabilitas semu , melainkan menerima perubahan dengan lembut dan penuh pengertian . Kamu tetap berhak atas cinta dan dukungan , walau bentuk keluargamu telah berubah .\n",
            "Input: Bagaimana jika saya takut membuka diri karena takut akan ditinggalkan juga?\n",
            "Output: Rasa takut ditinggalkan setelah mengalami kehilangan adalah hal yang sangat manusiawi . Attachment positif mengajarkan bahwa rasa aman bisa dibangun secara perlahan , bukan dipaksakan . Kamu boleh mengambil waktu , dan kamu tidak harus langsung percaya sepenuhnya . Yang penting , kamu tetap memberi dirimu kesempatan untuk terhubung , meski dengan hati hati .\n",
            "Input: Aku merasa overthinking\n",
            "Output: Terkadang pikiran kita bisa terasa begitu penuh , ya . Apa hal yang paling sering muncul di pikiranmu akhir akhir ini ?\n",
            "Input: Aku merasa sangat sedih\n",
            "Output: Kesedihan yang kamu rasakan valid dan penting untuk dikenali . Dalam hubungan yang aman secara emosional , kita punya ruang untuk menangis dan merasa lemah tanpa harus merasa dihakimi . Kadang , perasaan sedih itu tidak datang begitu saja ada cerita di baliknya . Bolehkah aku tahu , hal apa yang sedang kamu rindukan atau khawatirkan saat ini ?\n",
            "Input: Kapan aku bisa keluar dari perasaan ini?\n",
            "Output: Rasa sakit ini tidak selamanya , meskipun rasanya seperti itu . Hal yang penting adalah kamu tidak harus menunggu semuanya hilang untuk merasa lebih baik kamu bisa mulai merasa sedikit dari langkah kecil . Dalam hubungan yang bisa mulai merasa lebih baik kamu ragukan ?\n",
            "📘 Average BLEU score: 0.5778\n",
            "📙 Average METEOR score: 0.7504\n"
          ]
        }
      ]
    }
  ]
}